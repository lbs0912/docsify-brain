# 中间件-05-Rpc和Dubbo

[TOC]


## 更新
* 2022/06/06，撰写




## 参考资料
* [RPC框架整的介绍 | Blog](https://developer.51cto.com/article/597963.html)




## RPC

RPC（`Remote Procedure Call`），即远程过程调用。一个典型 RPC 框架使用场景中，包含了服务注册与发现（注册中心）、负载均衡、容错、网络传输、序列化等组件。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/rpc-structure-1.png)



### 开源 RPC 产品

目前流行的开源 RPC 框架还是比较多的，包括

1. 阿里的 Dubbo
2. Facebook 的 Thrift
3. Google 的 gRPC
4. Twitter 的 Finagle 



### RPC的核心功能



![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/rpc-core-component-2.png)


一个 RPC 的核心功能主要有 5 个部分组成
1. 客户端
2. 客户端存根（Stub）
   * 存放服务端地址信息
   * 将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端
3. 服务端
4. 服务端存根（Stub）
   * 接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理
5. 网络传输模块
   * **网络数据的底层传输，可以是 HTTP 或 TCP 或 Socket**


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/rpc-core-component-1.png)



结合上图，分析一次 RPC 调用流程
1. 服务消费者（Client 客户端）通过本地调用的方式调用服务。
2. 客户端存根（Client Stub）接收到调用请求后，负责将方法、入参等信息序列化（组装）成能够进行网络传输的消息体。
3. 客户端存根（Client Stub）找到远程的服务地址，并且将消息通过网络发送给服务端。
4. 服务端存根（Server Stub）收到消息后进行解码（反序列化操作）。
5. 服务端存根（Server Stub）根据解码结果调用本地的服务进行相关处理。
6. 服务端（Server）本地服务业务处理。
7. 处理结果返回给服务端存根（Server Stub）。
8. 服务端存根（Server Stub）序列化结果。
9. 服务端存根（Server Stub）将结果通过网络发送至消费方。
10. 客户端存根（Client Stub）接收到消息，并进行解码（反序列化）。
11. 服务消费方得到最终结果。



### RPC核心功能的实现

若要自己实现一个 RPC，需要实现 3 个技术点
1. 服务寻址
2. 数据流的序列化和反序列化
3. 网络传输

#### 服务寻址

服务寻址可以使用 `Call ID` 映射。

在本地调用中，函数体是直接通过「函数指针」来指定的。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以在 RPC 中，所有的函数都必须有自己的一个 ID，这个 ID 在所有进程中都是唯一确定的。

客户端在做远程过程调用时，必须附上这个 ID。然后我们还需要在客户端和服务端分别维护一个函数和 `Call ID` 的对应表。当客户端需要进行远程调用时，它就查一下这个表，找出相应的 `Call ID`，然后把它传给服务端。服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。


可以在「服务注册中心」中维护个函数和 `Call ID` 的对应关系。客户端调用服务前，先去服务注册中心查询对方服务的信息。Dubbo 的服务注册中心是可以配置的，官方推荐使用 Zookeeper。

Java 的 RMI（`Remote Method Invocation`），即「远程方法调用」，也是 RPC 的一种实现方式，如下图所示。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/java-rmi-structure-1.png)



> **服务发现（Registry）**
* 当服务端开发完服务之后，要对外暴露，并在服务注册中心注册。
* 如果没有服务注册，则客户端是无从调用的，因为客户端无法发现该服务。


#### 序列化和反序列化

在远程过程调用时，客户端跟服务端是不同的进程，不能通过「内存」来传递参数。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。

只有二进制数据才能在网络中传输，所以需要进行序列化和反序列化。
1. 将对象转换成二进制流的过程叫做序列化
2. 将二进制流转换成对象的过程叫做反序列化

常见的序列化方式包括 
* json
* messagepack（msgpack）
* hession



#### 网络传输

RPC 中，所有的数据都需要通过网络传输。需要把 `Call ID` 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。

**对于网络传输协议，RPC 并没有限制，尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 则直接使用 HTTP 2 协议。也可以使用 Socket 或者 Netty。**


##### 基于TCP协议的RPC调用和长/短连接

由服务的调用方与服务的提供方建立 `Socket` 连接，并由服务的调用方通过 `Socket` 将需要调用的接口名称、方法名称和参数序列化后传递给服务的提供方。


根据是否及时断开连接，可以将 TCP 连接分为短连接和长连接
1. 短连接
   * 需要调用的时候就建立连接，调用结束后就立马断掉
2. 长连接
   * 客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送
   * 可以配合「心跳检测机制」定期检测建立的连接是否存活有效
   * 多个远程过程调用共享同一个连接


##### 基于HTTP协议的RPC调用

由服务的调用者向服务的提供者发送请求，这种请求的方式可能是 GET、POST、PUT、DELETE 等中的一种，服务的提供者可能会根据不同的请求方式做出不同的处理。



##### 两种方式的对比

* TCP 是传输层的协议，HTTP 是传输层上面的应用层的协议。
* 由于 TCP 协议处于协议栈的下层，所以「基于 TCP 协议的 RPC 调用」能够更加灵活地对协议字段进行定制，减少网络开销，提高性能，实现更大的吞吐量和并发数。
* 同样因为 TCP 协议处于协议栈的下层，所以「基于 TCP 协议的 RPC 调用」需要更多关注底层复杂的细节，实现的代价更高。同时对不同平台，如安卓，iOS 等，需要重新开发出不同的工具包来进行请求发送和相应解析，工作量大，难以快速响应和满足用户需求。
* 基于 HTTP 协议实现的 RPC 调用，可以使用 JSON 和 XML 格式的请求或响应数据。
* 由于 HTTP 协议是上层协议，发送包含同等内容的信息，使用 HTTP 协议传输所占用的字节数会比使用 TCP 协议传输所占用的字节数更高。
* **在同等网络下，通过 HTTP 协议传输相同内容，效率会比基于 TCP 协议的数据效率要低，信息传输所占用的时间也会更长。**



### 有了HTTP，为什么还要RPC
* ref 1-[既然有 HTTP 请求，为什么还要用 RPC 调用 |知乎](https://www.zhihu.com/question/41609070)

对于「有了HTTP，为什么还要RPC」，是一个可能被问到的面试题。

**首先，不要被面试问题带跑偏，HTTP 是网络应用层的一个通信协议，RPC 是一种设计、实现框架，通信协议只是 RPC 中的一个组成部分。**


**RPC 跟 HTTP 不是对立面，RPC 中可以使用 HTTP 作为通讯协议，也可以使用 TCP、UDP、Socket、Netty 等作为通讯协议。RPC 是一种设计、实现框架，通讯协议只是其中一部分。RPC 的本质是提供了一种轻量无感知的跨进程通信的方式。**



**对于「有了HTTP，为什么还要RPC」这个问题，面试官可能更想问的是「为什么要使用自定义 TCP 协议的 RPC 做后端进程通信」。**

这个问题可以从以下几个方面回答
1. 减少传输内容
   * 自定义 TCP 协议，可以减少报文占用的字节数，减少不必要的传输内容
2. 长链接
   * 客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送、
   * 可以配合「心跳检测机制」定期检测建立的连接是否存活有效
   * 多个远程过程调用共享同一个连接
3. 注册发布机制
   * RPC 框架一般都有注册中心，发布、下线接口、动态扩展等操作，对调用方来说是无感知、统一化的操作
4. 丰富的监控管理
5. 安全性
   * 没有暴露资源操作
6. 微服务支持
   * RPC 可很好的支持微服务架构
7. HTTP 是应用层的协议，TCP 协议是下一层的传输层协议，更偏向底层，更灵活



**最后，要明确的是「HTTP 协议相较于自定义 TCP 报文协议，增加的开销并不是在于连接的建立与断开」。自定义 TCP 报文协议的 RPC 调用时，也涉及 TCP 建立连接的三次握手，它的优势主要体现在可以减少报文占用的字节数，减少不必要的传输内容。**



| 对比项 |   RPC   |      HTTP       |
|-------|---------|-----------------|
| message body 的长度 | 由具体协议协商决定，一般会在包头 | head field 里的 Content-Length 设置 |
| header 类型 | 一般为二进制 | 明文，以空行表示结束 |
| body 内容类型 | 和 RPC 框架相关，比如 gRPC 框架解析 Protobuf，而 Thrift 框架解析 thrift | 由 Content-Type 决定，比如 `application/json`，`application/protobuf` |

HTTP 协议也是可以支持连接池复用的，建立一定数量的连接不断开，并不会频繁的创建和销毁连接。此外，HTTP 也可以使用 Protobuf 这种二进制编码协议对内容进行编码。

HTTP 协议和自定义 TCP 报文协议，二者最大的区别还是在传输协议上。HTTP 1.1 协议的TCP 报文包含太多信息，占用字节数较大。一个 POST 协议的格式大致如下。

```s
HTTP/1.0 200 OK 
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84

<html>
  <body>Hello World</body>
</html>
```

即使编码协议（`body` 部分）使用二进制编码协议，报文元数据（`head` 头的键值）使用的是文本编码，非常占字节数。如上图所使用的报文中有效字节数仅仅占约 30%，也就是 70% 的时间用于传输元数据废编码。

那么假如我们使用自定义 TCP 协议的报文如下

```s
| 1-> 4 byte  | 5-> 8 byte| 9 -> 16 byte   | 17 -> length + 16 byte |
| length(int) | type(int) | package_id(long) | package_data |   
```

报头占用的字节数也就只有 16 个 byte，极大地精简了传输内容。

**这也就是为什么后端进程间通常会采用自定义 TCP 协议的 RPC 来进行通信的原因。**


## TCP的短/长连接和keepAlive

* ref 1-[gRPC 长连接在微服务业务系统中的实践 | InfoQ](https://www.infoq.cn/article/cpxr35bwjttgncltyekz)
* ref 2-[Dubbo 的连接机制](https://www.cnblogs.com/intotw/p/13815394.html)


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/keep-alive-tcp-1.png)


TCP 连接的三种行为如上图所示
1. 短连接
   * 需要调用的时候就建立连接，调用结束后就立马断掉
2. 短连接 + `keepAlive`
   * keepalive 机制开启之后，系统会为每一个连接设置一个定时器，不断地发送 ACK 包，用来探测目标主机是否存活
3. 长连接
   * 客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送
   * 可以配合「心跳检测机制」定期检测建立的连接是否存活有效
   * 多个远程过程调用共享同一个连接


需要强调的是
* TCP 连接本身并没有长短的区分，长或短只是在描述我们使用它的方式
* **长/短是指多次数据交换能否复用同一个连接，而不是指连接的持续时间**
* TCP 的 `keepAlive` 仅起到保活探测的作用，和连接的长短并没有因果关系



### 长连接的优势

相比于短连接，长连接的优点如下
1. 较低的延时
   * 由于复用同一个连接，省去了重新建立连接的三次握手，长连接比短连接有更低的延迟
   * 需要注意的是，长连接在建立时，依然会有 TCP 创建连接的三次握手
2. 较低的带宽占用
   * 由于不用为每个请求建立和关闭连接，长连接交换效率更高，网络带宽占用更少
3. 较少的系统资源占用
   * Server 为了维持连接，会为每个连接创建 `socket`，分配文件句柄，在内存中分配读写 `buffer`，设置定时器进行 `keepAlive`
   * 更少的连接数也意味着更少的资源占用



另外，gRPC 使用 HTTP/2.0 作为传输协议，从该协议的设计来讲，长连接也是更推荐的使用方式，原因是
1. HTTP/2.0 的多路复用，使得连接的复用效率得到了质的提升
2. HTTP/2.0 的单个连接维持的成本更高
   * 除了分帧分流之外， HTTP/2.0 还加入了诸如流控制和服务端推送等特性，这也使得协议变得复杂，连接的建立和维护成本升高



### 长连接的劣势
1. client 和 server 的数量
   * 长连接模式下，server 要和每一个 client 都保持连接。如果 client 数量远远超过 server 数量，与每个 client 都维持一个长连接，对 server 来说会是一个极大的负担。
   * 使用简单且易于管理的短连接也许是更好的选择。
   * 即使用长连接，也必须设置一个合理的超时机制，如在空闲时间过长时断开连接，释放 server 资源。
2. 负载均衡机制
   * 使用负载均衡后，在短连接模式下，由于连接会不断的建立和关闭，同一个 client 的流量会被分发到不同的 server。
   * 在长连接模式下，由于连接一旦建立便不会断开，就会导致流量会被分发到同一个 server。在 client 与 server 数量差距不大，甚至 client 少于 server 的情况下，就会导致流量分发不均。

## gRPC

gRPC 是谷歌开源的一个 RPC 框架，面向移动和 `HTTP/2` 设计。
* 内容交换格式采用 ProtoBuf（`Google Protocol Buffers`），提供了一种灵活、高效、自动序列化结构数据的机制，作用与 XML、JSON 类似，但使用二进制，（反）序列化速度快，压缩效率高。
* 传输协议采用 `HTTP/2`，性能比 `HTTP/1.1` 好了很多





## Dubbo

* [Dubbo Cookbook](https://dubbo.apache.org/zh/)


Dubbo 是一款高性能、轻量级的开源 RPC 框架，提供服务自动注册、自动发现等高效服务治理方案。Dubbo 提供 3 个核心功能
1. 面向接口的远程方法调用
2. 智能容错和负载均衡
3. 服务自动注册和发现




