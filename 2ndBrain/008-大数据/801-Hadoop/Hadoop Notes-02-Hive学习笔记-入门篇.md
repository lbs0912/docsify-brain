# Hadoop Notes-02-Hiveå­¦ä¹ ç¬”è®°-å…¥é—¨ç¯‡


[TOC]

## æ›´æ–°
* 2020/03/28ï¼Œæ’°å†™



## å­¦ä¹ èµ„æ–™æ±‡æ€»
* [Hiveå®˜ç½‘](http://hive.apache.org/)
* [ä¸€èµ·å­¦Hiveç³»åˆ—æ–‡ç« ](http://lxw1234.com/archives/2015/07/365.htm) !!
* [User Documentation - Apache Hive](https://cwiki.apache.org/confluence/display/Hive#Home-UserDocumentation)
* [Hiveå­¦ä¹ è·¯çº¿å›¾è°± | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/hadoop-hive-roadmap/)
* [Hiveå®‰è£…åŠä½¿ç”¨æ”»ç•¥ | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/hadoop-hive-intro/)



## Overview

> Hiveæ˜¯å»ºç«‹åœ¨ Hadoop ä¸Šçš„æ•°æ®ä»“åº“åŸºç¡€æ„æ¶ã€‚

Hive æ˜¯ Hadoop å®¶æ—ä¸­ä¸€æ¬¾æ•°æ®ä»“åº“äº§å“ï¼ŒHive æœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯æä¾›äº†ç±» SQL çš„è¯­æ³•ï¼Œå°è£…äº†åº•å±‚çš„ MapReduce è¿‡ç¨‹ï¼Œè®©æœ‰ SQL åŸºç¡€çš„ä¸šåŠ¡äººå‘˜ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åˆ©ç”¨ Hadoop è¿›è¡Œå¤§æ•°æ®çš„æ“ä½œã€‚å°±æ˜¯è¿™ä¸€ä¸ªç‚¹ï¼Œè§£å†³äº†åŸæ•°æ®åˆ†æäººå‘˜å¯¹äºå¤§æ•°æ®åˆ†æçš„ç“¶é¢ˆã€‚


**Hive å¯ä»¥å°†ç»“æ„åŒ–çš„æ•°æ®æ–‡ä»¶æ˜ å°„ä¸ºä¸€å¼ æ•°æ®åº“è¡¨ï¼Œå¹¶æä¾›å®Œæ•´çš„ SQL æŸ¥è¯¢åŠŸèƒ½ï¼Œå¯ä»¥å°† SQL è¯­å¥è½¬æ¢ä¸º MapReduce ä»»åŠ¡è¿è¡Œã€‚Hive å®šä¹‰äº†ç®€å•çš„ç±» SQL æŸ¥è¯¢è¯­è¨€ï¼Œç§°ä¸º HQL**ã€‚

Hive æ„å»ºåœ¨ Hadoop çš„ HDFS å’Œ MapReduce ä¹‹ä¸Šï¼Œç”¨äºç®¡ç†å’ŒæŸ¥è¯¢ç»“æ„åŒ–/éç»“æ„åŒ–æ•°æ®çš„æ•°æ®ä»“åº“ã€‚
* ä½¿ç”¨ HQL ä½œä¸ºæŸ¥è¯¢æ¥å£
* ä½¿ç”¨ HDFS ä½œä¸ºåº•å±‚å­˜å‚¨
* ä½¿ç”¨ MapReduce ä½œä¸ºæ‰§è¡Œå±‚



Hive çš„çŸ¥è¯†å›¾è°±å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hadoop-hive-roadmap.png)



Hive å·²ç»ç”¨ç±» SQL çš„è¯­æ³•å°è£…äº† MapReduce è¿‡ç¨‹ï¼Œè¿™ä¸ªå°è£…è¿‡ç¨‹å°±æ˜¯ MapReduce çš„æ ‡å‡†åŒ–çš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬åœ¨åšä¸šåŠ¡æˆ–è€…å·¥å…·æ—¶ï¼Œä¼šé’ˆå¯¹åœºæ™¯ç”¨é€»è¾‘å°è£…ï¼Œè¿™é‡Œçš„ç¬¬2å±‚å°è£…æ˜¯åœ¨Hiveä¹‹ä¸Šçš„å°è£…ã€‚åœ¨ç¬¬2å±‚å°è£…æ—¶ï¼Œæˆ‘ä»¬è¦å°½å¯èƒ½å¤šçš„å±è”½ Hive çš„ç»†èŠ‚ï¼Œè®©æ¥å£å•ä¸€åŒ–ï¼Œä½å°‘çµæ´»æ€§ï¼Œå†æ¬¡ç²¾ç®€ HQL çš„è¯­æ³•ç»“æ„ã€‚åªæ»¡è¶³æˆ‘ä»¬çš„ç³»ç»Ÿè¦æ±‚ï¼Œä¸“ç”¨çš„æ¥å£ã€‚

åœ¨ä½¿ç”¨äºŒæ¬¡å°è£…çš„æ¥å£æ—¶ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥ä¸ç”¨çŸ¥é“ Hive æ˜¯ä»€ä¹ˆ, æ›´ä¸ç”¨çŸ¥é“ Hadoop æ˜¯ä»€ä¹ˆã€‚åªéœ€è¦çŸ¥é“ï¼ŒSQLæŸ¥è¯¢(SQL92æ ‡å‡†)ï¼Œæ€ä¹ˆå†™æ•ˆç‡é«˜ï¼Œæ€ä¹ˆå†™å¯ä»¥å®Œæˆä¸šåŠ¡éœ€è¦å°±å¯ä»¥äº†ã€‚

å½“æˆ‘ä»¬å®Œæˆäº† Hive çš„äºŒæ¬¡å°è£…åï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºæ ‡å‡†åŒ–çš„ MapReduce å¼€å‘è¿‡ç¨‹ã€‚



![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hive-architect-2.jpg)



Hive ä¸é€‚åˆç”¨äºè”æœºï¼ˆ`online`ï¼‰äº‹åŠ¡å¤„ç†ï¼Œä¹Ÿä¸æä¾›å®æ—¶æŸ¥è¯¢åŠŸèƒ½ã€‚å®ƒæœ€é€‚åˆç”¨åœ¨åŸºäºå¤§é‡ä¸å¯å˜æ•°æ®çš„æ‰¹å¤„ç†ä½œä¸šã€‚Hiveç‰¹ç‚¹æ˜¯å¯ä¼¸ç¼©ï¼ˆåœ¨Hadoopçš„é›†ç¾¤ä¸ŠåŠ¨æ€åœ°æ·»åŠ è®¾å¤‡ï¼‰ï¼Œå¯æ‰©å±•ï¼Œå®¹é”™ï¼Œè¾“å…¥æ ¼å¼çš„æ¾æ•£è€¦åˆã€‚

Hive çš„æœ€ä½³ä½¿ç”¨åœºåˆæ˜¯å¤§æ•°æ®é›†çš„æ‰¹å¤„ç†ä½œä¸šï¼Œä¾‹å¦‚ï¼Œç½‘ç»œæ—¥å¿—åˆ†æã€‚

### Hiveå’Œå…³ç³»å‹æ•°æ®åº“çš„åŒºåˆ«

Hive åœ¨å¾ˆå¤šæ–¹é¢ä¸ä¼ ç»Ÿå…³ç³»æ•°æ®åº“ç±»ä¼¼ï¼ˆä¾‹å¦‚æ”¯æŒ SQL æ¥å£ï¼‰ï¼Œä½†æ˜¯å…¶åº•å±‚å¯¹ HDFS å’Œ MapReduce çš„ä¾èµ–æ„å‘³ç€å®ƒçš„ä½“ç³»ç»“æ„æœ‰åˆ«äºä¼ ç»Ÿå…³ç³»æ•°æ®åº“ï¼Œè€Œè¿™äº›åŒºåˆ«åˆå½±å“ç€ Hive æ‰€æ”¯æŒçš„ç‰¹æ€§ï¼Œè¿›è€Œå½±å“ç€ Hive çš„ä½¿ç”¨ã€‚

ä¸‹é¢åˆ—ä¸¾ä¸€äº›ç®€å•åŒºåˆ«
* Hive å’Œå…³ç³»æ•°æ®åº“å­˜å‚¨æ–‡ä»¶çš„ç³»ç»Ÿä¸åŒï¼ŒHive ä½¿ç”¨çš„æ˜¯ Hadoop çš„HDFSï¼ˆHadoopçš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼‰ï¼Œå…³ç³»æ•°æ®åº“åˆ™æ˜¯æœåŠ¡å™¨æœ¬åœ°çš„æ–‡ä»¶ç³»ç»Ÿ
* Hive ä½¿ç”¨çš„è®¡ç®—æ¨¡å‹æ˜¯ MapReduceï¼Œè€Œå…³ç³»æ•°æ®åº“åˆ™æ˜¯è‡ªå·±è®¾è®¡çš„è®¡ç®—æ¨¡å‹
* å…³ç³»æ•°æ®åº“éƒ½æ˜¯ä¸ºå®æ—¶æŸ¥è¯¢çš„ä¸šåŠ¡è¿›è¡Œè®¾è®¡çš„ï¼Œè€Œ Hive åˆ™æ˜¯ä¸ºæµ·é‡æ•°æ®åšæ•°æ®æŒ–æ˜è®¾è®¡çš„ï¼Œå®æ—¶æ€§å¾ˆå·®ï¼›å®æ—¶æ€§çš„åŒºåˆ«å¯¼è‡´ Hive çš„åº”ç”¨åœºæ™¯å’Œå…³ç³»æ•°æ®åº“æœ‰å¾ˆå¤§çš„ä¸åŒ
* Hive å¾ˆå®¹æ˜“æ‰©å±•è‡ªå·±çš„å­˜å‚¨èƒ½åŠ›å’Œè®¡ç®—èƒ½åŠ›ï¼Œè¿™ä¸ªæ˜¯ç»§æ‰¿ Hadoop çš„ï¼Œè€Œå…³ç³»æ•°æ®åº“åœ¨è¿™ä¸ªæ–¹é¢è¦å·®å¾ˆå¤š



## Hive å®‰è£…é…ç½®
Hive å®‰è£…å‚è€ƒèµ„æ–™å¦‚ä¸‹
* [Mac ä¸Š Hive ç¯å¢ƒæ­å»º | blog](https://www.cnblogs.com/micrari/p/7067968.html)
* [MacOS ä¸‹hiveçš„å®‰è£…ä¸é…ç½® | çŸ¥ä¹](https://zhuanlan.zhihu.com/p/70601668)
* [Hiveå®‰è£…åŠä½¿ç”¨æ”»ç•¥ | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/hadoop-hive-intro/)
* [macä¸‹Hive+MySqlç¯å¢ƒé…ç½® | blog](https://jyzhangchn.github.io/hive.html)
* [Mac Hive é…ç½®å’Œå®‰è£… | ç®€ä¹¦](https://www.jianshu.com/p/5c11073d19d3)

æ­¤å¤„ï¼Œç®€å•è®°å½•Hiveçš„å®‰è£…å’Œé…ç½®æ­¥éª¤


### å®‰è£…mysql

1. é€šè¿‡ Homebrew å®‰è£… mysql

```
brew install mysql
```

å®‰è£…ç»“æŸåï¼Œä¼šæœ‰å¦‚ä¸‹æç¤º

```
We've installed your MySQL database without a root password. To secure it run:
    mysql_secure_installation

MySQL is configured to only allow connections from localhost by default

To connect run:
    mysql -uroot

To have launchd start mysql now and restart at login:
  brew services start mysql
Or, if you don't want/need a background service you can just run:
  mysql.server start

```

ä¸Šè¿°ä¿¡æ¯æç¤ºï¼Œ
* è¿è¡Œ `brew services start mysql`ï¼Œå¯ä»¥åœ¨åå°å¯åŠ¨ mysql
* è¿è¡Œ `mysql.server start`ï¼Œå¯ä»¥åœ¨å‰å°å¯åŠ¨ mysqlï¼ˆå…³é—­æ§åˆ¶å°ï¼ŒæœåŠ¡åœæ­¢ï¼‰
* è¿è¡Œ `mysql_secure_installation`ï¼Œå¯ä»¥è¿›è¡Œå¯†ç è®¾ç½®


2. ä½¿ç”¨ `mysql --version` æ ¡éªŒ mysql ç‰ˆæœ¬å·


```
mysql --version

// mysql  Ver 8.0.19 for osx10.15 on x86_64 (Homebrew)
```



3. è®¾ç½®mysqlç§˜å¯†ï¼Œè®¾å®šå¯†ç ä¸º `mysql113459`

```
brew services start mysql   //è®¾å®šå¯†ç å‰éœ€è¦å…ˆå¯åŠ¨mysql

mysql_secure_installation
//å¯†ç è®¾å®šä¸º mysql113459
```



MySQL æ–°ç‰ˆæœ¬ä¸­å¼•å…¥äº†å¯†ç å®‰å…¨çº§åˆ«çš„æ¦‚å¿µï¼Œè®¾ç½®ä½å¼ºåº¦çš„å¯†ç æœ‰æ—¶ä¼šè¢«ç¦æ­¢ã€‚ä¸ºæ­¤å¯ä»¥ç›´æ¥æŒ‡å®šå¯†ç å®‰å…¨å¼ºåº¦ï¼Œæ‰§è¡Œä¸‹è¿°å‘½ä»¤ã€‚


```
mysql> set global validate_password_policy=0;  //è®¾ç½®å¯†ç å¼ºåº¦çº§åˆ«ä¸ºlow
mysql> set global validate_password_length=1;   //è®¾ç½®å¯†ç æœ€å°é•¿åº¦ä¸º4

mysql> SHOW VARIABLES LIKE 'validate_password%';    //æŸ¥çœ‹å¯†ç ç›¸å…³å‚æ•°è®¾ç½®

+--------------------------------------+--------+
| Variable_name                        | Value  |
+--------------------------------------+--------+
| validate_password.check_user_name    | ON     |
| validate_password.dictionary_file    |        |
| validate_password.length             | 8      |
| validate_password.mixed_case_count   | 1      |
| validate_password.number_count       | 1      |
| validate_password.policy             | MEDIUM |
| validate_password.special_char_count | 1      |
| validate_password_check_user_name    | ON     |
| validate_password_dictionary_file    |        |
| validate_password_length             | 4      |
| validate_password_mixed_case_count   | 1      |
| validate_password_number_count       | 1      |
| validate_password_policy             | LOW    |
| validate_password_special_char_count | 1      |
+--------------------------------------+--------+
```






è‹¥æ‰§è¡Œ `SHOW VARIABLES LIKE 'validate_password%';` é‡åˆ° `Unknown system variable 'validate_password_policy'` æŠ¥é”™ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒ [MySQL validate_password_policy unknown system variable | StackOverflow](https://stackoverflow.com/questions/55237257/mysql-validate-password-policy-unknown-system-variable) è¿›è¡Œå¤„ç†ã€‚


> This problem has happened because validate_password plugin is by default NOT activated. 

```
mysql> select plugin_name, plugin_status from information_schema.plugins where plugin_name like 'validate%';

mysql> install plugin validate_password soname 'validate_password.so';

mysql> select plugin_name, plugin_status from information_schema.plugins where plugin_name like 'validate%';

mysql> SHOW VARIABLES LIKE 'validate_password%';
```

4. mysqlå¯åŠ¨


```
brew services start mysql   //åå°å¯åŠ¨

sudo mysql.server start     //å‰å°å¯åŠ¨

//è‹¥é‡åˆ°æƒé™é—®é¢˜ï¼Œå¯æ‰§è¡Œä¸‹è¿°å‘½ä»¤
sudo chmod -R a+rwx /usr/local/var/mysql
```

5. mysqlå…³é—­


```
sudo mysql.server stop
```


6. mysqlé‡å¯


```
sudo mysql.server restart
```


7. æŸ¥çœ‹é»˜è®¤æ•°æ®åº“


```
mysql -u root -p    //å¯†ç   mysql113459

show databases

exit  //é€€å‡ºmysqläº¤äº’CI
```

### Hive å®‰è£…


1. é€šè¿‡ Homebrew å®‰è£… Hive

```
brew install hive
```

å®‰è£…ç»“æŸåï¼Œä¼šæœ‰å¦‚ä¸‹æç¤º

```
==> Caveats
Hadoop must be in your path for hive executable to work.

If you want to use HCatalog with Pig, set $HCAT_HOME in your profile:
  export HCAT_HOME=/usr/local/opt/hive/libexec/hcatalog
==> Summary
ğŸº  /usr/local/Cellar/hive/3.1.2: 1,126 files, 231.8MB, built in 7 seconds

```


2. ä½¿ç”¨ `hive --version` æ ¡éªŒ hive ç‰ˆæœ¬å·


```
lbsMacBook-Pro:~ lbs$ hive --version
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/Cellar/hive/3.1.2/libexec/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Library/hadoop-2.10.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive 3.1.2
Git git://HW13934/Users/gates/tmp/hive-branch-3.1/hive -r 8190d2be7b7165effa62bd21b7d60ef81fb0e4af
Compiled by gates on Thu Aug 22 15:01:18 PDT 2019
From source with checksum 0492c08f784b188c349f6afb1d8d9847
```


3. hive ç¯å¢ƒå˜é‡é…ç½®

(1) æ‰“å¼€é…ç½®æ–‡ä»¶

```
vim ~/.bash_profile
```

(2) æ›´æ–°é…ç½®æ–‡ä»¶

```
HIVE_HOME=/usr/local/Cellar/hive/3.1.2 
HCAT_HOME=/usr/local/opt/hive/libexec/hcatalog
PATH=$PATH:${HIVE_HOME}/bin

export HIVE_HOME
export HCAT_HOME
```

(3) ä½¿é…ç½®æ–‡ä»¶ç”Ÿæ•ˆ

```
source ~/.bash_profile
```


### ä¿®æ”¹ Hive é»˜è®¤å…ƒæ•°æ®åº“

> é»˜è®¤æƒ…å†µä¸‹ï¼ŒHive å…ƒæ•°æ®ä¿å­˜åœ¨å†…åµŒçš„ Derby æ•°æ®åº“ä¸­ï¼Œåªèƒ½å…è®¸ä¸€ä¸ªä¼šè¯è¿æ¥ï¼Œåªé€‚åˆç®€å•çš„æµ‹è¯•ã€‚å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ä¸ä½¿ç”¨ï¼Œä¸ºäº†æ”¯æŒå¤šç”¨æˆ·ä¼šè¯ï¼Œåˆ™éœ€è¦ä¸€ä¸ªç‹¬ç«‹çš„å…ƒæ•°æ®åº“ï¼Œå¯ä»¥ä½¿ç”¨ MySQL ä½œä¸ºå…ƒæ•°æ®åº“ï¼ŒHive å†…éƒ¨å¯¹ MySQL æä¾›äº†å¾ˆå¥½çš„æ”¯æŒã€‚

1. Hive å°†å…ƒæ•°æ®å­˜å‚¨åœ¨ `RDBMS` ä¸­,ä¸€èˆ¬å¸¸ç”¨çš„æœ‰ `MYSQL` å’Œ `DERBY`ã€‚ç”±äº `DERBY` åªæ”¯æŒå•å®¢æˆ·ç«¯ç™»å½•ï¼Œæ‰€ä»¥ä¸€èˆ¬é‡‡ç”¨ `MySql` æ¥å­˜å‚¨å…ƒæ•°æ®ã€‚Hive é»˜è®¤å…ƒæ•°æ®åº“æ˜¯ `derby`ã€‚ä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œç»™å‡ºç”¨ mysql å‚¨å­˜å…ƒæ•°æ®çš„é…ç½®


```
//åˆ›å»ºæ•°æ®åº“metastore
mysql> create database metastore; 

//åˆ›å»ºç”¨æˆ·åä¸ºhiveï¼Œç™»å½•å¯†ç ä¸ºHive113459...çš„è´¦æˆ·
mysql> create user 'hive'@'localhost' identified by 'Hive113459...'; 

//ç»™å»ºå¥½çš„æ•°æ®åº“æ·»åŠ æƒé™
grant select,insert,update,delete,alter,create,index,references on metastore.* to 'hive'@'localhost'; 

// åˆ·æ–°æƒé™
mysql> flush privileges; 
```


### Hive é…ç½®

1. è¿›å…¥ Hive çš„å®‰è£…ç›®å½•ï¼Œåˆ›å»º `hive-site.xml` æ–‡ä»¶


```
$ cd /usr/local/Cellar/hive/3.1.2/libexec/conf
$ cp hive-default.xml.template hive-site.xml    //å¤åˆ¶æä¾›çš„æ¨¡æ¿æ–‡ä»¶ 
```

åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œå¯¹ä»¥ä¸‹å‡ ä¸ªå±æ€§è¿›è¡Œä¿®æ”¹ã€‚


```
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://localhost/metastore</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>com.mysql.jdbc.Driver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>hive(ä¸Šè¿°mysqlä¸­åˆ›å»ºçš„ç”¨æˆ·å)</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>Hive113459...(ä¸Šè¿°mysqlä¸­åˆ›å»ºçš„ç”¨æˆ·å¯†ç )</value>
</property>

<property>
  <name>hive.exec.local.scratchdir</name>
  <value>/tmp/hive</value>
</property>

<property>
  <name>hive.querylog.location</name>
  <value>/tmp/hive</value>
</property>

<property>
  <name>hive.downloaded.resources.dir</name>
  <value>/tmp/hive</value>
</property>

<property>
  <name>hive.server2.logging.operation.log.location</name>
  <value>/tmp/hive/operation_logs</value>
</property>
```

2. æ‹·è´ `mysql-connector` åˆ° hive çš„å®‰è£…ç›®å½•ä¸‹

```
$ curl -L 'http://www.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.15.tar.gz/from/http://mysql.he.net/' | tar xz

$ cp mysql-connector-java-8.0.15/mysql-connector-java-8.0.15-bin.jar /usr/local/Cellar/hive/3.1.2/libexec/lib/
```


3. åˆå§‹åŒ– metastore æ•°æ®åº“


ç›®å‰ç›´æ¥æŸ¥çœ‹ `metastore` æ•°æ®åº“ï¼Œå¯ä»¥å‘ç°æ•°æ®åº“æ˜¯ç©ºçš„ã€‚

```
mysql> show databases;
mysql> use metastore;
mysql> show tables;   // empty
```

åœ¨å‘½ä»¤è¡Œæ¨¡å¼ï¼ˆémysql CLIï¼‰ä¸‹æ‰§è¡Œä¸‹è¿°å‘½ä»¤ï¼Œåˆå§‹åŒ– metastore æ•°æ®åº“

```
$ schematool -initSchema -dbType mysql

//Initialization script completed
//schemaTool completed
```

æ‰§è¡Œå®Œæ¯•åï¼Œå†æ¬¡æŸ¥çœ‹æ•°æ®åº“ï¼Œä¼šå‘ç°å¦‚ä¸‹ä¿¡æ¯

```
mysql> show tables;
+-------------------------------+
| Tables_in_metastore           |
+-------------------------------+
| AUX_TABLE                     |
| BUCKETING_COLS                |
| CDS                           |
| COLUMNS_V2                    |
| COMPACTION_QUEUE              |
| COMPLETED_COMPACTIONS         |
| COMPLETED_TXN_COMPONENTS      |
| CTLGS                         |
| DATABASE_PARAMS               |
| DB_PRIVS                      |
| DBS                           |
| DELEGATION_TOKENS             |
| FUNC_RU                       |
| FUNCS                         |
| GLOBAL_PRIVS                  |
| HIVE_LOCKS                    |
| I_SCHEMA                      |
| IDXS                          |
| INDEX_PARAMS                  |
| KEY_CONSTRAINTS               |
| MASTER_KEYS                   |
| MATERIALIZATION_REBUILD_LOCKS |
| METASTORE_DB_PROPERTIES       |
| MIN_HISTORY_LEVEL             |
| MV_CREATION_METADATA          |
| MV_TABLES_USED                |
| NEXT_COMPACTION_QUEUE_ID      |
| NEXT_LOCK_ID                  |
| NEXT_TXN_ID                   |
| NEXT_WRITE_ID                 |
| NOTIFICATION_LOG              |
| NOTIFICATION_SEQUENCE         |
| NUCLEUS_TABLES                |
| PART_COL_PRIVS                |
| PART_COL_STATS                |
| PART_PRIVS                    |
| PARTITION_EVENTS              |
| PARTITION_KEY_VALS            |
| PARTITION_KEYS                |
| PARTITION_PARAMS              |
| PARTITIONS                    |
| REPL_TXN_MAP                  |
| ROLE_MAP                      |
| ROLES                         |
| RUNTIME_STATS                 |
| SCHEMA_VERSION                |
| SD_PARAMS                     |
| SDS                           |
| SEQUENCE_TABLE                |
| SERDE_PARAMS                  |
| SERDES                        |
| SKEWED_COL_NAMES              |
| SKEWED_COL_VALUE_LOC_MAP      |
| SKEWED_STRING_LIST            |
| SKEWED_STRING_LIST_VALUES     |
| SKEWED_VALUES                 |
| SORT_COLS                     |
| TAB_COL_STATS                 |
| TABLE_PARAMS                  |
| TBL_COL_PRIVS                 |
| TBL_PRIVS                     |
| TBLS                          |
| TXN_COMPONENTS                |
| TXN_TO_WRITE_ID               |
| TXNS                          |
| TYPE_FIELDS                   |
| TYPES                         |
| VERSION                       |
| WM_MAPPING                    |
| WM_POOL                       |
| WM_POOL_TO_TRIGGER            |
| WM_RESOURCEPLAN               |
| WM_TRIGGER                    |
| WRITE_SET                     |
+-------------------------------+
74 rows in set (0.01 sec)
```


### å¯åŠ¨ Hive

å¯åŠ¨Hiveå‰ï¼Œéœ€è¦å…ˆè¿è¡ŒHadoopã€‚ä¹‹åè¿è¡Œ `hive` æˆ–è€… `hive shell` å¯ä»¥è¿›å…¥Hive Shell

```
hive 

//or
 hive shell
 
 
hive>
```

### å¯è§†åŒ–å·¥å…· DbVisualizer

* [DbVisualizer Software](https://www.dbvis.com/download/11.0)
* [DbVisualizer User Guide](http://confluence.dbvis.com/display/UG110/Installing)
* [Installing a JDBC Driver](http://confluence.dbvis.com/display/UG110/Installing+a+JDBC+Driver)
* [Supported databases and JDBC drivers Download](https://www.dbvis.com/features/database-drivers/)
* [åœ¨macä¸ŠDbVisualizerå›¾å½¢åŒ–å®¢æˆ·ç«¯é…ç½®è¿æ¥Hive | Blog](https://juejin.im/post/5d04675051882518e845cb8f)
* [hive-jdbc-uber-jar | github](https://github.com/timveil/hive-jdbc-uber-jar/releases)




1. ä¸‹è½½ `dbvis_macos_11_0_jre.dmg` å¹¶æ‰§è¡Œå®‰è£…

2. ä¹Ÿå¯ä»¥ä¸‹è½½ `.tar.gz` åŒ…è¿›è¡Œå®‰è£… 

```
gunzip dbvis_unix_11_0.tar.gz
tar xf dbvis_unix_11_0.tar
```

3. ç‚¹å‡» Docker ä¸­ DbVisualizerå›¾æ ‡å¯åŠ¨ï¼Œæˆ–ä½¿ç”¨å¦‚ä¸‹è„šæœ¬å¯åŠ¨

```
DbVisualizer/dbvis.sh
```

4. ä» [hive-jdbc-uber-jar | github](https://github.com/timveil/hive-jdbc-uber-jar/releases) ä¸‹è½½ `hive-jdbc-uber-jar`ï¼Œæ”¾ç½®åˆ° `/Users/lbs/.dbvis/jdbc` è·¯å¾„ä¸‹ï¼Œå¹¶å¯¼å…¥åˆ° DbVisualizer é…ç½®ä¸­


5. åœ¨ DbVisualizer çš„åå¥½è®¾ç½®ä¸­çš„ `Specify overridden Java VM Prperties here` ä¸­æ·»åŠ å¦‚ä¸‹è®¾ç½®

```
-Dsun.security.krb5.debug=true
-Djavax.security.auth.useSubjectCredsOnly=false
```



## Hiveäº¤äº’å¼æ¨¡å¼ CLI 

è¿è¡Œ `hive` æˆ–è€… `hive shell` å¯ä»¥è¿›å…¥Hive Shellã€‚Hiveçš„äº¤äº’æ¨¡å¼éµå¾ªä¸‹è¿°è§„åˆ™ã€‚


1. `quit`,`exit`:  é€€å‡ºäº¤äº’å¼shell
2. `reset`: é‡ç½®é…ç½®ä¸ºé»˜è®¤å€¼
3. `set <key>=<value>` : ä¿®æ”¹ç‰¹å®šå˜é‡çš„å€¼(å¦‚æœå˜é‡åæ‹¼å†™é”™è¯¯ï¼Œä¸ä¼šæŠ¥é”™)
4. `set` :  è¾“å‡ºç”¨æˆ·è¦†ç›–çš„ hiveé…ç½®å˜é‡
5. `set -v` : è¾“å‡ºæ‰€æœ‰Hadoopå’ŒHiveçš„é…ç½®å˜é‡
6. `add FILE[S] *`, `add JAR[S] *`, `add ARCHIVE[S] *` : æ·»åŠ  ä¸€ä¸ªæˆ–å¤šä¸ª file, jar, archivesåˆ°åˆ†å¸ƒå¼ç¼“å­˜
7. `list FILE[S]`, `list JAR[S]`, `list ARCHIVE[S]` : è¾“å‡ºå·²ç»æ·»åŠ åˆ°åˆ†å¸ƒå¼ç¼“å­˜çš„èµ„æº
8. `list FILE[S] *`, `list JAR[S] *`,`list ARCHIVE[S] *` : æ£€æŸ¥ç»™å®šçš„èµ„æºæ˜¯å¦æ·»åŠ åˆ°åˆ†å¸ƒå¼ç¼“å­˜
9. `delete FILE[S] *`, `delete JAR[S] *`, `delete ARCHIVE[S] *` : ä»åˆ†å¸ƒå¼ç¼“å­˜åˆ é™¤æŒ‡å®šçš„èµ„æº
10. `! <command>` :  ä» Hive shell æ‰§è¡Œä¸€ä¸ª shell å‘½ä»¤
11. `dfs <dfs command>` :  ä» Hive shell æ‰§è¡Œä¸€ä¸ª dfs å‘½ä»¤
12. `<query string>` : æ‰§è¡Œä¸€ä¸ª Hive æŸ¥è¯¢ï¼Œç„¶åè¾“å‡ºç»“æœåˆ°æ ‡å‡†è¾“å‡º
13. `source FILE <filepath>`:  åœ¨ CLI é‡Œæ‰§è¡Œä¸€ä¸ª hive è„šæœ¬æ–‡ä»¶
14. `!clear;`: æ¸…é™¤å‘½ä»¤è¡Œ
15. `show tables;`ï¼š å±•ç¤ºæ•°æ®è¡¨
16. `desc tableName`ï¼šå±•ç¤ºä¸€ä¸ªæ•°æ®è¡¨çš„ç»“æ„




å’ŒSQLç±»ä¼¼ï¼ŒHiveQLä¸€èˆ¬æ˜¯å¤§å°å†™ä¸æ•æ„Ÿçš„ï¼ˆé™¤äº†å­—ç¬¦ä¸²æ¯”è¾ƒä»¥å¤–ï¼‰ï¼Œå› æ­¤ `show tables;` ç­‰åŒäº `SHOW TABLES;`ã€‚åˆ¶è¡¨ç¬¦ï¼ˆTabï¼‰ä¼šè‡ªåŠ¨è¡¥å…¨ Hive çš„å…³é”®å­—å’Œå‡½æ•°ã€‚


ä¸‹é¢ç»™å‡ºä¸€ä¸ªç®€å•çš„ Hive Shell æ“ä½œ Demoï¼Œè¯¦æƒ…å‚è€ƒ [Hiveå®‰è£…åŠä½¿ç”¨æ”»ç•¥ | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/hadoop-hive-intro/)ã€‚


* åˆ›å»ºæœ¬åœ°æ•°æ®æ–‡ä»¶(æ–‡æœ¬ä»¥tabåˆ†éš”)

```
~ vi /home/cos/demo/t_hive.txt

16      2       3
61      12      13
41      2       31
17      21      3
71      2       31
1       12      34
11      2       34
```

* è¿›å…¥Hive Shellï¼Œåˆ›å»ºæ–°è¡¨

```
#åˆ›å»ºæ–°è¡¨
hive> CREATE TABLE t_hive (a int, b int, c int) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
OK
Time taken: 0.489 seconds
```


* æŸ¥çœ‹è¡¨

```
hive> show tables;
OK
t_hive
Time taken: 0.099 seconds
```


* æ­£åˆ™åŒ¹é…è¡¨å

```
hive>show tables '*t*';
OK
t_hive
Time taken: 0.065 seconds
```


* æŸ¥çœ‹è¡¨æ•°æ®

```
hive> select * from t_hive;
OK
16      2       3
61      12      13
41      2       31
17      21      3
71      2       31
1       12      34
11      2       34
Time taken: 0.264 seconds
```

* æŸ¥çœ‹è¡¨ç»“æ„

```
hive> desc t_hive;
OK
a       int
b       int
c       int
Time taken: 0.1 seconds
```
* ä¿®æ”¹è¡¨ï¼Œå¢åŠ ä¸€ä¸ªå­—æ®µ

```
hive> ALTER TABLE t_hive ADD COLUMNS (new_col String);
OK
Time taken: 0.186 seconds
hive> desc t_hive;
OK
a       int
b       int
c       int
new_col string
Time taken: 0.086 seconds
```


* åˆ é™¤è¡¨

```
hive> DROP TABLE t_hadoop;
OK
Time taken: 0.767 seconds

hive> show tables;
OK
Time taken: 0.064 seconds
```


## Beeline

### HiveServer2

Hive å†…ç½®äº† `HiveServer` å’Œ `HiveServer2` æœåŠ¡ï¼Œä¸¤è€…éƒ½å…è®¸å®¢æˆ·ç«¯ä½¿ç”¨å¤šç§ç¼–ç¨‹è¯­è¨€è¿›è¡Œè¿æ¥ï¼Œä½†æ˜¯ HiveServer ä¸èƒ½å¤„ç†å¤šä¸ªå®¢æˆ·ç«¯çš„å¹¶å‘è¯·æ±‚ï¼Œæ‰€ä»¥äº§ç”Ÿäº† `HiveServer2`ã€‚

`HiveServer2`ï¼ˆ`HS2`ï¼‰å…è®¸è¿œç¨‹å®¢æˆ·ç«¯å¯ä»¥ä½¿ç”¨å„ç§ç¼–ç¨‹è¯­è¨€å‘ Hive æäº¤è¯·æ±‚å¹¶æ£€ç´¢ç»“æœï¼Œæ”¯æŒå¤šå®¢æˆ·ç«¯å¹¶å‘è®¿é—®å’Œèº«ä»½éªŒè¯ã€‚HS2 æ˜¯ç”±å¤šä¸ªæœåŠ¡ç»„æˆçš„å•ä¸ªè¿›ç¨‹ï¼Œå…¶åŒ…æ‹¬åŸºäº Thrift çš„ Hive æœåŠ¡ï¼ˆTCP æˆ– HTTPï¼‰å’Œç”¨äº Web UI çš„ Jetty Web æœåŠ¡å™¨ã€‚

HiveServer2 æ‹¥æœ‰è‡ªå·±çš„ CLI(`Beeline`)ï¼ŒBeeline æ˜¯ä¸€ä¸ªåŸºäº SQLLine çš„ JDBC å®¢æˆ·ç«¯ã€‚ç”±äº HiveServer2 æ˜¯ Hive å¼€å‘ç»´æŠ¤çš„é‡ç‚¹ (Hive0.15 åå°±ä¸å†æ”¯æŒ hiveserver)ï¼Œæ‰€ä»¥ Hive CLI å·²ç»ä¸æ¨èä½¿ç”¨äº†ï¼Œå®˜æ–¹æ›´åŠ æ¨èä½¿ç”¨ Beelineã€‚

* [Hive CLI å’Œ Beeline å‘½ä»¤è¡Œçš„åŸºæœ¬ä½¿ç”¨](https://juejin.im/post/5d8593905188254009777049)


### Beeline å‚æ•°

Beeline æ‹¥æœ‰æ›´å¤šå¯ä½¿ç”¨å‚æ•°ï¼Œå¯ä»¥ä½¿ç”¨ `beeline --help` æŸ¥çœ‹ï¼Œå®Œæ•´å‚æ•°å¦‚ä¸‹

```
    // ...
    // ...
    
   Example:
    1. Connect using simple authentication to HiveServer2 on localhost:10000
    $ beeline -u jdbc:hive2://localhost:10000 username password

    2. Connect using simple authentication to HiveServer2 on hs.local:10000 using -n for username and -p for password
    $ beeline -n username -p password -u jdbc:hive2://hs2.local:10012

    3. Connect using Kerberos authentication with hive/localhost@mydomain.com as HiveServer2 principal
    $ beeline -u "jdbc:hive2://hs2.local:10013/default;principal=hive/localhost@mydomain.com"

    4. Connect using SSL connection to HiveServer2 on localhost at 10000
    $ beeline "jdbc:hive2://localhost:10000/default;ssl=true;sslTrustStore=/usr/local/truststore;trustStorePassword=mytruststorepassword"

    5. Connect using LDAP authentication
    $ beeline -u jdbc:hive2://hs2.local:10013/default <ldap-username> <ldap-password>
```


åœ¨ Hive CLI ä¸­æ”¯æŒçš„å‚æ•°ï¼ŒBeeline éƒ½æ”¯æŒï¼Œå¸¸ç”¨çš„å‚æ•°å¦‚ä¸‹ã€‚æ›´å¤šå‚æ•°è¯´æ˜å¯ä»¥å‚è§å®˜æ–¹æ–‡æ¡£ [Beeline Command Options](https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline%E2%80%93NewCommandLineShell)ã€‚



| å‚æ•° | è¯´æ˜ |
| --- | --- |
| -u <database URL>	 | æ•°æ®åº“åœ°å€ |
| -n <username> | ç”¨æˆ·å |
| -p <password> | å¯†ç  |
| -d <driver class> | é©±åŠ¨ (å¯é€‰) |
| -e <query> | æ‰§è¡Œ SQL å‘½ä»¤ |
| -f <file> | æ‰§è¡Œ SQL è„šæœ¬ |


ä¾‹å¦‚ï¼Œä½¿ç”¨ç”¨æˆ·åå’Œå¯†ç è¿æ¥ Hive

```
// $ beeline -u jdbc:hive2://localhost:10000  -n username -p password 
$ beeline -u jdbc:hive2://localhost:10000  -n hive -p Hive113459... 
```

## Ambari

* [Ambari User Guide](http://ambari.apache.org/1.2.2/installing-hadoop-using-ambari/content/index.html)
* [Ambariâ€”â€”å¤§æ•°æ®å¹³å°çš„æ­å»ºåˆ©å™¨](https://www.ibm.com/developerworks/cn/opensource/os-cn-bigdata-ambari/index.html)
* [Ambariâ€”â€”å¤§æ•°æ®å¹³å°çš„æ­å»ºåˆ©å™¨ä¹‹è¿›é˜¶ç¯‡](https://www.ibm.com/developerworks/cn/opensource/os-cn-bigdata-ambari2/)

å’ŒHiveè¿›è¡Œäº¤äº’çš„æ–¹å¼ä¸»è¦æœ‰2ç§ï¼šå‘½ä»¤è¡Œå’ŒAmbariè§†å›¾ã€‚

å°± Ambari çš„ä½œç”¨æ¥è¯´ï¼Œå°±æ˜¯åˆ›å»ºã€ç®¡ç†ã€ç›‘è§† Hadoop çš„é›†ç¾¤ï¼Œä½†æ˜¯è¿™é‡Œçš„ Hadoop æ˜¯å¹¿ä¹‰ï¼ŒæŒ‡çš„æ˜¯ Hadoop æ•´ä¸ªç”Ÿæ€åœˆï¼ˆä¾‹å¦‚ Hiveï¼ŒHbaseï¼ŒSqoopï¼ŒZookeeper ç­‰ï¼‰ï¼Œè€Œå¹¶ä¸ä»…æ˜¯ç‰¹æŒ‡ Hadoopã€‚ç”¨ä¸€å¥è¯æ¥è¯´ï¼ŒAmbari å°±æ˜¯ä¸ºäº†è®© Hadoop ä»¥åŠç›¸å…³çš„å¤§æ•°æ®è½¯ä»¶æ›´å®¹æ˜“ä½¿ç”¨çš„ä¸€ä¸ªå·¥å…·ã€‚

Ambari è‡ªèº«ä¹Ÿæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æ¶æ„çš„è½¯ä»¶ï¼Œä¸»è¦ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š`Ambari Server` å’Œ `Ambari Agent`ã€‚ç®€å•æ¥è¯´ï¼Œ
* ç”¨æˆ·é€šè¿‡ Ambari Server é€šçŸ¥ Ambari Agent å®‰è£…å¯¹åº”çš„è½¯ä»¶
* Agent ä¼šå®šæ—¶åœ°å‘é€å„ä¸ªæœºå™¨æ¯ä¸ªè½¯ä»¶æ¨¡å—çš„çŠ¶æ€ç»™ Ambari Server
* æœ€ç»ˆè¿™äº›çŠ¶æ€ä¿¡æ¯ä¼šå‘ˆç°åœ¨ Ambari çš„ GUIï¼Œæ–¹ä¾¿ç”¨æˆ·äº†è§£åˆ°é›†ç¾¤çš„å„ç§çŠ¶æ€ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„ç»´æŠ¤

## Hiveå®æˆ˜Demo
* [Hiveå¯¼å…¥10Gæ•°æ®çš„æµ‹è¯• | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/hadoop-hive-10g/)
* [ç”¨RHiveä»å†å²æ•°æ®ä¸­æå–é€†å›è´­ä¿¡æ¯ | ç²‰ä¸æ—¥å¿—](http://blog.fens.me/finance-rhive-repurchase/)
* [ç½‘ç«™æ—¥å¿—ç»Ÿè®¡æ¡ˆä¾‹åˆ†æä¸å®ç° | blog](https://www.cnblogs.com/smartloli/p/4272705.html)



## Hiveæ¶æ„

å°½ç®¡Hiveä½¿ç”¨èµ·æ¥ç±»ä¼¼SQLï¼Œä½†å®ƒä»ç„¶ä¸æ˜¯SQLï¼Œå°¤å…¶ä½“ç°åœ¨å¤„ç†é€Ÿåº¦æ–¹é¢ã€‚åº•å±‚çš„HiveæŸ¥è¯¢ä»ç„¶æ˜¯ä»¥ MapReduce ä½œä¸šçš„å½¢å¼è¿è¡Œã€‚MapReduceæ˜¯æ‰¹å¤„ç†ï¼Œè€ŒSQLåˆ™æ˜¯ä¸€ç§äº¤äº’å¼å¤„ç†è¯­éŸ³ã€‚


### HCatalog
HCatalog æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å…ƒæ•°æ®æœåŠ¡ï¼Œå…è®¸ä¸åŒçš„å·¥å…·å¦‚ Pigã€MapReduce ç­‰é€šè¿‡ HCatalog ç›´æ¥è®¿é—®å­˜å‚¨åœ¨ HDFS ä¸Šçš„åº•å±‚æ–‡ä»¶ã€‚

HCatalog æœ¬è´¨ä¸Šæ˜¯æ•°æ®è®¿é—®å·¥å…·ï¼ˆå¦‚Hiveæˆ–Pigï¼‰å’Œåº•å±‚æ–‡ä»¶ä¹‹é—´çš„æŠ½è±¡å±‚ã€‚



## Hive æ•°æ®ç±»å‹

* [User Documentation - Apache Hive](https://cwiki.apache.org/confluence/display/Hive#Home-UserDocumentation)

### åŸºæœ¬æ•°æ®ç±»å‹
*  tinyint/smallint/int/bigintï¼šæ•´æ•°ç±»å‹
*  float/doubleï¼šæµ®ç‚¹æ•°ç±»å‹
*  booleanï¼šå¸ƒå°”ç±»å‹
*  stringï¼šå­—ç¬¦ä¸²ç±»å‹

`string` ç±»å‹ä¸‹åˆåŒ…æ‹¬ å˜é•¿å­—ç¬¦ä¸² `VARCHAR` å’Œ å®šé•¿å­—ç¬¦ä¸² `CHAR`ã€‚ä¸‹é¢ç»™å‡ºä¾‹å­ï¼Œè¯´æ˜ä¸¤è€…åŒºåˆ«

```
hive > create table test1
     > (vname varchar(20), cname char(20));
     > desc test1;
     
vname   varchar(20)
cname   char(20)
```

ä¸Šè¿°ä¾‹å­ä¸­ï¼Œ`varchar(20)` è¡¨ç¤ºæœ€å¤§é•¿åº¦ä¸º20ï¼Œå®é™…é•¿åº¦å¯èƒ½ä¸è¶³20ã€‚`char(20)` è¡¨ç¤ºé•¿åº¦å›ºå®šä¸º20ã€‚


### å¤æ‚æ•°æ®ç±»å‹
* Arrayï¼šæ•°ç»„ï¼Œç”±ä¸€ç³»åˆ—ç›¸åŒæ•°æ®ç±»å‹çš„å…ƒç´ ç»„æˆ
* Mapï¼šé›†åˆï¼ŒåŒ…å« `key->value` é”®å€¼å¯¹ï¼Œå¯ä»¥é€šè¿‡ `key` æ¥è®¿é—®å…ƒç´ 
* Structï¼šç»“æ„ç±»å‹ï¼Œå¯ä»¥åŒ…å«ä¸åŒæ•°æ®ç±»å‹çš„å…ƒç´ ï¼Œè¿™äº›å…ƒç´ å¯ä»¥é€šè¿‡ â€œç‚¹è¯­æ³•â€ çš„æ–¹å¼è®¿é—®


```
hive> create table student
    > (sid int,
    > sname string,
    > grade1 array<float>,
    > grade2 map<string,float>
    > info struct<name:string, age:int>);
OK
Time taken: 0.246 seconds

hive> desc student;
OK
sid                 	int
sname               	string
grade1               	array<float>
grade2                  map<string,float>
info                    struct<name:string, age:int>
Time taken: 0.077 seconds, Fetched: 5 row(s)
```


### æ—¶é—´ç±»å‹
* Dateï¼šä» Hive 0.12.0 å¼€å§‹æ”¯æŒ
* Timestampï¼šä» Hive 0.8.0 å¼€å§‹æ”¯æŒ




## Hive æ–‡ä»¶æ ¼å¼

Hive æ”¯æŒ4ç§æ–‡ä»¶æ ¼å¼
1. `TextFile` ï¼ˆé»˜è®¤æ ¼å¼ï¼‰ï¼šåŸºäºè¡Œåˆ—æ··åˆçš„æ€æƒ³
2. `SequenceFile` ï¼šåŸºäºè¡Œå­˜å‚¨
3. `RCFile` ï¼šåŸºäºè¡Œå­˜å‚¨
4. è‡ªå®šä¹‰



åŸºäº HDFS çš„è¡Œå­˜å‚¨å…·å¤‡å¿«é€Ÿæ•°æ®åŠ è½½å’ŒåŠ¨æ€è´Ÿè½½çš„é«˜é€‚åº”èƒ½åŠ›ï¼Œå› ä¸ºè¡Œå­˜å‚¨ä¿è¯äº†ç›¸åŒè®°å½•çš„æ‰€æœ‰åŸŸéƒ½åœ¨åŒä¸€ä¸ªé›†ç¾¤èŠ‚ç‚¹ã€‚ä½†æ˜¯å®ƒä¸èƒ½æ»¡è¶³å¿«é€Ÿçš„æŸ¥è¯¢å“åº”æ—¶é—´çš„è¦æ±‚ï¼Œå› ä¸ºå½“æŸ¥è¯¢ä»…ä»…é’ˆå¯¹æ‰€æœ‰åˆ—ä¸­çš„å°‘æ•°å‡ åˆ—æ—¶ï¼Œä»–å°±ä¸èƒ½è·³è¿‡ä¸éœ€è¦çš„åˆ—ï¼Œç›´æ¥å®šä½åˆ°æ‰€éœ€çš„åˆ—ã€‚æ­¤å¤–ï¼Œè¡Œå­˜å‚¨ä¹Ÿä¸æ˜“è·å¾—ä¸€ä¸ªè¾ƒé«˜çš„å‹ç¼©æ¯”ã€‚


### TextFile
TextFile æ˜¯é»˜è®¤æ ¼å¼ï¼Œæ•°æ®ä¸åšå‹ç¼©ï¼Œç£ç›˜å¼€é”€å¤§ï¼Œæ•°æ®è§£æå¼€é”€å¤§ã€‚å¯ç»“åˆ Gzipï¼ŒBzip2ä½¿ç”¨ã€‚ä½†ä½¿ç”¨è¿™æ–¹å¼ï¼ŒHive ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œåˆ‡åˆ†ï¼Œä»è€Œæ— æ³•å¯¹æ•°æ®è¿›è¡Œå¹¶è¡Œæ“ä½œã€‚


### SequenceFile

SequenceFile æ˜¯Hadoop API æä¾›çš„ä¸€ç§äºŒè¿›åˆ¶æ–‡ä»¶æ”¯æŒï¼Œå…¶å…·æœ‰ä½¿ç”¨æ–¹ä¾¿ï¼Œå¯åˆ†å‰²ï¼Œå¯å‹ç¼©çš„ç‰¹ç‚¹ã€‚ SequenceFile æ”¯æŒä¸‰ç§å‹ç¼©é€‰æ‹©ï¼š`NONE`, `RECORD`, `BLOCK`ã€‚`RECORD` å‹ç¼©ç‡è¾ƒä½ï¼Œä¸€èˆ¬å»ºè®®ä½¿ç”¨ `BLOCK` å‹ç¼©ã€‚


### RCFile

RCFile æ˜¯ Facebook å¼€å‘çš„ä¸€ä¸ªé›†è¡Œå­˜å‚¨å’Œåˆ—å­˜å‚¨çš„ä¼˜ç‚¹äºä¸€èº«ï¼Œå‹ç¼©æ¯”æ›´é«˜ï¼Œè¯»å–åˆ—æ›´å¿«ã€‚

RCFile å­˜å‚¨ç»“æ„éµå¾ªâ€œå…ˆæ°´å¹³åˆ’åˆ†ï¼Œå†å‚ç›´åˆ’åˆ†â€çš„è®¾è®¡ç†å¿µã€‚RCFileä¿è¯åŒä¸€è¡Œçš„æ•°æ®ä½äºåŒä¸€èŠ‚ç‚¹ï¼Œå› æ­¤å…ƒç»„é‡æ„çš„å¼€é”€å¾ˆä½ã€‚å…¶æ¬¡ï¼Œåƒåˆ—å­˜å‚¨ä¸€æ ·ï¼ŒRCFile èƒ½å¤Ÿåˆ©ç”¨åˆ—ç»´åº¦çš„æ•°æ®å‹ç¼©ï¼Œå¹¶ä¸”èƒ½è·³è¿‡ä¸å¿…è¦çš„åˆ—è¯»å–ã€‚


> åœ¨ RC File çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æ”¹è¿›ï¼Œå¼•å…¥äº† ORC ï¼ˆ`Optimized Record Columnar`ï¼‰ï¼ŒORC ä¸»è¦åœ¨å‹ç¼©ç¼–ç ã€æŸ¥è¯¢æ€§èƒ½ä¸Šè¿›è¡Œäº†å‡çº§ã€‚

### è‡ªå®šä¹‰æ–‡ä»¶æ ¼å¼

å½“ç”¨æˆ·çš„æ•°æ®æ–‡ä»¶æ ¼å¼ä¸èƒ½è¢«å½“å‰Hiveè¯†åˆ«çš„æ—¶å€™ï¼Œå¯ä»¥è‡ªå®šä¹‰æ–‡ä»¶æ ¼å¼ï¼Œé€šè¿‡å®ç° `InputFormat` å’Œ `OutputFormat` è‡ªå®šä¹‰è¾“å…¥/è¾“å‡ºæ ¼å¼ã€‚


## Hiveçš„æ•°æ®å­˜å‚¨

Hive çš„å­˜å‚¨æ˜¯å»ºç«‹åœ¨ Hadoop æ–‡ä»¶ç³»ç»Ÿä¹‹ä¸Šçš„ã€‚Hive æœ¬èº«æ²¡æœ‰ä¸“é—¨çš„æ•°æ®å­˜å‚¨æ ¼å¼ï¼Œä¹Ÿä¸èƒ½ä¸ºæ•°æ®å»ºç«‹ç´¢å¼•ï¼Œå› æ­¤ç”¨æˆ·å¯ä»¥éå¸¸è‡ªç”±åœ°ç»„ç»‡ Hive ä¸­çš„è¡¨ï¼Œåªéœ€è¦åœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘Šè¯‰ Hive æ•°æ®ä¸­çš„åˆ—åˆ†éš”ç¬¦å°±å¯ä»¥è§£ææ•°æ®äº†ã€‚

ä¾‹å¦‚ï¼Œæ‰“å¼€ `http://localhost:50070/`ï¼Œé€‰æ‹©é¡¶éƒ¨åˆ†ç±»æ ä¸­çš„ `Utilities -> Browse the file system`ï¼Œå¯ä»¥æŸ¥çœ‹åˆ° Hive ä¸­åˆ›å»ºçš„æ•°æ®åº“è¡¨å¯¹åº”çš„æ–‡ä»¶ï¼ˆå­˜å‚¨åœ¨ `/user/hive/warehouse` è·¯å¾„ä¸‹ï¼‰ã€‚

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hadoop-hive-hdfs-1.png)

### Hiveçš„æ•°æ®æ¨¡å‹

Hive ä¸­ä¸»è¦åŒ…æ‹¬ 4 ç§æ•°æ®æ¨¡å‹
1. è¡¨ï¼ˆTableï¼‰
2. å¤–éƒ¨è¡¨ï¼ˆExternal Tableï¼‰
3. åˆ†åŒºï¼ˆPartitionï¼‰
4. æ¡¶ï¼ˆBucketï¼‰

Hive çš„è¡¨å’Œæ•°æ®åº“ä¸­çš„è¡¨åœ¨æ¦‚å¿µä¸Šæ²¡æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Œåœ¨ Hive ä¸­æ¯ä¸ªè¡¨éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„å­˜å‚¨ç›®å½•ã€‚è€Œå¤–éƒ¨è¡¨æŒ‡å‘å·²ç»åœ¨ HDFS ä¸­å­˜åœ¨çš„æ•°æ®ï¼Œä¹Ÿå¯ä»¥åˆ›å»ºåˆ†åŒºã€‚

Hive ä¸­çš„æ¯ä¸ªåˆ†åŒºéƒ½å¯¹åº”æ•°æ®åº“ä¸­ç›¸åº”åˆ†åŒºåˆ—çš„ä¸€ä¸ªç´¢å¼•ï¼Œä½†æ˜¯å…¶å¯¹åˆ†åŒºçš„ç»„ç»‡æ–¹å¼å’Œä¼ ç»Ÿå…³ç³»æ•°æ®åº“ä¸åŒã€‚

æ¡¶åœ¨æŒ‡å®šåˆ—è¿›è¡Œ Hash è®¡ç®—æ—¶ï¼Œä¼šæ ¹æ®å“ˆå¸Œå€¼åˆ‡åˆ†æ•°æ®ï¼Œä½¿æ¯ä¸ªæ¡¶å¯¹åº”ä¸€ä¸ªæ–‡ä»¶ã€‚



#### è¡¨
è¡¨å¯ä»¥ç»†åˆ†ä¸º
1. Table å†…éƒ¨è¡¨
2. Partition åˆ†åŒºè¡¨
3. External Table å¤–éƒ¨è¡¨
4. Bucket Table æ¡¶è¡¨


#### è§†å›¾ View

* è§†å›¾æ˜¯ä¸€ç§è™šè¡¨ï¼Œæ˜¯ä¸€ä¸ªé€»è¾‘æ¦‚å¿µï¼ŒHive æš‚ä¸æ”¯æŒç‰©åŒ–è§†å›¾
* è§†å›¾å¯ä»¥è·¨è¶Šå¤šå¼ è¡¨
* è§†å›¾å»ºç«‹åœ¨å·²æœ‰è¡¨çš„åŸºç¡€ä¸Šï¼Œè§†å›¾èµ–ä»¥å»ºç«‹çš„è¿™äº›è¡¨ç§°ä¸ºåŸºè¡¨
* è§†å›¾å¯ä»¥ç®€åŒ–å¤æ‚çš„æŸ¥è¯¢
* è§†å›¾ VIEW æ˜¯åªè¯»çš„ï¼Œä¸æ”¯æŒ `LOAD/INSERT/ALTER`ã€‚å¯ä»¥ä½¿ç”¨ `ALTER VIEW` æ”¹å˜ VIEW å®šä¹‰
* Hive æ”¯æŒè¿­ä»£è§†å›¾






## Hive æ•°æ®æ“ä½œ

> åœ¨æ‰§è¡Œæ“ä½œå‰ï¼Œè¯·ç¡®ä¿ `localhost:50070` é¡µé¢è®¿é—®åˆ°çš„ `Live Node` ä¸ªæ•°å¤§äº0ã€‚


### å‘è¡¨ä¸­è£…è½½æ•°æ®
* [Hiveä¹‹å¯¼å…¥å¤–éƒ¨æ•°æ® | CSDN](https://blog.csdn.net/jclian91/article/details/78481673)
* [Hive å†™å…¥æ•°æ®åˆ°Hiveè¡¨(å‘½ä»¤è¡Œ)](http://www.tracefact.net/tech/067.html)
* [ä¸€èµ·å­¦Hiveâ€”â€”è¯¦è§£å››ç§å¯¼å…¥æ•°æ®çš„æ–¹å¼ | blog](http://www.bigdata17.com/2018/10/07/hiveimportdata.html)




#### Demo-Insertæ’å…¥æ•°æ® 

1. åˆ›å»º `hiveDemo` æ•°æ®åº“å¹¶ä½¿ç”¨è¯¥æ•°æ®åº“

```
create datbase IF NOT EXISTS hiveDemo;
show databases;
use hiveDemo;
```

2. å»ºè¡¨/æŸ¥çœ‹/åˆ é™¤ æ•°æ®è¡¨


```
hive> Create Table golds_log(user_id bigint, accounts string, change_type string, golds bigint, log_time int);

hive> show tables;

hive> drop table golds_log;

hive> desc golds_log;
```

3. ä½¿ç”¨ `Insert...Values` è¯­å¥å†™å…¥æ•°æ®

```
hive> Insert into table golds_log values
(3645356,'wds7654321(4171752)','æ–°äººæ³¨å†Œå¥–åŠ±',1700,1526027152),
(2016869,'dqyx123456789(2376699)','å‚åŠ ä¸€åœºæ¯”èµ›',1140,1526027152),
(3630468,'dke3776611(4156064)','å¤§è½¬ç›˜å¥–åŠ±',1200,1526027152),
(995267,'a254413189(1229417)','å¦å¦æ‹¼åç¿»ç‰Œ',200,1526027152),
(795276,'li8762866(971402)','å¦å¦æ‹¼åç¿»ç‰Œ',1200,1526027152);
```



æ­£å¸¸æƒ…å†µä¸‹å¯ä»¥çœ‹åˆ°ä¸‹é¢çš„ç»“æœè¾“å‡ºï¼Œè¯´æ˜åœ¨æ‰§è¡Œ `Insert...values` è¯­å¥æ—¶ï¼Œåº•å±‚æ˜¯åœ¨æ‰§è¡Œ MapReduce ä½œä¸šã€‚



```
Query ID = lbs_20200422053833_55b98d5a-ba4c-470d-909a-098213d1d937
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1587504428431_0001, Tracking URL = http://localhost:8088/proxy/application_1587504428431_0001/
Kill Command = /Library/hadoop-2.10.0/bin/mapred job  -kill job_1587504428431_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-04-22 05:39:14,966 Stage-1 map = 0%,  reduce = 0%
2020-04-22 05:39:21,154 Stage-1 map = 100%,  reduce = 0%
2020-04-22 05:39:27,296 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1587504428431_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://localhost:9000/user/hive/warehouse/hivedemo.db/golds_log/.hive-staging_hive_2020-04-22_05-38-33_916_330193107719508203-1/-ext-10000
Loading data to table hivedemo.golds_log
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   HDFS Read: 20647 HDFS Write: 764 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 54.82 seconds
```




æ­¤æ—¶åœ¨ `http://localhost:50070/` é¡µé¢æŸ¥çœ‹ `Utillities -> Browser the file system`ï¼Œåœ¨ `/user/hive/warehouse/hivedemo.db/golds_log` è·¯å¾„ä¸‹å¯ä»¥çœ‹åˆ°ä¸€ä¸ª `000000_0` çš„æ–‡ä»¶ï¼Œä¸‹è½½åˆ°æœ¬åœ°ï¼ŒæŸ¥çœ‹å…¶å†…å®¹ä¸º


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hadoop-namenode-manage-web-1.png)

```
3645356 wds7654321(4171752) æ–°äººæ³¨å†Œå¥–åŠ± 1700 1526027152
2016869 dqyx123456789(2376699) å‚åŠ ä¸€åœºæ¯”èµ› 1140 1526027152
3630468 dke3776611(4156064) å¤§è½¬ç›˜å¥–åŠ± 1200 1526027152
995267 a254413189(1229417) å¦å¦æ‹¼åç¿»ç‰Œ 200 1526027152
795276 li8762866(971402) å¦å¦æ‹¼åç¿»ç‰Œ 1200 1526027152
```

> `000000_0` æ–‡ä»¶æ˜¯ä¸€ä¸ªæ™®é€šçš„æ–‡æœ¬æ–‡ä»¶ï¼ˆHiveä¸­é»˜è®¤çš„æ–‡ä»¶å­˜å‚¨æ ¼å¼ï¼‰ï¼Œå¯ä»¥ç”¨ VSCode æ‰“å¼€ã€‚


4. ç»§ç»­æ‰§è¡Œ2æ¬¡ `Insert...values` å‘½ä»¤ï¼Œå†æ¬¡è®¿é—® `http://localhost:50070/explorer.html#/user/hive/warehouse/hivedemo.db/golds_log` é¡µé¢ï¼Œå¯ä»¥å‘ç°æœ‰3ä¸ªæ–‡ä»¶ï¼Œå³**æ¯æ¬¡ä»»åŠ¡éƒ½ç”Ÿæˆäº†å•ç‹¬çš„æ•°æ®æ–‡ä»¶ã€‚**


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hadoop-namenode-manage-web-2.png)

**Hiveä¸­ï¼Œæ¯æ¬¡æ‰§è¡Œ `Insert` è¯­å¥ï¼ˆåº•å±‚æ‰§è¡Œ MapReduce ä»»åŠ¡ï¼‰éƒ½ä¼šç”Ÿæˆç‹¬ç«‹çš„æ•°æ®æ–‡ä»¶ã€‚å¯¹äº HDFS æ¥è¯´ï¼Œä¼˜åŠ¿æ˜¯å­˜å‚¨å°‘é‡å¤§æ–‡ä»¶ï¼Œä¸æ˜¯å­˜å‚¨å¤§é‡å°æ–‡ä»¶ã€‚**

è€Œå¯¹äºæˆ‘ä»¬çš„åº”ç”¨è€Œè¨€ï¼Œæ¯ 10 åˆ†é’Ÿå°±ä¼šåŒæ­¥ä¸€æ¬¡æ•°æ®åˆ° Hive ä»“åº“ï¼Œå¦‚æ­¤ä¸€æ¥ä¼šç”Ÿæˆæ— æ•°çš„å°æ–‡ä»¶ï¼Œç³»ç»Ÿçš„è¿è¡Œé€Ÿåº¦ä¼šè¶Šæ¥è¶Šæ…¢ã€‚æ‰€ä»¥ç¬¬ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼šå¦‚ä½•åˆå¹¶å°æ–‡ä»¶ï¼Ÿ


#### Demo-åˆå¹¶æ•°æ®åº“å°æ–‡ä»¶

åœ¨å»ºè¡¨çš„æ—¶å€™ï¼Œæˆ‘ä»¬æ²¡æœ‰æŒ‡å®šè¡¨å­˜å‚¨çš„æ–‡ä»¶ç±»å‹ï¼ˆ`file format`ï¼‰ï¼Œé»˜è®¤çš„æ–‡ä»¶ç±»å‹æ˜¯ `Textfile`ï¼Œæ‰€ä»¥ï¼Œå½“æˆ‘ä»¬ä¸‹è½½ç”Ÿæˆçš„ `000000_0` æ–‡ä»¶åï¼Œä½¿ç”¨ç¼–è¾‘å™¨å¯ä»¥ç›´æ¥æŸ¥çœ‹å…¶å†…å®¹ã€‚

Hive æä¾›äº†ä¸€ä¸ª `ALTER TABLE table_name CONCATENATE` è¯­å¥ï¼Œç”¨äºåˆå¹¶å°æ–‡ä»¶ã€‚ä½†æ˜¯åªæ”¯æŒ `RCFILE` å’Œ `ORC`æ–‡ä»¶ç±»å‹ã€‚


å› æ­¤ï¼Œå¦‚æœæƒ³åˆå¹¶å°æ–‡ä»¶ï¼Œå¯ä»¥åˆ é™¤è¡¨ï¼Œç„¶åå†ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤é‡å»º


```
hive> drop table golds_log;
```

```
hive> Create Table golds_log(user_id bigint, accounts string, change_type string, golds bigint, log_time int)
STORED AS RCFile;
```



```
hive> Insert into table golds_log values
(3645356,'wds7654321(4171752)','æ–°äººæ³¨å†Œå¥–åŠ±',1700,1526027152),
(2016869,'dqyx123456789(2376699)','å‚åŠ ä¸€åœºæ¯”èµ›',1140,1526027152),
(3630468,'dke3776611(4156064)','å¤§è½¬ç›˜å¥–åŠ±',1200,1526027152),
(995267,'a254413189(1229417)','å¦å¦æ‹¼åç¿»ç‰Œ',200,1526027152),
(795276,'li8762866(971402)','å¦å¦æ‹¼åç¿»ç‰Œ',1200,1526027152);
```

é‡å¤ä¸Šé¢çš„è¿‡ç¨‹ï¼Œæ‰§è¡Œ 3 æ¬¡ `insert` è¯­å¥ï¼Œæ¯æ¬¡æ’å…¥ 5 æ¡æ•°æ®ã€‚åˆ·æ–° WebUIï¼Œä¼šçœ‹åˆ°å’Œå‰é¢ä¸€æ ·äº§ç”Ÿ 3 ä¸ªæ–‡ä»¶ã€‚

> Tip: å¦‚æœæ­¤æ—¶å†å°† `000000_0` æ–‡ä»¶ä¸‹è½½ä¸‹æ¥ï¼Œç”¨æ–‡æœ¬ç¼–è¾‘å™¨æˆ–è€… VSCode æ‰“å¼€æŸ¥çœ‹ï¼Œå‘ç°å·²ç»æ˜¯ä¹±ç äº†ã€‚å› ä¸ºå®ƒå·²ç»ä¸å†æ˜¯æ–‡æœ¬æ–‡ä»¶äº†ã€‚

æ¥ä¸‹æ¥ï¼Œæ‰§è¡Œä¸‹é¢çš„è¯­å¥ï¼Œå¯¹æ–‡ä»¶è¿›è¡Œåˆå¹¶

```
hive> alter table golds_log concatenate;
```

è¾“å‡ºç»“æœå¦‚ä¸‹

```
Starting Job = job_1587504428431_0006, Tracking URL = http://localhost:8088/proxy/application_1587504428431_0006/
Kill Command = /Library/hadoop-2.10.0/bin/mapred job  -kill job_1587504428431_0006
Hadoop job information for null: number of mappers: 1; number of reducers: 0
2020-04-22 06:10:40,875 null map = 0%,  reduce = 0%
2020-04-22 06:10:47,012 null map = 100%,  reduce = 0%
Ended Job = job_1587504428431_0006
Loading data to table hivedemo.golds_log
MapReduce Jobs Launched: 
Stage-null: Map: 1   HDFS Read: 3137 HDFS Write: 632 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 43.978 seconds
```



åˆ·æ–°WebUIï¼Œä¼šå‘ç°æ–‡ä»¶å·²ç»åˆå¹¶äº†ï¼Œåªæœ‰ä¸€ä¸ªæ–‡ä»¶å­˜åœ¨ã€‚

æœ€åï¼Œä½¿ç”¨ `SELECT` è¯­å¥æŸ¥çœ‹æ•°æ®è¡¨çš„å†…å®¹ã€‚

```
hive> select * from  golds_log;

OK
3645356	wds7654321(4171752)	æ–°äººæ³¨å†Œå¥–åŠ±	1700	1526027152
2016869	dqyx123456789(2376699)	å‚åŠ ä¸€åœºæ¯”èµ›	1140	1526027152
3630468	dke3776611(4156064)	å¤§è½¬ç›˜å¥–åŠ±	1200	1526027152
995267	a254413189(1229417)	å¦å¦æ‹¼åç¿»ç‰Œ	200	1526027152
795276	li8762866(971402)	å¦å¦æ‹¼åç¿»ç‰Œ	1200	1526027152
3645356	wds7654321(4171752)	æ–°äººæ³¨å†Œå¥–åŠ±	1700	1526027152
2016869	dqyx123456789(2376699)	å‚åŠ ä¸€åœºæ¯”èµ›	1140	1526027152
3630468	dke3776611(4156064)	å¤§è½¬ç›˜å¥–åŠ±	1200	1526027152
995267	a254413189(1229417)	å¦å¦æ‹¼åç¿»ç‰Œ	200	1526027152
795276	li8762866(971402)	å¦å¦æ‹¼åç¿»ç‰Œ	1200	1526027152
3645356	wds7654321(4171752)	æ–°äººæ³¨å†Œå¥–åŠ±	1700	1526027152
2016869	dqyx123456789(2376699)	å‚åŠ ä¸€åœºæ¯”èµ›	1140	1526027152
3630468	dke3776611(4156064)	å¤§è½¬ç›˜å¥–åŠ±	1200	1526027152
995267	a254413189(1229417)	å¦å¦æ‹¼åç¿»ç‰Œ	200	1526027152
795276	li8762866(971402)	å¦å¦æ‹¼åç¿»ç‰Œ	1200	1526027152
Time taken: 0.133 seconds, Fetched: 15 row(s)
```


#### Demo-Load å¯¼å…¥å¤–éƒ¨æ•°æ®

ä¸‹é¢ç»™å‡ºä¸€ä¸ªå®ä¾‹ï¼Œå¦‚ä½•å°†æœ¬åœ°æ•°æ®æ–‡ä»¶ `test.txt` å¯¼å…¥åˆ° Hive æ•°æ®è¡¨ä¸­ã€‚

1. æœ¬åœ°æ•°æ®æ–‡ä»¶ `test.txt` å†…å®¹å¦‚ä¸‹

```
3645356|wds7654321(4171752)|æ–°äººæ³¨å†Œå¥–åŠ±|1700|1526027152
2016869|dqyx123456789(2376699)|å‚åŠ ä¸€åœºæ¯”èµ›|1140|1526027152
3630468|dke3776611(4156064)|å¤§è½¬ç›˜å¥–åŠ±|1200|1526027152
3642022|é»‘å¨ƒ123456(4168266)|æ–°äººæ³¨å†Œå¥–åŠ±|500|1526027152
2016869|dqyx123456789(2376699)|å¤§è½¬ç›˜å¥–åŠ±|1500|1526027152
```

2. åˆ›å»ºæ•°æ®è¡¨ï¼Œä¸æœ¬åœ° `test.txt` çš„æ•°æ®ç±»å‹ä¸€è‡´


```
hive> Create Table golds_log(user_id bigint, accounts string, change_type string, golds bigint, log_time int)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|';
```
ä¸Šé¢æœ€é‡è¦çš„ä¸€å¥å°±æ˜¯ `ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'`ï¼Œè¯´æ˜è¡¨çš„å­—æ®µç”±ç¬¦å· `"|"` è¿›è¡Œåˆ†éš”ã€‚

> Tip: `test.txt` ä¸­åŒ…å«æœ‰ä¸­æ–‡ï¼Œç¡®ä¿æ–‡ä»¶æ ¼å¼æ˜¯ `utf-8`ï¼ˆ`GB2312` å¯¼å…¥åä¼šæœ‰ä¹±ç ï¼‰



3. æŸ¥çœ‹æ•°æ®è¡¨çš„ç»“æ„

```
describe golds_log;

describe formatted student1;
```

4. æŸ¥çœ‹æ•°æ®è¡¨å†…å®¹ï¼ˆæ­¤æ—¶ä¸ºç©ºï¼‰


```
select * from student1;
```

5. å¯¼å…¥æœ¬åœ°æ•°æ®


```
hive> load data local inpath '/Users/lbs/Downloads/test.txt' into table golds_log;

Loading data to table hivedemo.golds_log
OK
Time taken: 0.139 seconds
```

ä½ ä¼šå‘ç°ä½¿ç”¨ `load` è¯­å¥å†™å…¥æ•°æ®æ¯” `insert` è¯­å¥è¦å¿«è®¸å¤šå€ï¼Œå› ä¸º HIVE å¹¶ä¸å¯¹ `scheme` è¿›è¡Œæ ¡éªŒï¼Œä»…ä»…æ˜¯å°†æ•°æ®æ–‡ä»¶æŒªåˆ° HDFS ç³»ç»Ÿä¸Šï¼Œä¹Ÿæ²¡æœ‰æ‰§è¡Œ MapReduce ä½œä¸šã€‚æ‰€ä»¥ä»å¯¼å…¥æ•°æ®çš„è§’åº¦è€Œè¨€ï¼Œä½¿ç”¨ load è¦ä¼˜äºä½¿ç”¨ insert...valuesã€‚





6. å†æ¬¡æ•°æ®è¡¨å†…å®¹

```
hive> select * from golds_log;
OK
3645356	wds7654321(4171752)	æ–°äººæ³¨å†Œå¥–åŠ±	1700	1526027152
2016869	dqyx123456789(2376699)	å‚åŠ ä¸€åœºæ¯”èµ›	1140	1526027152
3630468	dke3776611(4156064)	å¤§è½¬ç›˜å¥–åŠ±	1200	1526027152
3642022	é»‘å¨ƒ123456(4168266)	æ–°äººæ³¨å†Œå¥–åŠ±	500	1526027152
2016869	dqyx123456789(2376699)	å¤§è½¬ç›˜å¥–åŠ±	1500	1526027152
Time taken: 0.087 seconds, Fetched: 5 row(s)
```


7. åå¤å¯¼å…¥ 3 æ¬¡åï¼Œæ‰“å¼€ Web UIï¼Œåˆ·æ–°åï¼Œå‘ç°å’Œä½¿ç”¨ Insert è¯­å¥æ—¶ä¸€æ ·ï¼Œæ¯æ¬¡ load è¯­å¥éƒ½ä¼šç”Ÿæˆä¸€ä¸ªæ•°æ®æ–‡ä»¶ï¼ŒåŒæ ·å­˜åœ¨å°æ–‡ä»¶çš„é—®é¢˜ã€‚

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/BigData2020/hadoop-namenode-manage-web-3.png)


å’Œå‰é¢çš„æ–¹æ³•ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¡¨çš„å­˜å‚¨ç±»å‹æ”¹ä¸º RCFileï¼Œç„¶åå†è¿›è¡Œåˆå¹¶ï¼Œä½†æ˜¯å› ä¸ºä½¿ç”¨ load è¯­å¥çš„æ—¶å€™ï¼Œè¦å¯¼å…¥çš„æ–‡ä»¶ç±»å‹æ˜¯ txtï¼Œå’Œè¡¨çš„å­˜å‚¨ç±»å‹ä¸ä¸€è‡´ï¼Œæ‰€ä»¥ä¼šæŠ¥é”™ã€‚

è¿™æ—¶å€™ï¼Œåªèƒ½æ›²çº¿æ•‘å›½äº†ï¼šå°†ä¸»è¡¨åˆ›å»ºä¸º RCFile ç±»å‹ï¼Œå†åˆ›å»ºä¸€å¼ ä¸´æ—¶è¡¨ï¼Œç±»å‹æ˜¯ Textfileï¼Œç„¶å load æ—¶å¯¼å…¥åˆ°ä¸´æ—¶è¡¨ï¼Œç„¶åå†ä½¿ç”¨ä¸‹ä¸€èŠ‚è¦ä»‹ç»çš„ `Insert...select` è¯­å¥ï¼Œå°†æ•°æ®ä»ä¸´æ—¶è¡¨å¯¼å…¥åˆ°ä¸»è¡¨ã€‚


#### Demo-ä½¿ç”¨ Insert...Select è¯­å¥å†™å…¥æ•°æ®

1. ä½¿ç”¨ä¸‹é¢çš„è¯­å¥åˆ›å»ºä¸€å¼ ä¸´æ—¶è¡¨ï¼Œä¸´æ—¶è¡¨çš„åç§°ä¸º `golds_log_tmp`ã€‚ä¸´æ—¶è¡¨åœ¨å½“å‰ä¼šè¯(`session`)ç»“æŸåä¼šè¢« HIVE è‡ªåŠ¨åˆ é™¤ï¼Œä¸´æ—¶è¡¨å¯ä»¥ä¿å­˜åœ¨SSDã€å†…å­˜æˆ–è€…æ˜¯æ–‡ä»¶ç³»ç»Ÿä¸Šã€‚

```
hive> Create TEMPORARY Table golds_log_tmp(user_id bigint, accounts string, change_type string, golds bigint, log_time int)
ROW FORMAT DELIMITED  FIELDS TERMINATED BY '|';
```

2. ä½¿ç”¨ä¸‹é¢çš„è¯­å¥åˆ›å»ºä¸»è¡¨


```
hive> drop table golds_log;
```

```
hive> Create Table golds_log(user_id bigint, accounts string, change_type string, golds bigint, log_time int)
STORED AS RCFile;
```

3. ä½¿ç”¨ä¸‹é¢çš„è¯­å¥å°†æ•°æ®å¯¼å…¥åˆ°ä¸´æ—¶è¡¨

```
hive> load data local inpath '/Users/lbs/Downloads/test.txt' into table golds_log_tmp;
```

4. ä½¿ç”¨insert...selectè¯­å¥å°†æ•°æ®ä»ä¸´æ—¶è¡¨è½¬ç§»åˆ°ä¸»è¡¨

```
hive> Insert into table golds_log select * from golds_log_tmp;

Query ID = lbs_20200422063734_475e168a-5016-4ba7-a67f-9c7f76373f98
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1587504428431_0007, Tracking URL = http://localhost:8088/proxy/application_1587504428431_0007/
Kill Command = /Library/hadoop-2.10.0/bin/mapred job  -kill job_1587504428431_0007
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-04-22 06:38:10,330 Stage-1 map = 0%,  reduce = 0%
2020-04-22 06:38:16,479 Stage-1 map = 100%,  reduce = 0%
2020-04-22 06:38:21,572 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1587504428431_0007
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://localhost:9000/user/hive/warehouse/hivedemo.db/golds_log/.hive-staging_hive_2020-04-22_06-37-34_112_939503175258871139-1/-ext-10000
Loading data to table hivedemo.golds_log
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   HDFS Read: 18494 HDFS Write: 794 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 48.647 seconds
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`insert...select` è¯­å¥åº•å±‚ä¹Ÿä¼šæ‰§è¡Œä¸€ä¸ª MapReduce ä½œä¸šï¼Œé€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢ã€‚


5. åœ¨å¤šæ¬¡æ‰§è¡Œ `insert...select` åï¼Œ`golds_log` ä¸‹ä»ç„¶ä¼šç”Ÿæˆå¤šä¸ªå°æ–‡ä»¶ï¼Œæ­¤æ—¶ï¼Œåªè¦æ‰§è¡Œä¸€ä¸‹åˆå¹¶å°æ–‡ä»¶çš„è¯­å¥å°±å¯ä»¥äº†

```
hive> alter table golds_log concatenate;
```



## Hive æ•°æ®æŸ¥è¯¢

### è¡¨æ“ä½œ
Hiveçš„æ•°æ®è¡¨åˆ†ä¸º2ç§ï¼šå†…éƒ¨è¡¨å’Œå¤–éƒ¨è¡¨
1. å†…éƒ¨è¡¨ï¼šHiveåˆ›å»ºå¹¶é€šè¿‡ LOAD DATA INPATH è¿›æ•°æ®åº“çš„è¡¨ï¼Œè¿™ç§è¡¨å¯ä»¥ç†è§£ä¸ºæ•°æ®å’Œè¡¨ç»“æ„éƒ½ä¿å­˜åœ¨ä¸€èµ·çš„æ•°æ®è¡¨ã€‚å½“é€šè¿‡ `DROP TABLE table_name` åˆ é™¤å…ƒæ•°æ®ä¸­è¡¨ç»“æ„çš„åŒæ—¶ï¼Œè¡¨ä¸­çš„æ•°æ®ä¹ŸåŒæ ·ä¼šä» HDFS ä¸­è¢«åˆ é™¤ã€‚
2. å¤–éƒ¨è¡¨ï¼šåœ¨è¡¨ç»“æ„åˆ›å»ºä»¥å‰ï¼Œæ•°æ®å·²ç»ä¿å­˜åœ¨HDFSä¸­ï¼Œé€šè¿‡åˆ›å»ºè¡¨ç»“æ„ï¼Œå°†æ•°æ®æ ¼å¼åŒ–åˆ°è¡¨çš„ç»“æ„é‡Œã€‚å½“é€šè¿‡ `DROP TABLE table_name` æ“ä½œçš„æ—¶å€™ï¼ŒHive ä»…ä»…åˆ é™¤å…ƒæ•°æ®çš„è¡¨ç»“æ„ï¼Œè€Œä¸åˆ é™¤HDFSä¸Šçš„æ–‡ä»¶ã€‚æ‰€ä»¥ï¼Œç›¸æ¯”å†…éƒ¨è¡¨ï¼Œå¤–éƒ¨è¡¨å¯ä»¥æ›´æ”¾å¿ƒåœ°å¤§èƒ†ä½¿ç”¨ã€‚


* **åˆ›å»ºè¡¨æ—¶ï¼Œ`LIKE` å…è®¸ç”¨æˆ·å¤åˆ¶ç°æœ‰çš„è¡¨ç»“æ„ï¼Œä½†ä¸æ˜¯å¤åˆ¶æ•°æ®**

```
LIKE existing_table_name
```

* åˆ›å»ºè¡¨æ—¶ï¼Œå¦‚æœæ–‡ä»¶æ•°æ®æ˜¯çº¯æ–‡æœ¬ï¼Œå¯ä»¥ä½¿ç”¨ `STORED AS TEXTFILE`ï¼ˆä¹Ÿæ˜¯é»˜è®¤çš„æ ¼å¼ï¼‰ã€‚å¦‚æœæ•°æ®éœ€è¦å‹ç¼©ï¼Œä½¿ç”¨ `STORED AS SEQUENCE` 
* 


* åˆ›å»ºè¡¨æ—¶ï¼Œä½¿ç”¨ `EXTERNAL` å£°æ˜å¤–éƒ¨è¡¨

```
CREATE EXTERNAL TABLE tablename IF NOT EXISTS tablename
```

* æ•°æ®è¡¨åœ¨åˆ é™¤æ—¶å€™ï¼Œå†…éƒ¨è¡¨ä¼šè¿æ•°æ®ä¸€èµ·åˆ é™¤ï¼Œè€Œå¤–éƒ¨è¡¨åªåˆ é™¤è¡¨ç»“æ„ï¼Œæ•°æ®è¿˜æ˜¯ä¿ç•™çš„ã€‚


```
DROP TABLE table_name
```

* åœ¨è¡¨æŸ¥è¯¢æ—¶å€™ï¼Œä½¿ç”¨ `ALL` å’Œ `DISTINCT` é€‰é¡¹åŒºåˆ†å¯¹é‡å¤è®°å½•çš„å¤„ç†ã€‚é»˜è®¤æ˜¯ `ALL`,è¡¨ç¤ºæŸ¥è¯¢æ‰€æœ‰è®°å½•ï¼Œ`DISTINCT` è¡¨ç¤ºå»æ‰é‡å¤çš„è®°å½•ã€‚

```
SELECT age, grade FROM table;
SELECT ALL age, grade FROM table;
SELECT DISTINCT age, grade FROM table;
```


* Hive ä¸æ”¯æŒ `HAVING` å­å¥ï¼Œå¯ä»¥å°† HAVING å­å¥è½¬åŒ–ä¸ºä¸€ä¸ªå­æŸ¥è¯¢ã€‚



```
//Hive ä¸æ”¯æŒ HAVING å­å¥
SELECT  col1 FROM table GROUP BY col1 HAVING SUM(col2) > 10;


//å¯ä»¥æ”¹ä¸ºä¸‹è¿°å­æŸ¥è¯¢æ ¼å¼  Hiveæ”¯æŒä¸‹è¿°å‘½å
SELECT  col1 FROM (SELECT col1, SUM(col2) AS col2 sum FROM table GROUP BU col1) table2 WHERE table2.col2sum > 10;
```

### è§†å›¾æ“ä½œ

è§†å›¾ VIEW æ˜¯åªè¯»çš„ï¼Œä¸æ”¯æŒ `LOAD/INSERT/ALTER`ã€‚å¯ä»¥ä½¿ç”¨ `ALTER VIEW` æ”¹å˜ VIEW å®šä¹‰


ä¸‹é¢ä»‹ç»ä¸‹è§†å›¾VIEWå¸¸è§çš„æ“ä½œè¯­å¥

* åˆ›å»º VIEW 

```
CREATE  VIEW [IF NOT EXISTS] view_name
```

* åˆ é™¤ VIEW 

```
DROP VIEW [IF EXISTS] view_name
```


### ç´¢å¼•æ“ä½œ

ç´¢å¼•æ˜¯æ ‡å‡†çš„æ•°æ®åº“æŠ€æœ¯ã€‚Hive 0.7 ç‰ˆæœ¬ä¹‹åæ”¯æŒç´¢å¼•ã€‚




### GROUP BY


#### GROUP BY 1 2 3

* [What does SQL clause â€œGROUP BY 1â€ mean? | StackOverflow](https://stackoverflow.com/questions/7392730/what-does-sql-clause-group-by-1-mean)


```
SELECT account_id, open_emp_id
         ^^^^        ^^^^
          1           2
          
FROM account
GROUP BY 1;
```

åœ¨ä¸Šè¿°ä¾‹å­ä¸­ï¼Œ`GROUP BY 1` ä¸­çš„ `1` æŒ‡çš„æ˜¯ `SELECT` è¯­å¥åé¢çš„ç¬¬ `1` ä¸ªåˆ—åï¼ˆ`coloumn`ï¼‰ã€‚ ä¸Šè¿°æŸ¥è¯¢è¯­å¥ï¼Œç­‰ä»·äºä¸‹è¿°æŸ¥è¯¢

```
SELECT account_id, open_emp_id
FROM account
GROUP BY account_id;
```

éœ€è¦æ³¨æ„çš„ï¼Œåœ¨ `GROUP BY 1 2 3 4 ... index` è¯­æ³•ä¸­ï¼Œåºå· `index` æ˜¯ä» 1 å¼€å§‹è®¡æ•°çš„ã€‚


> Note: The number in ORDER BY and GROUP BY always start with 1 not with 0.



## èšåˆå‡½æ•°

### count(*) count(1) count(col)

#### æŸ¥è¯¢è§„åˆ™

* `count(*)` ï¼šå¯¹è¡¨ä¸­è¡Œæ•°è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼ŒåŒ…å« `null` å€¼
* `count(1)` ï¼šå¯¹è¡¨ä¸­è¡Œæ•°è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼ŒåŒ…å« `null` å€¼
* `count(col_name)`ï¼šå¯¹è¡¨ä¸­æŸå­—æ®µçš„è¡Œæ•°è¿›è¡Œç»Ÿè®¡ï¼Œä¸åŒ…å« `null` å€¼ã€‚ä½†æ˜¯å¦‚æœå‡ºç°ç©ºå­—ç¬¦ä¸²ï¼ŒåŒæ ·ä¼šè¿›è¡Œç»Ÿè®¡



#### æŸ¥è¯¢æ•ˆç‡


1. å¦‚æœåˆ—ä¸ºä¸»é”®ï¼Œ`count(åˆ—å)` æ•ˆç‡ä¼˜äº `count(1)` 
2. å¦‚æœåˆ—ä¸ä¸ºä¸»é”®ï¼Œ`count(1)` æ•ˆç‡ä¼˜äº `count(åˆ—å)`
3. å¦‚æœæœ‰ä¸»é”®çš„è¯ï¼Œé‚£ä¹ˆ `count(ä¸»é”®åˆ—å)` æ•ˆç‡æœ€ä¼˜
4. å¦‚æœè¡¨åªæœ‰ä¸€åˆ—ï¼Œé‚£ä¹ˆ `count(*)` æ•ˆç‡æœ€ä¼˜
5. **å¦‚æœè¡¨æœ‰å¤šåˆ—ä¸”ä¸å­˜åœ¨ä¸»é”®ï¼Œé‚£ä¹ˆ `count(1)` æ¯” `count(*)` å¿«** 




#### Demo-æ•°æ®æŸ¥è¯¢å®ä¾‹

1. å‡†å¤‡ä¸€ä¸ª `golds_log` æ•°æ®è¡¨ï¼Œå…¶ç»“æ„å¦‚ä¸‹

```
hive> desc golds_log;
OK
user_id             	bigint              	                    
accounts            	string              	                    
change_type         	string              	                    
golds               	bigint              	                    
log_time            	int                 	                    
Time taken: 0.246 seconds, Fetched: 5 row(s)
```

2. åœ¨æ•°æ®è¡¨ä¸­æ’å…¥ 6 æ¡æµ‹è¯•æ•°æ®ï¼Œå…¶ä¸­ 1 æ¡æ•°æ®ä¸­éƒ¨åˆ†å­—æ®µä¸º `null`


```
hive> select *  from golds_log;
OK
3645356	wds7654321(4171752)	æ–°äººæ³¨å†Œå¥–åŠ±	1700	1526027152
2016869	dqyx123456789(2376699)	å‚åŠ ä¸€åœºæ¯”èµ›	1140	1526027152
3630468	dke3776611(4156064)	å¤§è½¬ç›˜å¥–åŠ±	1200	1526027152
3642022	é»‘å¨ƒ123456(4168266)	æ–°äººæ³¨å†Œå¥–åŠ±	500	1526027152
2016869	dqyx123456789(2376699)	å¤§è½¬ç›˜å¥–åŠ±	1500	1526027152
36453522	NULL	æ–°äººæ³¨å†Œå¥–åŠ±	NULL	NULL
Time taken: 0.108 seconds, Fetched: 6 row(s)
```

3. ä½¿ç”¨ `count(*)` å¯¹è¡¨ä¸­è¡Œæ•°è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼ŒåŒ…å« `null` å€¼


```
hive> select count(*) from golds_log;
OK
6
Time taken: 0.273 seconds, Fetched: 1 row(s)
```


4. ä½¿ç”¨ `count(1)` å¯¹è¡¨ä¸­è¡Œæ•°è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼ŒåŒ…å« `null` å€¼


```
hive> select count(1) from golds_log;
OK
6
Time taken: 0.091 seconds, Fetched: 1 row(s)
```

5. ä½¿ç”¨ `count(accounts)` å¯¹è¡¨ä¸­ `accounts` å­—æ®µçš„è¡Œæ•°è¿›è¡Œç»Ÿè®¡ï¼Œ`accounts` å­—æ®µè®°å½•ä¸­åŒ…å« `null` å€¼

```
hive> select count(accounts) from golds_log;
OK
5
Time taken: 0.103 seconds, Fetched: 1 row(s)
```


6. ä½¿ç”¨ `count(change_type)` å¯¹è¡¨ä¸­ `change_type` å­—æ®µçš„è¡Œæ•°è¿›è¡Œç»Ÿè®¡ï¼Œ`change_type` å­—æ®µè®°å½•ä¸­ä¸åŒ…å« `null` å€¼


```
hive> select count(change_type) from golds_log;
OK
6
Time taken: 0.1 seconds, Fetched: 1 row(s)
```