# Redis-03-Redis缓存异常


[TOC]

## 更新
* 2021/12/16，撰写
* 2022/05/08，笔记整理




## 参考资料
* [实战缓存 | 悟空聊架构](https://mp.weixin.qq.com/s?__biz=MzAwMjI0ODk0NA==&mid=2451954442&idx=1&sn=e5ec784a11fcbad89eb2e4c7a809378d&chksm=8d1c2295ba6bab833b77318661d4aeb4533234f03d4b9e5a298e84b8041258569af4301a21c3&scene=21#wechat_redirect)
* [亿级系统的 Redis 缓存如何设计 | 悟空聊架构](https://my.oschina.net/u/4499317/blog/5204768)
* [缓存雪崩、击穿、穿透分析](https://new.qq.com/omn/20210622/20210622A061SF00.html)
* [《我们一起进大厂》系列-缓存雪崩、击穿、穿透 | 掘金](https://juejin.cn/post/6844903986475057165)





## 缓存异常的3个问题

设计一个缓存系统，就会面对缓存异常的 3 个问题
1. 缓存雪崩
2. 缓存击穿
3. 缓存穿透


> 缓存雪崩与缓存击穿的区别：缓存雪崩是针对很多 key 缓存失效的情况，缓存击穿是针对某一个 key。

|    分类   |                 原因                |       备注    |  
|-----------|-------------------------------------|-------------|
| 缓存雪崩  | 1.大量缓存数据同时过期；2.redis故障 |
| 缓存击穿  |       热点数据缓存过期              |  要请求的数据，不在缓存中，但在DB中 |
| 缓存穿透  |    数据既不在缓存，也不在数据库     |   缓存和DB中均无要请求的数据 | 




![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a9cfe34a7df54eeb896cb4df65fffbd2~tplv-k3u1fbpfcp-zoom-1.image)


## 缓存雪崩

### 产生原因 
1. 大量缓存数据在同一时间过期或失效
2. Redis 故障宕机

### 解决办法

#### 1.均匀设置过期时间，避免同一时间过期

避免将大量的数据设置成同一个过期时间。对缓存数据设置过期时间时，可以给过期期时间加上一个随机数，这样就可以保证数据不会在同一时间过期。


```s
setRedis(Key，value，time + Math.random() * 10000)；
```



#### 2.互斥锁

使用互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里）。当缓存构建完成后，再释放锁。

未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。



#### 3.双key策略

对缓存数据使用两个 `key`，一个是主 `key`，会设置过期时间；一个是备 `key`，不会设置过期。它们只是 `key` 不一样，但 `value` 值是一样的，相当于给缓存数据做了个副本。

当业务线程访问不到主 `key` 的缓存数据时，就直接返回备 `key` 的缓存数据，然后在更新缓存的时候，同时更新主 `key` 和备 `key` 的数据。


#### 4.后台更新缓存，定时更新或使用消息队列通知更新

**业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新或使用消息队列通知更新。**


1. 定时更新：后台线程定时的把数据更新到缓存中。
2. 使用消息队列通知更新：在业务线程发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存。


在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的 **「缓存预热」**。后台更新缓存的机制刚好也适合干这个事情。


#### 5.请求限流


启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。


## 缓存击穿

### 产生原因 

1. 热点数据缓存过期      


如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，造成缓存击穿。

### 解决办法


#### 1.互斥锁

同「缓存雪崩」的「互斥锁」解决方案。




#### 2.不给热点数据设置过期时间，由后台异步更新缓存


不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间。



## 缓存穿透

### 产生原因 

当用户访问的数据，**既不在缓存中，也不在数据库中**。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。


缓存穿透的发生一般有这 2 种情况
1. 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据
2. 黑客恶意攻击，故意大量访问某些读取不存在数据的业务



### 解决办法


#### 1.限制非法请求

在接口调用时候，判断求请求参数是否合理，请求参数是否含有非法值，请求字段是否存在等情况。如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。



#### 2.缓存空值或者默认值

当线上业务发现缓存穿透时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。



#### 3.使用布隆过滤器快速判断数据是否存在
* ref 1-[Redis-避免缓存穿透的利器之BloomFilter | 掘金](https://juejin.cn/post/6844903982209449991)

使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。





## 缓存设计中的一些问题

* ref 1-[亿级系统的 Redis 缓存如何设计 | 悟空聊架构](https://my.oschina.net/u/4499317/blog/5204768)
* ref 2-[发现并处理Redis的大Key和热Key | 阿里云](https://help.aliyun.com/document_detail/353223.html)



### 如何快速找出热key和大key
* [发现并处理Redis的大Key和热Key | 阿里云](https://help.aliyun.com/document_detail/353223.html)


|   方法	|   优点	 |     缺点  |     说明   | 
|--------|----------|----------|------------|
| 实时Top Key 统计（推荐） | 准确性高、对性能几乎无影响 | 展示的 Key 数量有一定限制，但能满足常规场景下的需求 | 可实时展示实例中的大Key和热Key信息，同时支持查看4天内大Key和热Key的历史信息。该功能可帮助您掌握Key在内存中的占用、Key的访问频次等信息，溯源分析问题，为您的优化操作提供数据支持 |
| 离线全量Key分析 | 可对历史备份数据进行分析，对线上服务无影响 | 时效性差，RDB文件较大时耗时较长 | 对Redis的RDB备份文件进行定制化的分析，帮助您发现实例中的大Key，掌握Key在内存中的占用和分布、Key过期时间等信息，为您的优化操作提供数据支持，帮助您避免因Key倾斜引发的内存不足、性能下降等问题 |
| 通过 redis-cli 的 bigkeys 和 hotkeys 参数查找大Key和热Key | 方便、快速、安全 | 分析结果不可定制化，准确性与时效性差 | Redis 提供了bigkeys参数能够使 redis-cli 以遍历的方式分析Redis实例中的所有Key，并返回Key的整体统计信息与每个数据类型中Top1的大Key。同时，自 Redis 4.0 版本起提供了 hotkeys 参数，可以快速帮您找出业务中的热Key | 
| 通过业务层定位热Key | 可准确并及时地定位热Key |业务代码复杂度的增加，同时可能会降低一些性能 | 通过在业务层增加相应的代码对Redis的访问进行记录并异步汇总分析 |
| 通过redis-rdb-tools工具以定制化方式找出大Key | 支持定制化分析，对线上服务无影响 | 时效性差，RDB文件较大时耗时较长 | Redis-rdb-tools是通过Python编写，支持定制化分析Redis RDB快照文件的开源工具。您可以根据您的精细化需求，全面地分析Redis实例中所有Key的内存占用情况，同时也支持灵活地分析查询 | 
| 通过 MONITOR 命令找出热 Key | 方便、安全 | 会占用CPU、内存、网络资源，时效性与准确性较差 | Redis的MONITOR命令能够忠实地打印Redis中的所有请求，包括时间信息、Client信息、命令以及Key信息。在发生紧急情况时，可以通过短暂执行MONITOR命令并将返回信息输入至文件，在关闭MONITOR命令后，对文件中请求进行归类分析，找出这段时间中的热Key | 

### 缓存热点（热key）

对于突发事件，大量用户同时去访问热点信息，这个突发热点信息所在的缓存节点就很容易出现过载和卡顿现象，甚至 Crash，我们称之为「缓存热点」或「热key问题」。

这个在新浪微博经常遇到，某大 V 明星出轨、结婚、离婚，瞬间引发数百千万的吃瓜群众围观，访问同一个 key，流量集中打在一个缓存节点机器，很容易打爆网卡、带宽、CPU 的上限，最终导致缓存不可用。





#### 影响

1. 占用大量的 CPU 资源，影响其他请求并导致整体性能降低。
2. **集群架构下，产生「访问倾斜」，即某个数据分片被大量访问，而其他数据分片处于空闲状态，可能引起该数据分片的连接数被耗尽，新的连接建立请求被拒绝等问题。**
3. 在抢购或秒杀场景下，可能因商品对应库存 Key 的请求量过大，超出 Redis 处理能力造成超卖。
4. 热 Key 的请求压力数量超出 Redis 的承受能力易造成缓存击穿，即大量请求将被直接指向后端的存储层，导致存储访问量激增甚至宕机，从而影响其他业务。



#### 产生原因

1. 预期外的访问量陡增
   * 如突然出现的爆款商品、访问量暴涨的热点新闻、直播间某主播搞活动带来的大量刷屏点赞等。

#### 解决方案

「缓存热点」的解决方案如下
* 方案1：提前把热 key 打散到不同的服务器中，降低压力
  1. 首先要先找到这个热 key，比如通过 Spark 实时流分析，及时发现新的热点 key。
  2. 将集中化流量打散，避免一个缓存节点过载。由于只有一个 key，我们可以在 key 的后面拼上「有序编号」，比如 `key#01`、`key#02` 等多个副本，这些加工后的 key 位于多个缓存节点上。
  3. 每次请求时，客户端随机访问一个即可。
* 方案2：**使用二级缓存，提前加载热 key 数据到内存中。如果 Redis 宕机，走内存查询。**




### 缓存大Key

当访问缓存时，如果 key 对应的 value 过大，读写、加载很容易超时，容易引发网络拥堵。另外缓存的字段较多时，每个字段的变更都会引发缓存数据的变更，频繁的读写，导致慢查询。如果大 key 过期被缓存淘汰失效，预热数据要花费较多的时间，也会导致慢查询。

所以我们在设计缓存的时候，要注意缓存的粒度，既不能过大，如果过大很容易导致网络拥堵；也不能过小，如果太小，查询频率会很高，每次请求都要查询多次。


#### 影响

1. 网络阻塞
   * 获取 bigkey 时，传输的数据量比较大，会增加带宽的压力。
2. 超时阻塞
   * 因为 bigkey 占用的空间比较大，所以操作起来效率会比较低，导致出现阻塞的可能性增加。
3. 导致内存空间不平衡
   * 一个 bigkey 存储数据量比较大，同一个 key 在同一个节点或服务器中存储，会造成一定影响。


#### 产生原因
* [发现并处理Redis的大Key和热Key | 阿里云](https://help.aliyun.com/document_detail/353223.html)

1. 在不适用的场景下使用 Redis，易造成 Key 的 value 过大，如使用 String 类型的 Key 存放大体积二进制文件型数据；
2. 业务上线前规划设计不足，没有对 Key 中的成员进行合理的拆分，造成个别 Key 中的成员数量过多；
3. **未定期清理无效数据，造成如 HASH 类型 Key 中的成员持续不断地增加；**
4. 使用 LIST 类型 Key 的业务消费侧发生代码故障，造成对应 Key 的成员只增不减。



#### 解决方案
「缓存大Key」的解决方案如下
1. 压缩
   * 设置一个阈值，当 value 的长度超过阈值时，对内容启动压缩，降低 kv 的大小。
   * 比如使用 gzip 压缩，但是在压缩和解压时候会消耗 CPU 资源。
   * 压缩方案，相当于是将存储遇到的瓶颈，转移给 CPU 处理。
2. 拆分
   * 颗粒划分，将大 key 拆分为多个小 key，独立维护，成本会降低不少。
   * 比如对 Hash，拆分为多个 Hash。在读取时候，若使用 MGET 读取，会存在结果在多个哈希槽上的情况，需要进行取舍。
3. 缓存过期和清理
   * 大 key 要设置合理的过期时间，尽量不淘汰那些大 key。



#### 京东素材中心中的Key大小

> 商品组的展示数量和存储数量

1. 一个普通商品组的分期下，默认最大支持存储 500 个商品，默认展示数量为 100。
2. 一个扩容商品组的分期下，默认最大支持存储 2000 个商品，默认展示数量为 500。
3. 一个素材池商品组，只存储一个池 ID，从算法侧拉取数据，默认截取前 1000 个商品。

> 为什么展示数量，不等于存储数量？

1. 存储数量要大于展示数量，是为了给算法同步过去足够的数据，方便算法侧排序。
2. 展示数量较小，因为促销落地页下用户深翻页的并不多，可能最多浏览前 00 个商品。促销落地页业务场景中，不涉及无限下拉 feed 流。


> Redis key 的大小

两个商品响应数据的 JSON 文件，在 JSON 未换行压缩时大小为 8 KB，换行压缩时大小为 6 KB。所以粗略认为一个商品相应数据为 3 KB。

因此有如下结论

1. 一个普通商品组，默认按照 100 个商品，则 Redis 缓存大小为 3KB * 100 = 300 KB。
2. 一个扩容商品组，按照 500 个商品，则 Redis 缓存大小为 3KB * 500 = 1500 KB，大约 1.46 MB。
3. 一个池类型的商品组，按照 1000 个商品，则 Redis 缓存大小为  3KB * 1000 = 3000 KB，大约为 2.92 MB。






## Spring Cache和缓存击穿、缓存穿透

* ref 1-[一行代码解决缓存击穿问题 | 掘金](https://juejin.cn/post/7088148239572008974#heading-5)
* ref 2-[Cacheable注解中sync属性 | CSDN](https://blog.csdn.net/yb223731/article/details/107619718)




### 缓存击穿


系统中若有热点数据缓存过期，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，造成缓存击穿。


在使用 Spring Cache 时，可使用 `@Cacheable` 注解的 `sync=true`属性，采用同步方式，在缓存不存在时只允许一个线程执行对应方法（如请求DB），其他线程将阻塞，直到将方法返回的结果写入缓存中。

```java
@Cacheable(cacheNames="expensiveOp", sync=true)
public void executeExpensiveOperation(String id) {
    //若无缓存，则请求DB
}
```


### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。


在使用 Spring Cache 时，若采用 Redis 作为缓存实现方案，可以在配置文件中，指定如下属性，避免缓存穿透。

```s
# 是否缓存空值 防止缓存穿透
spring.cache.redis.cache-null-values=true
```

