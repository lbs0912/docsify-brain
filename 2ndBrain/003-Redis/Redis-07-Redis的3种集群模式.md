# Redis-07-Redis的3种集群模式


[TOC]



## 更新
* 2022/05/15，撰写


@todo 受限于时间 此处先做大纲记录 后续待整理



## 参考资料
* [Redis 三种集群模式（主从、哨兵、集群） + 如何保证数据一致 | CSDN](https://blog.csdn.net/qq_30154571/article/details/121870701)
* [Redis主从、哨兵、 Cluster集群 | 掘金](https://juejin.cn/post/7077343204567154695)


## 前言
Redis 有三种集群模式
1. 主从模式
2. 哨兵模式（监控主从服务器，保证高可用）
3. 集群模式（Cluster）




## 主从模式

1. Redis 主从模式，就是部署多台 Redis 服务器，有主库和从库，它们之间通过主从复制，以保证数据副本的一致。
2. 主从库之间采用的是读写分离的方式，其中主库负责读操作和写操作，从库则负责读操作。
3. 如果 Redis 主库挂了，切换其中的从库成为主库（需要人工处理）。

### 主从复制（主从同步）


Redis 的「复制功能」是支持多个数据库之间的数据同步。（注意，并不能保证强一致性，只是保证最终一致性）
1. 主从模式下，可划分出主数据库（master）和从数据库（slave）
2. 主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库
3. 从数据库一般是只读的，并接收主数据库同步过来的数据
4. 一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库


通过 Redis 的复制功能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。



主从同步的具体过程如下图。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-replication-1.png)

Redis 主从同步包括 3 个阶段。
1. 第一阶段：主从库间建立连接、协商同步
   * 从库向主库发送 `psync` 命令，告诉它要进行数据同步。
   * 主库收到 `psync` 命令后，响应 `FULLRESYNC` 命令（它表示第一次复制采用的是「全量复制」），并带上主库 `runID` 和主库目前的复制进度 `offset`。

2. 第二阶段：主库把数据同步到从库，从库收到数据后，完成本地加载
   * 主库执行 `bgsave` 命令，生成 RDB 文件，接着将文件发给从库。
   * 从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。
   * 主库把数据同步到从库的过程中，新来的写操作，会记录到 `replication buffer`（复制缓冲区）。
3. 第三阶段：主库把新写的命令，发送到从库
   * 主库完成 RDB 发送后，会把 `replication buffer`（复制缓冲区）中的修改操作发给从库
   * 从库再重新执行这些操作，这样主从库就实现同步啦

### 「一主多从」下全量复制时主库的压力

一主多从模式下，如果从库很多，每个从库都要和主库进行全量复制的话，主库的压力是很大的。因为主库 fork 进程生成 RDB，这个 fork 的过程是会阻塞主线程处理正常请求的。同时，传输大的 RDB 文件也会占用主库的网络宽带。


可以使用「主-从-从」模式解决。部署主从集群时，选择硬件网络配置比较好的一个从库，让它跟部分从库再建立主从关系。

> Redis 不仅支持主从同步，还支持从从同步。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-replication-2.png)


### 主从模式下各个节点如何保证数据一致
* ref 1-[Redis集群中的节点如何保证数据一致 | CSDN](https://blog.csdn.net/itwxming/article/details/89491664)



### 主从网络断了怎么办

主从库完成了全量复制后，它们之间会维护一个网络长连接，用于主库后续收到写命令传输到从库，它可以避免频繁建立连接的开销。但是，如果网络断开重连后，是否还需要进行一次全量复制呢？


如果是 Redis 2.8 之前，从库和主库重连后，确实会再进行一次全量复制，但是这样开销就很大。而 Redis 2.8 之后做了优化，重连后采用「增量复制」方式，即把主从库网络断连期间主库收到的写命令，同步给从库。

主从库重连后，就是利用 `repl_backlog_buffer`（复制积压缓冲区）实现增量复制。

> 注意，此处的 `repl_backlog_buffer`（复制积压缓冲区）不同于上文提到的`replication buffer`（复制缓冲区）。


当主从库断开连接后，主库会把断连期间收到的写操作命令，写入 `replication buffer`，同时也会把这些操作命令写入 `repl_backlog_buffer` 这个缓冲区。
`repl_backlog_buffer` 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。






## Redis哨兵

主从模式中，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址。显然，多数业务场景都不能接受这种故障处理方式。Redis 从 2.8 开始正式提供了 Redis 哨兵机制来解决这个问题。

### 哨兵作用

哨兵其实是一个运行在特殊模式下的 Redis 进程。它有 3 个作用，分别是
1. 监控
   * 监视所有的 Redis 主节点和从节点的状态
   * 通过周期性给主从库发送 PING 命令，检测主从库的状态。
   * 如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为「下线状态」
   * 如果主库没有在规定时间内响应哨兵的 PING 命令，哨兵则会判定主库下线（又细分出了主观下线和客观下线），然后开始切换到选主任务
2. 自动选主切换（简称选主）
3. 通知
   * 选出主库后，哨兵把新主库的连接信息发给其他从库，让它们和新主库建立主从关系
   * 同时，哨兵也会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上



### 如果哨兵自身挂了呢

因为 Redis 哨兵也是一个 Redis 进程，如果它自己挂了呢，那是不是就起不了监控的作用啦？

针对这问题，一个哨兵进程对 Redis 节点进行监控，就可能会出现问题（单点问题）。因此，一般使用多个哨兵来进行监控 Redis 节点，并且各个哨兵之间还会进行监控。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-sentinel-1.png)



### 哨兵如何判定主库下线


哨兵是如何判断主库是否下线的呢？这里的「下线」，又可分为「主观下线」和「客观下线」。
* 哨兵进程向主库、从库发送 PING 命令，如果主库或者从库没有在规定的时间内响应 PING 命令，哨兵就把它标记为「主观下线」。
* 如果是主库被标记为主观下线，则正在监视这个主库的所有哨兵要以每秒一次的频率，以确认主库是否真的进入了主观下线。 当有多数的哨兵（一般少数服从多数，由 Redis 管理员自行设定的一个值）在指定的时间范围内确认主库的确进入了主观下线状态，则主库会被标记为「客观下线」。
* 这样做的目的就是避免对主库的误判，以减少没有必要的主从切换，减少不必要的开销。


假设我们有 N 个哨兵实例，如果有（N/2+1）个实例判断主库主观下线，此时就可以把节点标记为客观下线，就可以做主从切换了。


### 哨兵如何选主

哨兵选主包括两大过程，分别是「过滤」和「打分」。
1. 「过滤」环节中，会在多个从库中，先按照一定的筛选条件，把不符合条件的从库过滤掉。
2. 「打分」环节找那个，先按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-sentinel-2.png)


* 选主时，会判断从库的状态，如果已经下线，就直接过滤。
* 如果从库网络不好，老是超时，也会被过滤掉。`down-after-milliseconds` 参数表示我们认定主从库断连的最大连接超时时间。
* 过滤掉了不适合做主库的从库后，就可以给剩下的从库打分，按这三个规则打分：从库优先级、从库复制进度以及从库 ID 号。
* 从库优先级最高的话，打分就越高，优先级可以通过 `slave-priority` 配置。如果优先级一样，就选与旧的主库复制进度最快的从库。如果优先级和从库进度都一样，从库 ID 号小的打分高。


### 由哪个哨兵执行主从切换

一个哨兵标记主库为主观下线后，它会征求其他哨兵的意见，确认主库是否的确进入了主观下线状态。它向其他实例哨兵发送 `is-master-down-by-addr` 命令。其他哨兵会根据自己和主库的连接情况，回应 Y或 N。如果这个哨兵获取得足够多的赞成票数（`quorum` 配置），主库会被标记为客观下线。

标记主库客观下线的这个哨兵，紧接着向其他哨兵发送命令，再发起投票，希望它可以来执行主从切换。这个投票过程称为 Leader 选举。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。一个哨兵想成为 Leader 需要满足两个条件
1. 需要拿到 `num(sentinels)/2+1` 的赞成票。
2. 并且拿到的票数需要大于等于哨兵配置文件中的 `quorum` 值。


### 故障转移

假设哨兵模式架构如下，有三个哨兵，一个主库M，两个从库S1和S2。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-sentinel-3.png)


当哨兵检测到 Redis 主库 M1 出现故障，那么哨兵需要对集群进行故障转移。假设选出了哨兵 3 作为 Leader。故障转移流程如下。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-sentinel-4.png)


1. 从库 S1 解除从节点身份，升级为新主库。
2. 从库 S2 成为新主库的从库。
3. 原主节点恢复也变成新主库的从节点。
4. 通知客户端应用程序新主节点的地址。


故障转移后的状态如下图。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-sentinel-5.png)



## 集群模式（Cluster）


哨兵模式基于主从模式，实现读写分离，它还可以自动切换，系统可用性更高。但是它每个节点存储的数据是一样的，浪费内存，并且不好在线扩容。

因此，Reids Cluster集群（切片集群的实现方案）应运而生，它在 Redis 3.0 加入的，实现了 Redis 的分布式存储。对数据进行分片，也就是说每台 Redis 节点上存储不同的内容，来解决在线扩容的问题。并且，它可以保存大量数据，即分散数据到各个 Redis 实例，还提供复制和故障转移的功能。

比如你一个 Redis 实例保存 15G 甚至更大的数据，响应就会很慢，这是因为 Redis RDB 持久化机制导致的，Redis 会 fork 子进程完成 RDB 持久化操作，fork 执行的耗时与 Redis 数据量成正相关。



这时候你很容易想到，把 15G 数据分散来存储就好了嘛。这就是 Redis 切片集群的初衷。切片集群是啥呢？来看个例子，如果你要用 Redis 保存 15G 的数据，可以用单实例 Redis，或者 3 台 Redis 实例组成切片集群，对比如下。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-cluster-1.png)


切片集群和 Redis Cluster 的区别是，Redis Cluster 是从 Redis 3.0 版本开始，官方提供的一种实现切片集群的方案。



既然数据是分片分布到不同 Redis 实例的，那客户端到底是怎么确定想要访问的数据在哪个实例上呢？

Redis 是通过「哈希槽」来解决的。


### 哈希槽

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。

一个切片集群被分为 16384（2^14）个 slot（槽），每个进入 Redis 的键值对，根据 key 进行散列，分配到这 16384 插槽中的一个。

使用的哈希映射也比较简单，用 CRC16 算法计算出一个 16 bit 的值，再对 16384 取模。数据库中的每个键都属于这 16384 个槽的其中一个，集群中的每个节点都可以处理这 16384 个槽。

集群中的每个节点负责一部分的哈希槽，假设当前集群有A、B、C 这 3 个节点，每个节点上负责的哈希槽数 = `16384/3`，那么可能存在的一种分配
1. 节点 A 负责 0~5460 号哈希槽
2. 节点 B 负责 5461~10922 号哈希槽
3. 节点 C 负责 10923~16383 号哈希槽

客户端给一个 Redis 实例发送数据读写操作时，如果这个实例上并没有相应的数据，会怎么样呢？

这就引入了 `MOVED` 重定向和 `ASK` 重定向。




### Hash Slot为什么是16384

Redis 节点在发送心跳包时，需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息。心跳包中，使用 2k（`2 * 1024 * 8(bit)` = 16000）的空间可以表示 16000 个槽数目。一般情况下，Redis 集群不会有超过 1000 个节点，所以选用 16384（2^14）个哈希槽比较合适。


虽然使用 CRC16 算法（计算出的一个 16 bit 的值）最多可以分配 65535（2^16-1）个槽位，不过若要记录 65535 个卡槽信息，心跳包需要使用约 8k的空间（`8 * 1024 * 8(bit)` = 64000），这会造成心跳包过大。





### 哈希槽和一致性Hash

* ref 1-[一致性hash和redis中hash槽的区别](https://blog.csdn.net/swl1993831/article/details/108023473)
* ref 2-[为何 Redis 集群用哈希槽，而不用一致性哈希](https://blog.51cto.com/u_15077562/4537972)



Memcache 中使用了一致性 Hash 进行负载均衡。Redis 集群使用了哈希槽进行负载均衡。


那为什么 Redis 不采用一致性 Hash 呢？
1. 一致性 Hash 中，存在缓存抖动和数据倾斜问题
2. 哈希槽相比一致性 Hash，可以做到数据分配更加均匀
3. 哈希槽可以更便捷的新增、删除节点
   * 假设已有节点 R1、R2，若要新增节点 R3，只需要将 R1、R2 的一部分哈希槽移动到 R4 节点上即可；若要删除 R1，只需要移动 R1 的哈希槽至其他节点即可
   * 节点之间的槽移动不会停止服务，集群是一直可用状态


#### 一致性Hash的缺点

一致性 Hash 中，存在缓存抖动和数据倾斜问题。


|   问题     |             描述            |          解决       |
|------------|----------------------------|---------------------|
| 缓存抖动  | 删除节点时，会导致部分数据无法命中，出现缓存抖动，严重的甚至会导致缓存雪崩。比如节点 1 被删除后，节点 1 的请求被分配到顺时针方向的下一个节点 2 上，这可能导致节点 2 的访问量突然增大，再导致节点 2 宕机，继而将请求分配到节点 3 上，如此循环，导致缓存雪崩 | 虚拟节点 |
| 数据倾斜 | 集群中节点过少，大量的数据被分配到同一个节点上，负载不均衡 | 虚拟节点 |

### 重定向


#### MOVED重定向

客户端给一个 Redis 实例发送数据读写操作时，如果计算出来的槽不是在该节点上，这时候它会返回 MOVED 重定向错误，MOVED 重定向错误中，会将哈希槽所在的新实例的 IP 和 port 端口带回去。这就是 Redis Cluster 的 MOVED 重定向机制。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-cluster-2.png)


#### ASK重定向

Ask 重定向一般发生于集群伸缩的时候。集群伸缩会导致槽迁移，当我们去源节点访问时，此时数据已经可能已经迁移到了目标节点，使用 Ask 重定向可以解决此种情况。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-cluster-3.png)


### Cluster集群节点的通讯协议：Gossip

一个 Redis 集群由多个节点组成，各个节点之间是怎么通信的的？

**是通过 Gossip 协议！Gossip 是一种谣言传播协议，每个节点周期性地从节点列表中选择 k 个节点，将本节点存储的信息传播出去，直到所有节点信息一致，即算法收敛了。**

Gossip 协议基本思想是，一个节点想要分享一些信息给网络中的其他的一些节点。于是，它周期性的随机选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给 N 个目标节点，而不只是一个。这个 N 被称为 `fanout`（扇出）。

Redis Cluster 集群通过 Gossip 协议进行通信，节点之前不断交换信息，交换的信息内容包括节点出现故障、新节点加入、主从节点变更信息、slot 信息等等。Gossip 协议包含多种消息类型，包括 ping，pong，meet，fail 等等。



![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-cluster-4.png)



### 集群不可用

Redis 使用哈希槽进行映射。Redis 中的哈希槽一共有 16384 个，计算给定
密钥的哈希槽，我们只需要对密钥的 CRC16 取摸 16384。假设集群中有 A、B、C 三个集群节点。

不存在复制模式下，每个集群的节点包含的哈希槽如下
1. 节点 A 包含从 0 到 5500 的哈希槽；
2. 节点 B 包含从 5501 到 11000 的哈希槽；
3. 节点 C 包含从 11001 到 16383 的哈希槽；


此时，如果节点 B 出现故障，整个集群就会出现不可用。

若要保证集群高可用，可采用「故障转移」进行保证。

### 故障转移

Redis 集群实现了高可用，当集群内节点出现故障时，通过故障转移，以保证集群正常对外提供服务。

Redis 集群通过 ping/pong 消息，实现故障发现。这个环境包括主观下线和客观下线。

