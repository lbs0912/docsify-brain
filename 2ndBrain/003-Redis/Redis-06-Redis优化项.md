
# Redis-06-Redis优化项


[TOC]

## 更新
* 2022/05/15，撰写




## 性能优化
1. Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件；
2. 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次；
3. 为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网内；
4. 尽量避免在压力很大的主库上增加从库；
5. 主从复制不要用图状结构，用单向链表结构更为稳定，即 `Master -> Slave1 -> Slave2 -> Slave3`。这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可以立刻启用 Slave1 做 Master，其他不变。



### Redis性能优化13条军规
* [Redis 性能优化的 13 条军规](https://segmentfault.com/a/1190000022172968)

1. 缩短键值对的存储长度；
2. 使用 lazy free（延迟删除）特性；
3. 设置键值的过期时间；
4. 禁用长耗时的查询命令；
5. 使用 slowlog 优化耗时命令；
6. 使用 Pipeline 批量操作数据；
7. 避免大量数据同时失效；
8. 客户端使用优化；
9. 限制 Redis 内存大小；
10. 使用物理机而非虚拟机安装 Redis 服务；
11. 检查数据持久化策略；
12. 禁用 THP 特性；
13. 使用分布式架构来增加读写速度



#### 1. 缩短键值对的存储长度

键值对的长度是和性能成反比的。
1. 内容越大需要的持久化时间就越长，需要挂起的时间越长，Redis 的性能就会越低；
2. 内容越大在网络上传输的内容就越多，需要的时间就越长，整体的运行速度就越低；
3. 内容越大占用的内存就越多，就会更频繁的触发内存淘汰机制，从而给 Redis 带来了更多的运行负担。




#### 2. 使用 lazy free（延迟删除）特性


lazy free 特性是 Redis 4.0 新增的一个非常使用的功能，它可以理解为惰性删除或延迟删除。意思是在删除的时候提供异步延时释放键值的功能，把键值释放操作放在 BIO（Background I/O) 单独的子线程处理中，以减少删除删除对 Redis 主线程的阻塞，可以有效地避免删除 big key 时带来的性能和可用性问题。

lazy free 对应了 4 种场景，默认都是关闭的。

```s
# 当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除
lazyfree-lazy-eviction no
# 设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
slave-lazy-flush no
```


#### 3. 设置键值的过期时间

我们应该根据实际的业务情况，对键值设置合理的过期时间，这样 Redis 会帮你自动清除过期的键值对，**以节约对内存的占用，以避免键值过多的堆积，频繁的触发内存淘汰策略。**


#### 4. 禁用长耗时的查询命令


Redis 绝大多数读写命令的时间复杂度都在 O(1) 到 O(N) 之间，在官方文档对每命令都有时间复杂度说明，查看地址见 [redis.io/commands](https://redis.io/commands/)。

要避免 `O(N)` 命令对 Redis 造成的影响，可以从以下几个方面入手改造
1. 决定禁止使用 keys 命令；
2. 避免一次查询所有的成员，要使用 scan 命令进行分批的，游标式的遍历；
3. 通过机制严格控制 Hash、Set、Sorted Set 等结构的数据大小；
4. 将排序、并集、交集等操作放在客户端执行，以减少 Redis 服务器运行压力；
5. 删除 (del) 一个大数据的时候，可能会需要很长时间，所以建议用异步删除的方式 `unlink`，它会启动一个新的线程来删除目标数据，而不阻塞 Redis 的主线程。





#### 5. 使用 slowlog 优化耗时命令

我们可以使用 `slowlog` 功能找出最耗时的 Redis 命令进行相关的优化，以提升 Redis 的运行速度，慢查询有两个重要的配置项
1. `slowlog-log-slower-than`：用于设置慢查询的评定时间，也就是说超过此配置项的命令，将会被当成慢操作记录在慢查询日志中，它执行单位是微秒 (1 秒等于 1000000 微秒)；
2. `slowlog-max-len`：用来配置慢查询日志的最大记录数。




#### 6. 使用 Pipeline 批量操作数据


Pipeline (管道技术) 是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。


#### 7. 避免大量数据同时失效

Redis 过期键值删除使用的是贪心策略，它每秒会进行 10 次过期扫描（即每100ms扫描一次），此配置可在 `redis.conf` 进行配置，默认值是 `hz 10`，Redis 会随机抽取 20 个值，删除这 20 个键中过期的键，如果过期 key 的比例超过 25% ，重复执行此流程，如下图所示。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-expire-data-del-time-1.png)


如果在大型系统中有大量缓存在同一时间同时过期，那么会导致 Redis 循环多次持续扫描删除过期字典，直到过期字典中过期键值被删除的比较稀疏为止，而在整个执行过程会导致 Redis 的读写出现明显的卡顿，卡顿的另一种原因是内存管理器需要频繁回收内存页，因此也会消耗一定的 CPU。

为了避免这种卡顿现象的产生，我们需要预防大量的缓存在同一时刻一起过期，就简单的解决方案就是在过期时间的基础上添加一个指定范围的随机数。



#### 8. 客户端使用优化


在客户端的使用上我们除了要尽量使用 Pipeline 的技术外，还需要注意要尽量使用 Redis 连接池，而不是频繁创建销毁 Redis 连接，这样就可以减少网络传输次数和减少了非必要调用指令。

#### 9. 限制 Redis 内存大小

在 64 位操作系统中 Redis 的内存大小是没有限制的，也就是配置项 `maxmemory` 是被注释掉的，这样就会导致在物理内存不足时，使用 `swap` 空间既交换空间，而当操作系统将 Redis 所用的内存分页移至 swap 空间时，将会阻塞 Redis 进程，导致 Redis 出现延迟，从而影响 Redis 的整体性能。

因此我们需要限制 Redis 的内存大小为一个固定的值，当 Redis 的运行到达此值时会触发内存淘汰策略，内存淘汰策略在 Redis 4.0 之后有 8 种
1. noeviction：**不淘汰任何数据，当内存不足时，新增操作会报错，Redis 默认内存淘汰策略；**
2. allkeys-lru：淘汰整个键值中最久未使用的键值；
3. allkeys-random：随机淘汰任意键值;
4. volatile-lru：淘汰所有设置了过期时间的键值中最久未使用的键值；
5. volatile-random：随机淘汰设置了过期时间的任意键值；
6. volatile-ttl：优先淘汰更早过期的键值。

在 Redis 4.0 版本中又新增了 2 种淘汰策略
1. volatile-lfu：淘汰所有设置了过期时间的键值中，最少使用的键值；
2. allkeys-lfu：淘汰整个键值中最少使用的键值。

其中 `allkeys-xxx` 表示从所有的键值中淘汰数据，而 `volatile-xxx` 表示从设置了过期键的键值中淘汰数据。

我们可以根据实际的业务情况进行设置，默认的淘汰策略不淘汰任何数据，在新增时会报错。






#### 10. 使用物理机而非虚拟机安装 Redis 服务

在虚拟机中运行 Redis 服务器，因为和物理机共享一个物理网口，并且一台物理机可能有多个虚拟机在运行，因此在内存占用上和网络延迟方面都会有很糟糕的表现，我们可以通过 `./redis-cli --intrinsic-latency 100` 命令查看延迟时间，如果对 Redis 的性能有较高要求的话，应尽可能在物理机上直接部署 Redis 服务器。




#### 11. 检查数据持久化策略

Redis 的持久化策略是将内存数据复制到硬盘上，这样才可以进行容灾恢复或者数据迁移，但维护此持久化的功能，需要很大的性能开销。

在 Redis 4.0 之后，Redis 有 3 种持久化的方式
1. RDB（Redis DataBase，快照方式）将某一个时刻的内存数据，以二进制的方式写入磁盘；
2. AOF（Append Only File，文件追加方式），记录所有的操作命令，并以文本的形式追加到文件中；
3. 混合持久化方式，Redis 4.0 之后新增的方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。


询是否开启混合持久化可以使用 `config get aof-use-rdb-preamble` 命令。

```s
> config get aof-use-rdb-preamble
1) "aof-use-rdb-preamble"
2) "yes"
```




#### 12. 禁用 THP 特性


Linux kernel 在 2.6.38 内核增加了 Transparent Huge Pages (THP) 特性 ，支持大内存页 2MB 分配，默认开启。

当开启了 THP 时，fork 的速度会变慢，fork 之后每个内存页从原来 4KB 变为 2MB，会大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。例如简单的 `incr` 命令也会出现在慢查询中，因此 Redis 建议将此特性进行禁用，禁用方法如下。

```s
echo never > /sys/kernel/mm/transparent_hugepage/enabled
```

为了使机器重启后 THP 配置依然生效，可以在 `/etc/rc.local` 中追加 `echo never > /sys/kernel/mm/transparent_hugepage/enabled`。



#### 13. 使用分布式架构来增加读写速度


Redis 分布式架构有三个重要的手段
1. 主从同步
2. 哨兵模式
3. Redis Cluster 集群

使用主从同步功能我们可以把写入放到主库上执行，把读功能转移到从服务上，因此就可以在单位时间内处理更多的请求，从而提升的 Redis 整体的运行速度。

而哨兵模式是对于主从功能的升级，但当主节点崩溃之后，无需人工干预就能自动恢复 Redis 的正常使用。

Redis Cluster 是 Redis 3.0 正式推出的，Redis 集群是通过将数据库分散存储到多个节点上来平衡各个节点的负载压力。





Redis Cluster 采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16384（2^14） 整数槽内，计算公式为 `slot = CRC16(key) % 16384`，每一个节点负责维护一部分槽以及槽所映射的键值数据。这样 Redis 就可以把读写压力从一台服务器，分散给多台服务器了，因此性能会有很大的提升。

在这三个功能中，我们只需要使用一个就行了，毫无疑问 Redis Cluster 应该是首选的实现方案，它可以把读写压力自动的分担给更多的服务器，并且拥有自动容灾的能力。



## 管道
* ref 1-[Redis中的管道Pipeline操作 | 腾讯云](https://cloud.tencent.com/developer/article/1669677)
* ref 2-[Redis如何解决频繁的命令往返造成的性能瓶颈 | 掘金](https://juejin.cn/post/7089081484958679077)
* ref 3-[Redis管道Pipelining原理详解 | 华为云](https://bbs.huaweicloud.com/blogs/273922)


### 请求/响应协议和RTT

Redis 是一种基于客户端-服务端模型及请求/响应协议的 TCP 服务。这意味着一个请求会遵循以下步骤
1. 客户端向服务端发送一个查询请求，并监听 Socket 返回，通常以阻塞模式等待服务端响应
2. 服务端处理命令，并将结果返回给客户端。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-pipelin-1.png)


客户端将数据包发送至服务器，然后服务器再将响应数据发送回客户端，这都需要花费一定时间的。这段时间被称为「往返时间」，即RTT（`Round Trip Time`）。此时，每个命令的执行时间可表示为

```s
每个命令的执行时间 = 客户端发送时间 + 服务器处理和返回时间 + 一个网络往返时间（RTT）
```

### 管道技术

可以看到，当执行较多命令时，每个命令的「往返时间」累加起来，对性能还是有一定影响的。

Redis 的底层通信协议对管道（`Pipelineing`）提供了支持。通过管道可以一次性发送多条命令并在执行完后一次性将结果返回。当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出。

管道通过减少客户端与 Redis 的通信次数，来实现降低往返时延累计值的目的。



![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-pipelin-2.png)

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-pipelin-4.png)



**管道（`Pipelineing`）不仅是一种减少往返时间的延迟成本的方法，还大大提高了你在给定的Redis服务器中每秒可执行的总操作量。**

使用管道（`Pipelineing`）时，通常使用单个 `read` 系统调用读取许多命令，并且通过单个 `write` 系统调用传递多个答复。因此，每秒执行的总查询数最初随着较长的管道而几乎呈线性增加，最终可达到不使用流水线获得的基准的 10 倍左右，如下图所示。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-pipelin-3.png)

### 管道压力测试

Redis 自带了一个压力测试工具 `redis-benchmark`，使用这个工具就可以进行管道测试。

1. 首先我们对一个普通的 `set` 指令进行压测，QPS 大约 11W/S。

```s
lbsmacbook-pro:~ lbs$ redis-benchmark -t set  -q
SET: 109289.62 requests per second, p50=0.239 msec 
```

2. 然后我们加入管道选项 `-P` 参数，它表示单个管道内并行的请求数量。可以看到 `P=2` 时，QPS可达 20W/S；`P=5` 时，QPS可达 62W/S。

```s
lbsmacbook-pro:~ lbs$ redis-benchmark -t set -P 2 -q
SET: 208768.27 requests per second, p50=0.247 msec                    

lbsmacbook-pro:~ lbs$ redis-benchmark -t set -P 5 -q
SET: 465116.28 requests per second, p50=0.415 msec      

lbsmacbook-pro:~ lbs$ redis-benchmark -t set -P 10 -q
SET: 625000.00 requests per second, p50=0.663 msec 
```


3. 继续加大 `P` 参数，当 `P=50` 时，QPS 为 67W/S，和 `P=5` 相比，QPS 增幅并不明显。这是因为 Redis 的单线程 CPU 处理能力已经达到了瓶颈。

```s
lbsmacbook-pro:~ lbs$ redis-benchmark -t set -P 50 -q
SET: 675675.69 requests per second, p50=3.207 msec 
```




### 管道不保证原子性
* Redis 执行 LUA 脚本时，会把脚本当成一个命令，故 LUA 脚本可以保证原子性，在执行脚本的时候不会被其他的命令插入。因此，LUA 脚本更适合处理事务。
* 管道虽然也会将多个命令一次性传输到服务端，但在服务端执行的时候仍然是多个命令，所以管道是不具有原子性的，不适合处理事务。
* 就场景上来说，正因为 LUA 脚本会被视为一个命令去执行，因为 Redis 是单线程执行命令的，所以我们不能在 LUA 脚本里写过于复杂的逻辑，否则会造成阻塞，因此 LUA 脚本适合于相对简单的事务场景。


### 管道和脚本

* 大量 Pipelining 应用场景可通过 Redis 脚本（Redis 版本 >= 2.6）得到更高效的处理，后者可在服务器端执行大量工作。
* 脚本的一大优势是可通过最小的延迟读写数据，让读、计算、写等操作变得非常快。Pipeline 在这种情况下不能使用，因为客户端在写命令前需要读命令返回的结果。



### 集群模式下不能使用管道

**管道技术，只能作用在一个 Redis 节点上；集群模式下不能使用管道技术。**


Redis 集群的键空间被分割为 16384 个槽（`slot`），每个主节点都负责处理 16384 个哈希槽中的一部分。在执行具体的 Redis 命令时，会根据 `key` 计算出一个槽位（`slot`），然后根据槽位去特定的节点 Redis 上执行操作。

```s
# 卡槽示例
master1（slave1）： 0~5460
master2（slave2）：5461~10922
master3（slave3）：10923~16383
```

使用管道技术时，一次会批量执行多个命令，那么每个命令都需要根据 `key` 运算一个槽位，然后根据槽位去特定的节点上执行命令，也就是说一次管道操作会使用多个节点的 Redis 连接，而目前集群是不支持这种多节点操作的。


### 优缺点

优点
1. 打包多个命令，减少往返时间
2. 提高了在 Redis服务器中每秒可执行的总操作量，使用管道时，通常使用单个 `read` 系统调用读取许多命令，并且通过单个 `write` 系统调用传递多个答复。


缺点
1. 管道每批打包的命令不能过多，因为使用管道时，Redis 必须在处理完所有命令前，先缓存起所有命令的处理结果，这样就有一个内存的消耗。
2. 管道不保证原子性，执行命令过程中，如果一个命令出现异常也会继续执行其他命令。因此，不适用对可靠性和实时性要求较高的场景。
3. **管道每次只能作用在一个 Redis 节点上，集群模式下不能使用管道技术。**






### 适用场景

有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 Redis 了，那这种场景就不适合使用管道技术。



### 深入理解管道本质

* ref 1-[管道 | Redis深度历险](https://juejin.cn/book/684473324618129422/section/6844733724714598414)

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/redis-pipelin-5.png)




## MEGT和缓存无底洞
* ref 1-[缓存无底洞 | 并发编程网站](http://ifeve.com/redis-multiget-hole/)


### MEGT

```s
# 返回所有(一个或多个)给定 key 的值
# 如果给定的 key 里面，有某个 key 不存在，那么这个 key 返回特殊值 nil 
# 因此，该命令永不失败
MGET key [key ...]
```
一次 `MGET` 命令，可以查询多个 key 对应的值。
1. 在 Redis 单机模式下，一次 `MGET` 命令，查询的多个 key 对应的值，只存储在一台机器上，所以只涉及一次网络请求。
2. Redis 集群部署时，`MGET` 对应的多个 key，可能分布在不同的机器节点。此时，`MGET` 命令会涉及多次网络请求。


### 什么是缓存无底洞

2010 年，Facebook 的工作人员反应，他们的 Memcached 节点 已经达到了 3W 个，储存了数千 G 的缓存。他们遇到了一个问题，在集群节点已经较多的情况下，Memcached 的连接效率下降了，于是他们继续添加 Memcached 节点。但是添加完之后，情况并没有好转（仿佛增加的节点并没有起到任何效果）。这种现象被称为「缓存无底洞」现象。



### 问题的产生原因

键值数据库或者缓存系统，由于通常采用 hash 函数将 key 映射到对应的实例，造成 key 的分布与业务无关。但是由于数据量、访问量的需求，需要使用分布式后（无论是客户端一致性哈性、redis-cluster、codis），批量操作比如批量获取多个 key（例如 Redis 的 `MGET` 操作)，通常需要从不同实例获取 key 值，相比于单机批量操作只涉及到一次网络操作，分布式批量操作会涉及到多次网络 IO。

* Redis 单机部署时，`MGET` 命令是从一台机器取多个 key 的值，只涉及一次网络请求

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-1.png)

* Redis 集群部署时，`MGET` 对应的多个 key，可能分布在不同的机器节点。此时，`MGET` 命令会涉及多次网络请求

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-2.png)




### 问题的危害

1. 客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着实例的增多，耗时会不断增大。
2. 服务端网络连接次数变多，对实例的性能也有一定影响。


### 解决方案的引出

**针对「缓存无底洞」问题，用一句通俗的话总结，更多的机器不代表更多的性能，所谓「无底洞」就是说投入越多不一定产出越多。**

分布式又是不可以避免的，因为我们的网站访问量和数据量越来越大，一个实例根本坑不住，所以「如何在分布式系统中，高效地存储和批量获取数据」是一个难点。


下面，就针对该问题，探讨如何高效地批量获取数据。



### 哈希存储与顺序存储

在分布式存储产品中，「哈希存储」与「顺序存储」是两种重要的数据存储和分布方式，这两种方式不同也直接决定了批量获取数据的不同，所以这里需要对这两种数据的分布式方式进行简要说明。

#### Hash分布

Hash 分布应用于大部分 key-value 系统中，例如 Memcache、Redis Cluster，即使像 MySQL 在分库分表时候，也经常会用 `user%100` 这样的方式分库分表。

Hash 分布的主要作用是将 key 均匀地分布到各个机器，所以它的一个特点就是数据分散度较高，实现方式通常是将 `hash(key)` 得到的整数，和分布式节点的某台机器做映射。

以 Redis Cluster 为例，它采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。一个切片集群被分为 16384（2^14）个 slot（槽），每个进入 Redis 的键值对，根据 key 进行散列，分配到这 16384 插槽中的一个。使用的哈希映射也比较简单，用 CRC16 算法计算出一个 16 bit 的值，再对 16384 取模。Redis Cluster 的 Hash 分布如下图所示。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-3.png)

Hash 分布存在的一个问题就是，映射关系和业务无关，不支持范围查询。


#### 顺序分布

「顺序分布」中，直接按照某个字段的值的顺序进行划分，如下图所示。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-4.png)


「顺序分布」存在的一个问题就是，扩容和缩容时，需要调整的内容太大。



#### 两种分布方式的比较


| 分布方式	| 特点	| 典型产品  |
|----------|------|----------|
| 哈希分布	| 1. 数据分散度高；2. 键值分布与业务无关；3. 无法顺序访问；4. 支持批量操作 | 一致性哈希，Memcache，Redis Cluster |
| 顺序分布	| 1. 数据分散度易倾斜；2. 键值分布与业务相关； 3. 可以顺序访问；4. 支持批量操作 | BigTable，Hbase | 



### 分布式系统中 MGET 的解决方案

分布式系统中，批量查询数据时，常见的优化思路如下
1. 提高命令本身的效率：例如 SQL 优化，命令优化
2. 网络次数：减少通信次数
3. 降低接入成本：长连/连接池，NIO 等
4. IO 访问合并：`O(n)` 到 `O(1)`过程，批量接口（MGET）


如果只考虑减少网络次数的话，`MGET` 会有如下模型

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-5.png)



针对 Redis Cluster 集群部署，`MGET` 的优化方案有如下 4 种
1. 串行 MGET
2. 串行 IO
3. 并行 IO
4. hash-tag 实现

#### 串行 MGET


将 `MGET` 操作（N 个 key）拆分为逐次执行 N 次 get 操作。很明显，这种操作的时间复杂度较高，它的操作时间等于「N 次网络时间」加上「N 次命令时间」。

「串行 MGET」方案中，网络次数是 N。很显然这种方案不是最优的，但是足够简单。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-6.png)


#### 串行 IO

对于 `MGET` 命令中的 N 个 key，利用已知的 `hash` 函数算出 `key`对应的节点 `node`，这样就可以得到一个节点 `node` 和 `key` 的对应关系，记作 `Map<node,somekeys>`。一个节点 `node` 下可能对应多个 `key`。


「串行 IO」方案中，操作时间等于「`node` 次网络时间」加上「 N 次命令时间」，网络次数是节点 `node` 的个数。很明显这种方案比第一种要好很多，但是如果节点数足够多，还是有一定的性能问题。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-7.png)


#### 并行 IO


此方案是将「串行 IO」方案中的最后一步，改为多线程执行。网络次数虽然还是 `node.size()` 次，但网络时间变为 `O(1)`（因为并行执行了），但是这种方案会增加编程的复杂度。


「并行 IO」方案的操作时间，等于「1 次网络时间」加上「N 次命令时间」。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-8.png)



#### hash-tag 实现

Redis 提供了「hash-tag」功能，能够强制一些 key 映射到指定的节点。

假如我们现在使用的是 Redis Cluster 由 10 个节点组成，我们现在有 1000 个k-v，那么按照 hash 函数（CRC 16）规则，这 1000 个 key 会被打散到 10 个节点上。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-9.png)


那么我们能不能像使用单机 Redis 一样，一次 IO 将所有的 key 取出来呢？

hash-tag 提供了这样的功能，如果将上述的 key 改为如下，也就是用大括号括起来相同的内容，那么这些 key 就会到指定的一个节点上。

```s
user1,user2,user3......user1000
{user}1,{user}2,{user}3.......{user}1000
```

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-10.png)



如下图所示，它的操作时间，等于「1 次网络时间」加上「N 次命令时间」。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/redis-mget-network-time-11.png)



该方案有如下两个缺点，所以不建议使用「hash-tag」方案。
1. tag-key 业务维护成本较高
2. tag 分布容易出现数据倾斜

#### 四种批量操作解决方案对比

| 方案	|  优点	 | 缺点	 | 网络 IO  | 
|------|--------|-------|---------|
| 串行 mget	| 1.编程简单；2.少量 keys时，性能满足要求 | 大量 keys 时，请求延迟严重；| O(keys) |
| 串行 IO | 1.编程简单；2.少量节点时，性能满足要求 | 大量节点（node）时，延迟严重	 | O(nodes) |
| 并行 IO |	1.利用并行特性；2.延迟取决于最慢的节点 | 1.编程复杂；2.超时定位较难 | O(max_slow(node)) |
| hash tags	| 性能最高	| 1.tag-key 业务维护成本较高；2. tag 分布容易出现数据倾斜 |	O(1) |



### 总结

「缓存无底洞」问题对资源和性能有一定影响，但是其实大部分系统不需要考虑这个问题，因为
1. 99% 公司的数据和流量无法和 Facebook 相比
2. Redis/Memcache 的分布式集群通常来讲是按照项目组做隔离的，以我们经验来看一般不会超过 50 对主从

上述对 MGET 的优化方案，主要是用来提供一种优化思路，开阔一下视野。

