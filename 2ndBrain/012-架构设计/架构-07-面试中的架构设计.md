
# 架构-07-面试中的架构设计

[TOC]


## 参考资料
* [系统设计入门 | github](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md)
* [十大经典系统架构设计面试题](https://xie.infoq.cn/article/4c0c9328a725a76922f6547ad)
* [架构设计面试题](https://www.cnblogs.com/crazymakercircle/p/14367907.html)

## 更新
* 2022/06/06，撰写



## 系统设计题目回答步骤

* [系统设计面试的答题框架](https://cloud.tencent.com/developer/article/1899760)


| 步骤 | 说明  | 时长（分钟） |
|-----|------|------|
| 1 | 理解问题，设定边界 | 3-10 |
| 2 | 提出整体设计，达成一致 | 10-15 |
| 3 | 深入设计 |  10-25 |
| 4  | 杀青 | 3-5 |


下面进行必要的补充说明。
1. 对于求职者，在弄清问题后，不要马上就给出一个最终的设计版本，因为这通常会是一个错误的版本。**始终要记住，最终的设计是什么样并没有那么重要，重要的信息已经整个面试过程中传递给了面试官。**
2. 所以正确的做法是，在做设计的同时，问面试官的要求是什么，做出合理的假设、取舍，让面试官看出你的思考过程，最终综合所有的信息完成一个还不错的设计。
3. 不要害怕问问题。那并不会说明我们不懂，而是让面试官理解我们的思考过程。



## 物流订单系统设计
* [物流订单模块设计](https://cloud.tencent.com/developer/article/1525148)
* [物流服务与物流详情](https://juejin.cn/post/6844903721625714701)


物流服务主要有三种
1. 普通快递
2. 同城配送
3. 门店自提


物流服务从模型上又分成三个部分
1. 服务模板（标准快递，当日达，次日达）
2. 快递公司模型（顺丰，京东，圆通）
3. 运费模板（顺丰运费模板，京东运费模板）

物流服务从流程上来说分成三个阶段
1. 物流服务的表达
2. 物流服务的路由
3. 物流服务的履行


数据表 MySQL 的设计
1. 物流服务模板 `logistics_service`
   * 服务模板类型（标准快递，当日达，次日达）
   * 创建时间信息
2. 快递公司信息 `logistics_company`
   * 快递公司名称、类型
   * 快递公司信息
3. 物流服务模板与物流公司的关联表
4. 运费模板表
5. 运费模板明细表



物流系统的流程设计（分3步）
1. 物流订单中心
   * 物流订单发货
   * 发送订单发货信息至「物流详情模块」
2. 物流详情模块
   * 接收订单发货消息
   * 创建物流详情单
   * 定时任务查询物流详情，并展示物流详情信息
3. 快递公司
   * 接受物流详情模块传递来的查询物流详情消息
## 订单系统
* [订单系统：从0到1设计思路](https://www.woshipm.com/pd/1392102.html)
* [如何设计电商订单系统](https://www.woshipm.com/pd/3344134.html)


### 订单系统的特点

1. 业务类型不同，订单规则不同
   * 订单系统搭建需要考虑实际业务情况，分商品实物订单，虚拟订单等不同业务
2. 流程复杂，分正向逆向流程
   * 前端用户下单时，正常时的正向流程为，从商品下单，发货，收货到最后的订单交易成功
   * 发生售后异常时的逆向流程为，用户申请退货，到退款结算一系列售后流程
   * 正向流程和逆向流程的规则有很大的不同
3. 信息交互复杂，逻辑性强


### 订单信息展示

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-3.png)



1. 用户信息：用户账号，用户等级；
2. 订单基础信息：父订单，子订单，订单编号，订单状态，订单时间；
3. 收货信息：收货地址，收货人姓名，联系电话，邮箱；
4. 商品信息：SKU信息，规格，商品数量，价格，商品图片，商家，商品链接；
5. 优惠信息：优惠券，促销活动，虚拟币抵扣金额；
6. 支付信息：支付方式，支付单号，支付状态，支付时间，商品总金额，实付金额，运费，虚拟币抵扣金额，促销优惠金额，优惠券优惠金额，总优惠金额；
7. 物流信息：物流公司，物流状态，物流单号；
8. 其他信息：发票信息，下单平台，分销渠道


### 订单状态

不同业务类型商品订单状态不同，实物商品订单和虚拟商品订单状态都有所不同，订单状态最重要的是各个时间节点的数据流转，这里介绍下实物商品订单的订单流转状态

1. 待付款：用户提交订单，尚未付款，等待用户支付，由于待付款状态会锁定库存，所以一般会设置超时自动取消；
2. 待发货：用户付款之后，等待商家发货；
3. 待收货：商家已发货，等待用户收货；
4. 交易成功：用户确认收货后，订单已完成交易；
5. 已取消：付款之前取消订单，超时未付款或用户自动取消订单都会产生这种订单状态
6. 售后中：用户在付款后发货前申请退款，或商家发货后用户申请退换货状态，需要注意的是售后状态也有单独的订单流转状态：待审核，待退货入库，待退款
7. 待换货入库，换货出库中，售后成功；
8. 交易失败：当售后完成后的订单状态，”已取消“的订单状态可以合并到“交易关闭”中。



### 订单的数据统计

> 订单交易维度
1. 统计周期内订单销售额（GMV）【最重要】
2. 订单量：统计周期内订单量
3. 客单价：统计周期内，已支付的订单平均金额
4. 下单用户数支付用户数，订单金额分布，地域分布等等

> 商品分析维度
1. 被下单的商品数：统计周期内，被下单数 > 0的上架商品总和
2. 被支付的商品数：统计周期内，被支付订单数 > 0的上架商品总和
3. 被访商品数：统计周期内，被访问uv数>0的上架商品总和
4. 商品收藏次数，商品销售统计，加购件数等等。

> 订单来源维度
1. 统计每个订单的来源：如H5，公众号，APP，小程序，pc端；
2. 记录每个订单的产生过程，包括在创建之前的商品浏览，加入购物车，提交订单等关键路径的数据分析；
3. 追踪订单来源：包括来源的网站，关键词，来源网站等等


### 订单系统的上下游

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-1.png)


### 订单系统的业务架构

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-2.png)



### 正向流程

以一个通用 B2C 商城的订单系统为例，根据其实际业务场景，其订单流程可抽象为 5 大步骤
1. 订单创建
2. 订单支付
3. 订单生产
4. 订单确认
5. 订单完成

而每个步骤的背后，订单是如何在多系统之间交互流转的，可概括如下图。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-4.png)




### 逆向流程


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-5.png)


逆向流程是各种修改订单、取消订单、退款、退货等操作，需要梳理清楚这些流程与正向流程的关系，才能理清订单系统完整的订单流程。

1. 订单修改
可梳理订单内信息，根据信息关联程度及业务诉求，设定订单的可修改范围是什么，比如：客户下单后，想修改收货人地址及电话。此时只需对相应数据进行更新即可。

2. 订单取消
用户提交订单后没有进行支付操作，此时用户原则上属于取消订单，因为还未付款，则比较简单，只需要将原本提交订单时扣减的库存补回，促销优惠中使用的优惠券，权益等视平台规则，进行相应补回。

3. 退款
用户支付成功后，客户发出退款的诉求后，需商户进行退款审核，双方达成一致后，系统应以退款单的形式完成退款，关联原订单数据。因商品无变化，所以不许考虑与库存系统的交互，仅需考虑促销系统及支付系统交互即可。

4. 退货
用户支付成功后，客户发出退货的诉求后，需商户进行退款审核，双方达成一致后，需对库存系统进行补回，支付系统、促销系统以退款单形式完成退款。最后，在退款/退货流程中，需结合平台业务场景，考虑优惠分摊的逻辑，在发生退款/退货时，优惠该如何退回的处理规则和流程。


###状态机

状态机是管理订单状态逻辑的工具。状态机可归纳为 3 个要素，即
1. 现态：是指当前所处的状态
2. 动作：动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。
3. 次态：动作满足后要迁往的新状态，“次态”是相对于“现态”而言的，“次态”一旦被激活，就转变成新的“现态”了。


状态机的设计需要结合平台实际业务场景，将状态间的切换细化成了执行了某个动作。

以一个 B2C 商城的订单系统举例如下。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-order-6.png)




### 库存扣减

库存扣减，目前主流有两种方式
1. 下单减库存，即用户下单成功时减少库存数量
2. 付款减库存，即用户支付完成并反馈给平台后再减少库存数量


两种方式各有优缺点，因此，需结合实际场景进行考虑，如秒杀、抢购、促销活动等，可使用下单减库存的方式。而对于产品库存量大，并发流量没有那么强的产品使用付款减库存的方式。


#### 下单减库存

即用户下单成功时减少库存数量

* 优势：用户体验友好，系统逻辑简洁；
* 缺点：会导致恶意下单或下单后却不买，使得真正有需求的用户无法购买，影响真实销量
* 解决办法
  * 设置订单有效时间，若订单创建成功 N 分钟不付款，则订单取消，库存回滚；
  * 限购，用各种条件来限制买家的购买件数，比如一个账号、一个ip，只能买一件；
  * 风控，从技术角度进行判断，屏蔽恶意账号，禁止恶意账号购买。

#### 付款减库存

即用户支付完成并反馈给平台后再减少库存数量
* 优势：减少无效订单带来的资源损耗；
* 缺点：因第三方支付返回结果存在时差，同一时间多个用户同时付款成功，会导致下单数目超过库存，商家库存不足容易引发断货和投诉，成本增加。
* 解决办法
  * 付款前再次校验库存，如确认订单要付款时再验证一次，并友好提示用户库存不足；
  * 增加提示信息：在商品详情页，订单步骤页面提示不及时付款，不能保证有库存等
## 抖音支付十万级TPS流量发券实践
* [抖音支付十万级 TPS 流量发券实践](https://juejin.cn/post/7114262217301704712)


## LaaS、PaaS、SasS

* LaaS（Infrastructure-as-a-Service），基础设置即服务
* PaaS（Platform-as-a-Service），平台即服务
* SaaS（Software-as-a-Service），软件即服务


### SaaS多租户设计
* [关于SaaS多租户系统设计的思考](https://blog.csdn.net/u014203449/article/details/120214467)


#### 场景

软件的多租户设计，也是 SaaS 设计，软件的用户可以以租户为单位使用系统。

举个栗子，比如一个律师事务所系统，事务所 1 和事务所 2 共同使用这一个系统。
1. 两个事务所的数据是完全隔离，互不影响。
2. 甚至两家事务所访问系统域名地址也不同，比如 `http://law1`，`http://law2`
3. 可能两个系统内功能也有所不同，事务所 2 多掏了钱用的是高级版，事务所 1 用的普通版
4. 一个事务所系统下可以创建用户、角色等等，与另一个事务所系统无关
5. 租户和用户的关系，可能是一对多，也可能是多对多。一对多就是先选择用户再创建租户，多对多说明用户可能在多个租户下，涉及到切换租户的问题。

这样的系统有很多，比如钉钉，钉钉里一个单位就是一个租户，当然钉钉用户可以在多个租户下，可以切换租户


#### 哪些数据该隔离


首先租户数据隔离，要明确哪些该隔离。
1. 数据库数据肯定要隔离，持久化的数据。
2. 缓存也应该隔离，否则不同的两个系统用同一份代码，租户可能会获取到其他租户的缓存。
3. 中间件，消息队列
4. 文件存储，文件的获取地址 url 如果是由数据库表得到，那共用一个文件存储也没关系。
5. 凡是中间件，都应该想想是否要隔离。

#### 哪种场景要隔离

凡是调用程序的方式，都应该考虑是否应该隔离。
1. http 调用
2. 服务间调用，如feign、rpc
3. 定时任务
4. 消息队列订阅发布


#### 隔离设计思路

面对不同的应用场景，应该有不同的隔离思路，没有最好的方案，适合需求即可

> 数据表隔离

在表设计增加租户 id 字段，即所有租户用的表相同，数据也都存储在一起，这样所有跟租户数据有关的查询 sql 都要加 tenant_id=xxx。

这种方式适合租户较少的情况，比如开发教学系统，一个学校会有几个校区，每个校区有自己的数据，一个公司有几个子公司，每个子公司直接数据隔离。

因为学校校区不会有很多，子公司也不多，就比较适合，共用一个数据库也够用。如果采用其他方式反倒浪费资源。

> 数据库隔离

每个租户用单独的数据库，即数据源不同，但租户用的前后端应用程序是一个。

这种方式适合每个租户的软件需求大部分一致，这样可以共用一份前后端代码，如果有些许的需求不同，可以利用租户页面菜单进行控制，通过租户菜单数据，让租户页面显示不同。


数据源不同涉及到数据源的切换问题，主要靠后端程序进行。基本思路是请求中携带租户标志，可以是域名不同、请求头添加租户标志等等，后端拦截器中设置切换数据源。如果是分布式系统，则每个分布式系统都得有切换数据源的功能。

> 应用隔离

租户使用的应用直接不同，租户 1 使用应用 1，租户 2 使用应用 2，两个应用部署的服务器不同。

这样适合租户软件需求不一致，特殊化定制需求，或者某个租户有钱，专门为自己开设单独应用、服务器，保证性能。

这样相当于为租户单独部署一套系统，需要在网关针对租户域名或其他标识 ，路由到租户应用。

实际工作中，可以将数据库隔离和应用隔离结合起来，付费特殊化定制的租户就用应用隔离，普通租户就用数据库隔离、使用同一个应用，两个方案结合使用



## 异地多活
* [搞懂异地多活，看这篇就够了](http://kaito-kidd.com/2021/10/15/what-is-the-multi-site-high-availability-design/)

1. 单机架构
2. 主从副本（读写分离）
3. 同城灾备
4. 同城双活
5. 两地三中心
6. 异地双活（避免跨机房调用）


## 高并发优惠券系统
* [如何从零搭建10万级 QPS 大流量、高并发优惠券系统 | 掘金](https://juejin.cn/post/7087824893831544845)

### 需求拆解
1. 要配置券，会涉及到券批次（券模板）创建，券模板的有效期以及券的库存信息
2. 要发券，会涉及到券记录的创建和管理（过期时间，状态）

因此，我们可以将需求先简单拆解为两部分，如下图所示。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-1.png)

同时，无论是券模板还是券记录，都需要开放查询接口，支持券模板/券记录的查询。


### 技术选型
1. MySQL 用于存储
   * 券模板记录
   * 券发放记录
2. Redis 用于缓存
3. MQ 消息队列

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-2.png)



### 发券核心逻辑

发券流程分为三部分
1. 参数校验
2. 幂等校验
3. 库存扣减


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-3.png)


幂等操作用于保证发券请求不正确的情况下，业务方通过重试、补偿的方式再次请求，可以最终只发出一张券，防止资金损失。

### 券过期

券过期是一个状态推进的过程，这里我们使用 RocketMQ 来实现。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-4.png)



### 存储瓶颈及解决方案

> 瓶颈

在系统架构中，我们使用了 MySQL、Redis 作为存储组件。我们知道，单个服务器的 I/O 能力终是有限的，在实际测试过程中，能够得到如下的数据
1. 单个 MySQL 的每秒写入在 4000 QPS 左右，超过这个数字，MySQL 的 I/O 时延会剧量增长。
2. MySQL 单表记录到达了千万级别，查询效率会大大降低，如果过亿的话，数据查询会成为一个问题。
3. Redis 单分片的写入瓶颈在 2w 左右，读瓶颈在 10w 左右。

> 解决方案
1. 读写分离。在查询券模板、查询券记录等场景下，我们可以将 MySQL 进行读写分离，让这部分查询流量走 MySQL 的读库，从而减轻 MySQL 写库的查询压力。
2. 分治。在软件设计中，有一种分治的思想，对于存储瓶颈的问题，业界常用的方案就是分而治之：流量分散、存储分散，即「分库分表」。


> 业务层面的处理
1。 发券，归根结底是要对用户的领券记录做持久化存储。对于 MySQL 本身 I/O 瓶颈来说，我们可以在不同服务器上部署 MySQL 的不同分片，对 MySQL 做水平扩容，这样一来，写请求就会分布在不同的 MySQL 主机上，这样就能够大幅提升 MySQL 整体的吞吐量。
2. 给用户发了券，那么用户肯定需要查询自己获得的券。基于这个逻辑，我们以   `user_id` 后四位为分片键，对用户领取的记录表做水平拆分，以支持用户维度的领券记录的查询。
3. 每种券都有对应的数量，在给用户发券的过程中，我们是将发券数记录在 Redis 中的，大流量的情况下，我们也需要对 Redis 做水平扩容，减轻 Redis 单机的压力。

### 热点库存问题及解决方案

> 存在的问题

大流量发券场景下，如果我们使用的券模板为一个，那么每次扣减库存时，访问到的 Redis 必然是特定的一个分片，因此，一定会达到这个分片的写入瓶颈，更严重的，可能会导致整个 Redis 集群不可用。


> 解决方案

热点库存的问题，业界有通用的方案：即，扣减的库存 key 不要集中在某一个分片上。如何保证这一个券模板的 key 不集中在某一个分片上呢，我们拆 key（拆库存）即可。如图所示。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-5.png)

在业务逻辑中，我们在建券模板的时候，就将这种热点券模板做库存拆分，后续扣减库存时，也扣减相应的子库存即可。




### 建券

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-6.png)


### 库存扣减

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/design-coupon-7.png)


对于「扣减子库存」问题，每次都是从 1 开始进行的话，那对 Redis 对应分片的压力其实并没有减轻，因此，我们需要做到：每次请求，随机不重复的轮询子库存。

以下是本项目采取的一个具体思路。

Redis 子库存的 key 的最后一位是分片的编号，如 `xxx_stock_key1`、`xxx_stock_key2` ……，在扣减子库存时，我们先生成对应分片总数的随机不重复数组，如第一次是 `[1,2,3]`，第二次可能是 `[3,1,2]`，这样，每次扣减子库存的请求，就会分布到不同的 Redis 分片上，缓轻 Redis 单分片压力的同时，也能支持更高 QPS 的扣减请求。

这种思路的一个问题是，当我们库存接近耗尽的情况下，很多分片子库存的轮询将变得毫无意义，因此我们可以在每次请求的时候，将子库存的剩余量记录下来，当某一个券模板的子库存耗尽后，随机不重复的轮询操作直接跳过这个子库存分片，这样能够优化系统在库存即将耗尽情况下的响应速度。

业界针对 Redis 热点 key 的处理，除了分 key 以外，还有一种 key 备份的思路，即将相同的 key，用某种策略备份到不同的 Redis 分片上去，这样就能将热点打散。这种思路适用于那种读多写少的场景，不适合应对发券这种大流量写的场景。在面对具体的业务场景时，我们需要根据业务需求，选用恰当的方案来解决问题。






## 大流量活动下钱包提现方案的设计和实现
* [大流量活动下钱包提现方案的设计与实现 | 掘金](https://juejin.cn/post/7090490603712020488)
* [春节钱包大流量奖励系统入账及展示的设计与实现 | 掘金](https://juejin.cn/post/7081541862741245989)

### 大流量下的主要问题
1. 入账延迟和提现限制
2. 高并发
3. 资金安全


### 设计方案
1. 延时放量
   * 为防止瞬间流量突增过高可能引发数据库连接问题，我们通过在配置平台上进行配置，针对用户 id 进行取模后的结果进行分批放开。
   * 在有限的情况下，确保用户入账无误。
   * 延迟到凌晨 1 点分批次放开提现有效降低了用户提现的并发，保障了用户提现体验。
2. MQ 异步出款
   * 提现分为账户余额扣减和财经出款两个步骤。可使用 MQ 进行解耦，用户进行提现后，先提示 “提现成功，资金到账中”，并将财经出款任务放入到 MQ 队列中，异步处理
   * 可使用 Rocket MQ 的事务消息
   * 当 MQ 消费成功时则顺利出款，当消费失败或被限流时则返回错误，MQ 会进行消费重试。我们在这里设置 MQ 最大重试次数为 3 次，如果消息没有超过最大重试次数，则被放入 retry 队列；如果消息达到最大重试次数，则放入死信队列不再处理。（也可以针对死信队列中的消息，尝试后续人工触发消费或者定时任务触发消费）
3. 定时任务
   * 防止提现订单因 MQ 多次重试消费失败或其他原因导致状态一直卡在某个中间状态停止更新，我们额外设置了定时任务进行补单操作推进提现状态。
   * 每小时固定从数据库中捞取已被创建超过 4 个小时且当前还处于未完成状态的订单，并根据其当前状态进行推动。
4. 提现资金安全
   * 订单幂等保证。一次提现，只对应一次余额扣减动作，并且只对应一次财经出款操作。
   * 对账校验，可分为准实时校验和天级校验。准实时校验中，可以订阅活动账户 DB、钱包提现 DB、财经出款 DB 三个数据库的 binlog 日志，分析 binlog 日志，比较是否有差异。对于天级校验，可将天级数据落到 hive 表中，进行分析处理。

| 比较项 | 对账平台-准实时 | 对账对账平台-天级对账 | 线上服务对账| 
|--------|--------------|--------------------|----------|
| 对账时效| 准实时（5 分钟内）| 天级（t+1 级别）| 准实时 |
| 优点| 可及时发现问题，对账双方任一方存在数据缺失或不一致的情况，会报警| 对账双方任一方存在数据缺失或不一致即报警，天级对账减少了网络抖动引起的误报|准实时，只对提现终态订单进行校验，有查单重试机制避免了网络抖动引起的误报 |
| 缺点| 网络抖动可能引起误报 | 对账时效低，一天后才会发现 | 无法发现提现订单缺失的问题 | 
| 核对数据 | binlog | hive | binlog |



### 前期元
1. 提前演练
2. 充分压测
3. 除夕提现活动当日剧本
   * 执行细节
   * 配置校验（double check）
   * 容灾方案
   * 交叉检查


## 火车票查询/订票算法

* [火车票查询/订票算法初探 | 掘金](https://juejin.cn/post/7093418618108510244)



假设某列车共途径 9 站，`A-B-C-D-E-F-G-H-I`。

每位乘客实际上是完成连续的、一段又一段的乘段，则每个席位的可划分为8个乘段，以二进制表示为 `11111111`。

此时席位表的数据结构类似于下面的结构

| 席位号 | 其他字段 | 乘段码 |
| 14A | ... | 11111111 |
| 14B | ... | 00011111 |

假设乘客需要从 B 点到 E 点，则乘客的车票需求为 `01110000`。

查询时，对通过车票需求和席位表的段位码进行按位与，得到的结果与乘客需求相同的，就意味着可以出售，从而获得余票数。（这里先不考虑乘客选定车站时需要查询出的多个车次，只针对单个车次）

```s
11111111 & 01110000 = 01110000 √

00011111 & 01110000 = 00010000 ×
```

原则上，当每次乘客订票时，系统为其选择 1 最少的符合条件的席位，能够达到席位的最佳利用。

如果乘客退票，只需要将乘客的车票与原本的席位的段位码按位或 `|`，则可完成退票的操作。




## 全网显示IP归属地

* ref 1-[全网显示 IP 归属地，是怎么实现的 | CSDN](https://blog.csdn.net/bjweimengshu/article/details/124791326)



在我们印象中，我们都知道可以通过 IP 地址找到某个人。但当我们细想一下，我们会发现其实 IP 地址与地理位置并不是直接相关的。那我们到底是如何通过 IP 地址找到地址的呢？

答案是「通过自治系统（Autonomous System）」。

互联网是由不同网络组成的网络，「自治系统」是组成 Internet 的大型网络，连接到 Internet 的每台计算机或设备都连接到一个 AS，而每一个自治系统都会有一个编码，我们称之为 ASN。



可以认为 AS 类似于一个城镇的邮局。

邮件从一个邮局到另一个邮局，直到到达正确的城镇为止，然后该城镇的邮局将在该城镇内传递邮件。每个 AS 都控制一组特定的 IP 地址，就像每个镇的邮局负责将邮件传递到该镇内的所有地址一样。

通常，每个 AS 由单个大型组织（例如 Internet 服务提供商（ISP）、大型企业技术公司、大学或政府机构）运营。

**到这里，我们可以捋清楚这样一个逻辑关系：IP地址 -> 地址块 -> 自治网络编码（ASN） -> 组织 -> 国家。**

通过 IP 地址，我们就可以定位到一个大致的地理位置，例如，北京朝阳区、深圳南山区等。例如我现在的 IP 地址就归属于编码为 `AS4xxx` 这个自治网络，通过这个 ASN 可以知道位置在中国深圳，这个 ASN 编码所属的组织为中国电信。

但是通过 ASN 也只能是找到县级或者区级的地理位置，再细的位置就找不到了。

但怎么有些时候同学说，他被查水表了，直接定位到某个单元某一户呢？其实原理也很简单！上面我们说到可以根据 IP 地址定位到 ASN 所属组织，而 ASN 所属组织在进行 IP 地址分配的时候，都是会进行 IP 地址分配记录的。

某个 IP 地址分配给了谁，都记录得一清二楚。因此警察叔叔想找你喝茶，那还不是一抓一个准。

但要提示一下的是，并不是谁都有那个权限去运营商查询这些数据。所以那些说可以爬着网线找到你的人，基本上可以忽略，都是在吓唬你。只有警察叔叔立案，并且出示相关手续之后才可以进行数据查询。



## 为什么应用刚启动时候比较卡，过一会儿就好了
* ref 1-[阿里终面：为什么应用刚启动的时候比较卡，过一会就好了](https://www.hollischuang.com/archives/6654)


有如下两个思考方向
1. 如果是前端 App，可能涉及到资源懒加载，就是第一次启动时候只加载必要核心模块，其余非核心、非必要模块和资源，会在第一次使用时加载，加载后可缓存，如 React Native 的懒加载
2. 如果是涉及到接口请求，第一次请求时候走 DB，第二次走缓存，表现为接口响应时间大大缩短
3. 针对 Java 技术栈的应用（如 Spring 等），Java 有 JIT 编译的技术，详情参考上述参考资料 *ref-1*
   * 应用刚启动是，程序运行是边解释边运行，效率较低
   * 一旦解释器对 CPU 资源占用比较大的话，就会间接的导致 CPU、LOAD 等飙高，导致应用的性能进一步下降。这也是为什么很多应用在发布过程中，会出现刚刚重启好的应用会发生大量的超时问题了。
   * 程序运行一段时间后，JIT 编译器可以对热点代码进行优化。
   * 「热点代码」需要程序运行一段时间才能定位出哪些是热点代码，所以在应用刚启动时候，JIT 是无法确定哪些是热点代码的。

> JIT 编译是动态编译的一种特例。JIT 可以提高 Java 程序的运行效率。若没有 JIT 编译，字节码需要经过解释器解释再运行。使用 JIT 编译后，可以将字节码编译成平台相关的原生机器码，进行相关优化后将其缓存下来，以备下次使用。如果 JIT 对每条字节码都进行编译、缓存，会增加开销，因此 JIT 只对「热点代码」（比如高频度使用的方法）进行即时编译。



最后，针对「应用程序刚启动时候有点卡」的问题，如何进行解决或减缓卡顿程度呢？有如下两种思路
1. 提升 JIT 优化的效率
   * 可以尝试下阿里开发的 JDK —— Dragonwell，它相比 OpenJDK 提供了一些专有特性，其中一项叫做 `JwarmUp` 的技术就是解决 JIT 优化效率的问题的。
   * `JwarmUp` 技术主要是通过记录 Java 应用上一次运行时候的编译信息到文件中，在下次应用启动时，读取该文件，从而在流量进来之前，提前完成类的加载、初始化和方法编译，从而跳过解释阶段，直接执行编译好的机器码。
2. 降低瞬时请求量
   * 类似「缓存预热」的思想，在应用刚刚启动的时候，通过调节负载均衡，不要很快的把大流量分发给刚启动的机器，而是先分给它一小部分流量，通过这部分流量来触发 JIT 优化，等优化好了之后，再把流量调大。



## 如何设计一个指标体系
* ref 1-[系统的设计一个指标体系 | 知乎](https://zhuanlan.zhihu.com/p/360844908)


### 什么是指标体系

什么是指标体系？用一句简洁的话阐述，就是 “对业务有帮助的统计结果”。什么是有帮助？即 “描述发生了什么”、“度量发生了多少” 以及 “拆解发生的原因”，从而为业务提供帮助。

### 指标的分类

关于指标的分类，个人倾向于两种分类方式
1. 原子指标
   * 不加任何修饰词，比如 PV、UV、订单量
2. 派生指标，也叫复合指标
   * 通过四则运算或修饰限定得出，比如平均交易金额、购买转化率、近 N 天订单量

以下两个图是网上讲指标最常用的两个图，这里供大家参考。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/system-rule-1.png)


指标体系要做的，技术从不同的 “维度” 梳理业务过程，将零散的、有关联性的指标，系统化的组织起来，通过数据看板或接口形式，提供给运营、算法等不同的业务方使用。对于使用指标体系的人来说，指标体系能够把业务体系化的展示出来，提高发现问题、分析问题、解决问题的效率。

### 如何设计指标分析

“指标体系”，代表的是对业务的分析思路。总的而言，大体有三个阶段
1. 圈定业务目标
2. 建立分析模型
3. 统计及展示数据

定义指标体系，首先且最重要的一步，是要与高层的战略目标达成一致，不能 “你说你的规划、我玩我的数据”。在实际工作中，指标与 KPI 是强相关的，数据是提高绩效的一种利器。

比如今年的电商业务，目标是提高收入，那么平台的交易量就要上去，指标体系就要围绕订单量来展开；比如今年的企业业务，希望能够获得更多的潜在客户，那么如何提高平台的注册用户量，就是指标体系的设计目标……

其次，选择合适的分析模型，常见的有 OSM 方法、PLC 模型、AARRR 等。

OSM 是一种如何将大目标拆解到小行动的方法。
1. O：目标 —— 用户使用产品的目标是什么？产品满足了用户的什么需求？
2. S：策略 —— 为了达成上述目标我采取的策略是什么？
3. M：度量 —— 这些策略随之带来的数据指标变化有哪些？

例如在云计算行业，OSM 的拆分可以按照下面的示例进行。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/system-rule-2.jpeg)


PLC 模型则是另一种常见的方法论，即产品生命周期理论，将产品分成了探索、成长、成熟和衰退四个周期。
1. 探索：关注用户的关键行为，比如 PV、UV、转化率等；
2. 成长：关注用户的留存情况，比如留存率、自传播量等；
3. 成熟：关注用户的活跃与商业化，比如DAU、付费用户数等；
4. 衰退：关注用户的流失情况，比如流失用户数、召回量等。




## 商品无限极分类存储
* ref 1-[在数据库中存储一棵树，实现无限级分类 | Segmentfault](https://segmentfault.com/a/1190000014284076)
* ref 2-[ClosureTable | github](https://github.com/Kaciras/ClosureTable)
* ref 3-[电商项目数据库设计 | 掘金](https://juejin.cn/post/6956502460907126791)


1. 思路1：直接记录父分类的引用
   * 每一个分类存储一个 `parent` 属性，记录它的父级类目 ID
2. 思路2：路径列表
   * 每一个分类存储一个路径 `path` 属性，记录从顶级分类到当前分类的路径上，遍历到的所有的分类的 ID
   * 数据库中字段长度是有限的，所以不可能做到存储无限长度的 `path` 值，也就做不到无限极分类
3. 思路3：前序遍历树
4. 思路4：基于 ClosureTable（闭包树）的无限级分类存储，定义关系表 `CategoryTree`，其包含 3 个字段
   * `ancestor` 祖先：上级节点的 id
   * `descendant` 子代：下级节点的 id
   * `distance` 距离：子代到祖先中间隔了几级



## 单点登录
* ref 1-[单点登录（SSO）看这一篇就够了](https://developer.aliyun.com/article/636281)
* ref 2-[单点登录（SSO）的设计与实现](https://ken.io/note/sso-design-implement)

SSO 英文全称 Single Sign On，单点登录。SSO 指的是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。


### 普通的登录认证机制

我们在浏览器（Browser）中访问一个应用，这个应用需要登录，我们填写完用户名和密码后，完成登录认证。这时，我们在这个用户的 session 中标记登录状态为 yes（已登录），同时在浏览器（Browser）中写入 Cookie，这个 Cookie 是这个用户的唯一标识。

下次我们再访问这个应用的时候，请求中会带上这个 Cookie，服务端会根据这个 Cookie 找到对应的 session，通过 session 来判断这个用户是否登录。如果不做特殊配置，这个 Cookie的名字叫做 sessionid，值在服务端（server）是唯一的。



### cookie的处理


Cookie 的作用在于充当一个信息载体在 Server 端和 Browser 端进行信息传递，而 Cookie 一般是以域名为分割的，例如 **`a.xxx.com` 与 `b.xxx.com` 的 Cookie 是不能互相访问的，但是子域名是可以访问上级域名的 Cookie 的。** 即 `a.xxx.com` 和 `b.xxx.com` 是可以访问 `xxx.com` 下的 Cooki e的，于是就能将顶级域名的 Cookie 作为 `sessionId` 的载体。


### session的存储

使用 Redis 存储 session，分布式存储。



### 同域下的单点登录


## 如何设计一个短链接生成系统

* ref 1-[你来设计一个短链接生成系统吧](https://segmentfault.com/a/1190000041063901)
* ref 2-[短网址(short URL)系统的原理及其实现](https://hufangyun.com/2017/short-url/)




### 短链接请求示例

一次短链接请求过程如下。
1. 用户访问短链接，请求到达服务器。
2. 服务器将短链接装换成为长链接，然后给浏览器返回重定向的状态码 301/302
* 301 永久重定向，会导致浏览器缓存重定向地址，短链接系统统计访问次数会不正确
* 302 临时重定向，可以解决次数不准的问题，但是每次都会到短链接系统转换，服务器压力会变大
3. 浏览器拿到重定向的状态码，以及真正需要访问的地址，重定向到真正的长链接上。
4. 从下图可以看出，确实链接被 302 重定向到新的地址上去，返回的头里面有一个`Location` 字段，就是所要重定向的地址。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/tiny-url-design-1.png)

### 需要实现的功能

短链接生成系统需要解决两个方面的问题
1. 如何将一个长链接映射为短链接
2. 如何根据一个短链接获取它对应的长链接地址


在浏览器输入一个短链接后，会进行重定向，映射到对应的长链接。





### 解决方案

设计方案主要包括
1. 全局发号器
2. id 进制转换
3. 可以引入有效期的概念，对一些短连接设计过期时间


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/system-short-link-design-1.png)


#### 全局发号器

比如维护一个全局自增 ID，这个 ID 对应一个长连接，可以将这个对应关系存到 MySQL 或者 Redis。

每次有一个新的长 URL 进来，发号器就加 1。

全局自增 ID 的生成方案如下。
1. 数据库自增主键
2. UUID
3. Redis
4. Twitter - Snowflake 算法



|   方案   |   顺序性  |      重复性    |  存在的问题  |
|---------|----------|---------------|-------------|
| 数据库自增主键 |  递增 |   不会重复   | 数据库宕机不可用 |
| UUID   |   无序列 | 通过多位随机字符串做到极低的重复概率，但理论上仍会出现重复 | 一直可用 |
| Redis |  递增  |  RDB持久化模式下，会出现重复  | Redis宕机不可用 |
| Snowflake 算法 |  递增  |   不会重复 | 时钟回拨 | 



只使用全局发号器方案时，对应数据库的存储字段如下所示。

| id	| url  |
|-------|-------|
| 1	    | https://gd.10086.cn/gmccapp/w... |

#### id 进制转换

直接用递增的数字，有两个坏处
1. 数字很大的时候，还是很长
2. 递增的数字，不安全，规律性太强了


可以考虑 id 进制转换，比如我们使用大小写字母加上数字构成短链接，由 `a-z`，`A-Z`，`0-9` 组成，相当于（26+26+10）= 62 进制的数字。所以可以将问题转化为如何将 id 转换成为 62 进制的数字。

目前全球有 58 亿的网页，Java 中 int 取值最多是 2^32 = 4294967296 < 43 亿 < 58 亿，long 取值是 2^64 > 58 亿。所以如果是用数字的话，int 勉强能够支撑（毕竟不是所有网址都会调用短链服务创建短链），使用 long 就比较保险，但会造成空间浪费，具体使用哪种类型，需要根据业务自己判断了。


所以，一个更好的方案是，使用全局发号器生成 id，然后再通过 id 转换，转换一个 62 进制数字。此时数据库存储的字段信息如下所示。

| id	|  key	| url  |
|-------|--------|------|
| 27095455234| tzHLFw | https://gd.10086.cn/gmccapp/w... |



#### 有效期设置

可以引入有效期的概念，对一些短连接设计过期时间。


## 如何手写一个线程池
* [Java线程池原理——自己手写线程池](https://zhuanlan.zhihu.com/p/62394330)
* [手写线程池，对照学习ThreadPoolExecutor线程池实现原理](https://bbs.huaweicloud.com/blogs/306987)

## APM和分布式追踪traceId

* [APM 系统预览 | 掘金](https://juejin.cn/post/7012230328181850126)
* [一个著名的日志系统是怎么设计出来的](https://www.techug.com/post/how-log4j-designed/)


1. 前端统计用户请求的信息，如机器的硬件信息（UUID，EMI，机器唯一编码等），发起 HTTP 请求，**放在 `header` 中传递给后端。**
2. `Trace` 表示一次请求的完整的树形结构，用来记录请求之间的关系，一个Trace 由一个 Span 或者多个 Spen 组合而来。
3. `SpanContext` 表示分布式追踪的上下文信息，包括 `Trace ID`，`Span ID` 以及其它需要传递到下游服务的内容。
4. 一个 OpenTracing 的实现需要将 `SpanContext` 通过某种序列化协议 (Wire Protocol) 在进程边界上进行传递，以将不同进程中的 Span 关联到同一个 Trace 上。**对于 HTTP 请求来说，SpanContext 一般是采用 HTTP header 进行传递的。**
5. Span 翻译为跨度，可以被理解为一次方法调用,一个程序块的调用，或者一次RPC/数据库访问。只要是一个具有完整时间周期的程序访问都可以用 Span 表示。
6. Trace 和 Span 组成了一个调用链：Trace 代表了一个端到端的分布式调用，Span 是该调用中间的一段。SpanContext 则用于将一个 Span 的上下文传递到其下游的 Span 中，以将这些 Span 关联起来。
7. 在分布式系统中，了解「日志调用链-MDC/NDC」。
## 如何设计一个日志系统

* ref 1-[手把手教你从零设计一个日志框架](https://segmentfault.com/a/1190000038760707)


### 输出内容-LoggingEvent
对于一条日志，需要包含以下几个信息
1. 日志时间戳
2. 线程信息
3. 日志名称
4. 日志级别
5. 日志主体（需要输出的内容）


为了方便的管理输出内容，现在需要创建一个输出内容的类来封装这些信息。

```java
public class LoggingEvent {
    public long timestamp;//日志时间戳
    private int level;//日志级别
    private Object message;//日志主题
    private String threadName;//线程名称
    private long threadId;//线程id
    private String loggerName;//日志名称
    
    //getter and setters...
    
    @Override
    public String toString() {
        return "LoggingEvent{" +
                "timestamp=" + timestamp +
                ", level=" + level +
                ", message=" + message +
                ", threadName='" + threadName + '\'' +
                ", threadId=" + threadId +
                ", loggerName='" + loggerName + '\'' +
                '}';
    }
}
```

对于每一次日志打印，应该属于一次输出的「事件（Event）」，所以这里命名为 `LoggingEvent`。


### 输出组件-Appender

有了输出内容之后，现在需要考虑输出方式。输出的方式可以有很多
1. 标准输出/控制台（Standard Output/Console）
2. 文件（File）
3. 邮件（Email）
4. **消息队列（MQ）**
5. 数据库




现在将输出功能抽象成一个组件，即「输出器（Appender）」，这个 Appender 组件的核心功能就是输出，下面是 Appender 的实现代码。

```java
public interface Appender {
    void append(LoggingEvent event);
}
```

不同的输出方式，只需要实现 Appender 接口做不同的实现即可，比如 `ConsoleAppender`，输出至控制台。


```java
public class ConsoleAppender implements Appender {
    private OutputStream out = System.out;
    private OutputStream out_err = System.err;

    @Override
    public void append(LoggingEvent event) {
        try {
            out.write(event.toString().getBytes(encoding));
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```


### 日志级别-Level

日志框架还应该提供日志级别的功能，程序在使用时可以打印不同级别的日志，还可以根据日志级别来调整那些日志可以显示，一般日志级别会定义为以下几种，级别从左到右排序，只有大于等于某级别的 LoggingEvent 才会进行输出。

```s
ERROR > WARN > INFO > DEBUG > TRACE
```

现在来创建一个日志级别的枚举，只有两个属性，一个级别名称，一个级别数值（方便做比较）。

```java
public enum Level {
    ERROR(40000, "ERROR"), 
    WARN(30000, "WARN"), 
    INFO(20000, "INFO"), 
    DEBUG(10000, "DEBUG"), 
    TRACE(5000, "TRACE");

    private int levelInt;
    private String levelStr;

    Level(int i, String s) {
        levelInt = i;
        levelStr = s;
    }

    public static Level parse(String level) {
        return valueOf(level.toUpperCase());
    }

    public int toInt() {
        return levelInt;
    }

    public String toString() {
        return levelStr;
    }

    public boolean isGreaterOrEqual(Level level) {
        return levelInt>=level.toInt();
    }
}
```

日志级别定义完成之后，再将 LoggingEvent 中的日志级别替换为这个 Level 枚举。

```java
public class LoggingEvent {
    public long timestamp;//日志时间戳
    private Level level;//替换后的日志级别
    private Object message;//日志主题
    private String threadName;//线程名称
    private long threadId;//线程id
    private String loggerName;//日志名称
    
    //getter and setters...
}
```

现在基本的输出方式和输出内容都已经基本完成，下一步需要设计日志打印的入口，毕竟有入口才能打印嘛。

### 日志打印入口-Logger


现在来考虑日志打印入口如何设计，作为一个日志打印的入口，需要包含以下核心功能
1. 提供 error/warn/info/debug/trace 几个打印的方法
2. 拥有一个name属性，用于区分不同的 logger
3. 调用 appender 输出日志
4. 拥有自己的专属级别（比如自身级别为 INFO，那么只有 INFO/WARN/ERROR才可以输出）

先来简单创建一个 Logger 接口，方便扩展。

```java
public interface Logger{
    void trace(String msg);

    void info(String msg);

    void debug(String msg);

    void warn(String msg);

    void error(String msg);

    String getName();
}
```

### 日志层级-Hierarchy

### 日志创建-LoggerFactory

为了方便的构建 Logger 的层级结构，每次 new 可不太友好，现在创建一个 LoggerFactory 接口。


```java
public interface ILoggerFactory {
    //通过class获取/创建logger
    Logger getLogger(Class<?> clazz);
    //通过name获取/创建logger
    Logger getLogger(String name);
    //通过name创建logger
    Logger newLogger(String name);
}
```

## 如何设计一个点赞系统
* ref 1-[设计一个点赞功能 | 掘金](https://juejin.cn/post/6956866483242663967) 
* ref 2-[设计点赞系统 | CSDN](https://blog.csdn.net/weixin_43946031/article/details/117144912)
* ref 3-[新浪微博系统的点赞是如何设计的 | 知乎](https://www.zhihu.com/question/63947513)、[微博计数器的设计](https://blog.cydu.net/weidesign/2012/09/09/weibo-counter-service-design-2/)


### 场景分析


1. 用户应该可以对内容和视频进行评价，喜欢或不喜欢



### 技术设计
1. Redis 缓存处理
   * 用户对一个内容不能重复点赞，可以使用 `set` 数据结构进行去重，`key` 为 `点赞目标id`，`value`（或 `member`）为 `用户ID`
   * 对于 `set` 数据结构，使用 `SISMEMBER KEY VALUE ` 判断用户是否点过赞
   * 对于 `set` 数据结构，使用 `SCARD key` 得到集合中元素总数，即点赞总数
   * 也可以单独设置个 `key`，使用 `incrby key`，统计点赞总数

```s
# 插入一条点赞
# 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略
SADD key member [member ...]


# 判断一个用户是否对该内容点过赞
# 判断 member 元素是否集合 key 的成员
SISMEMBER key member


# 用户取消点赞
# 移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略
SREM key member


# 统计一个评论的点赞总数
# 返回集合 key 的基数(集合中元素的数量)
SCARD key

# 如何要查看该内容的点赞用户列表
# 返回一个集合的全部成员
SINTER key 
```


2. 用户数据库
3. 持久化
   * 采用 Quartz 等任务调度系统，每 5 分种运行一次任务，把点赞数据从redis 缓存中取出做持久化到 MySQL
   * 也可以使用 Redis 的 RDB 和 AOF 持久化
   * 或者使用 MQ 方式，发消息给 MySQL 或 Hbase 进行落库。
4. 数据的冷热分离
   * 对于热门点赞，使用 Redis
   * 对于冷门数据，使用 Hbase 或者 MySQL，降低硬件开销的成本


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/set-like-system-1.png)


### 点赞操作的原子性

利用 Redis 的 `setnx` 命令，设置用户点赞，若用户已经点赞了，则设置失败，用户无法重复点赞。若设置成果，再使用 `incr` 命令，将点赞总数加一。

```java
if setnx(key1) == 1
then 
   incr(key2)
```

为了保证上述两步操作的原子性，可以使用 Redis 的 LUA 脚本。




## 如何设计一个排行榜

* ref 1-[设计一个排行榜](https://segmentfault.com/a/1190000039320528)


1. 针对小流量，使用 MySQL，`order by` 排序
2. 大多数业务系统，都使用 Redis 的有序集合对象 `zset` 实现
   * `zrank` 可以按照分数从低到高返回排名信息
   * `zrevrank` 可以按照分数从高到低返回排名信息
   * `zrange/zrevrange key start end [withscores]` 可以返回指定排名范围内的信息

## 如何设计一个秒杀系统


### 技术设计

1. 服务隔离部署，热流量隔离
2. 秒杀链接加密，防止恶意供给
3. 库存预热，快速扣减
4. 动静分离
   * Nginx 做好动静分离，静态资源 Nginx 直接返回，保证秒杀和商品详情页的动态请求才打到后端服务集群
   * 使用 CDN 网络，分担本集群压力
5. 恶意请求拦截，使用网关识别非法请求，或使用布隆过滤器
6. 流量削峰
7. 限流、熔断、降级


### 优化方案
1. 丢弃订单
   * 若下单了太大，前端可以直接随机 `reject` 一些，简单粗暴，返回下单失败的提示
2. 优化吞吐
   * 增加服务器扩容
   * 分库分表
3. 引入 MQ，解耦，削峰，异步
   * 如针对瞬时流量洪峰，将请求暂时在 MQ 消息队列中缓存，异步处理，前端先提示 “秒杀结果计算中” 或 “红包金额计算中”
4. 内存分配（缓存预热）
5. 服务降级


## 如何设计一个积分系统
* ref 1-[如何设计一个电商平台积分兑换系统 | CSDN](https://blog.csdn.net/lchq1995/article/details/102589060)
* ref 2-[会员积分体系设计](https://learnku.com/articles/42520)



### 场景分析
1. 签到领积分
2. 通过购物、晒单评论等方式赚取积分
3. 下单时可用积分折扣金额
4. 下单后，需不需要查看商品的发货信息
5. 有无权限控制，比如针对新用户、老用户、付费用户
6. 积分的使用，可否当现金，可否兑换商品
   



### 表的设计

1. 用户积分表

| 字段  |  说明  |
|------|--------|
| id | 自增id |
|user_id | 用户id |
| toatl_credit | 总积分 |
| usable_credit | 可用积分 |
| level | 用户等级 |
| update_time | 更新时间 |

2. 积分兑换表


| 字段  |  说明  |
|------|--------|
| id | 自增id |
| user_id | 用户id |
| source_type | 积分来源，1-任务，2-系统赠送，3-取消订单，4-签到，5-兑换奖品，6-过期 |
| exchanged_credit | 用于兑换的积分 | 
| product_id | 兑换的商品id |
| update_time | 更新时间 |
| create_time | 创建时间 |


3. 发货申请表


| 字段  |  说明  |
|------|--------|
| id | 自增id |
| type | 发货类型，1-购买，2-积分兑换 |
| credit_exchange_id | 积分兑换表的id | 
| product_id | 要发货的商品id |
| express_no | 物流单号 | 


4. 物流配送进度查询（可拆分出积分系统）

5. 用户签到表

6. 任务表（获取积分的途径有很多，使用任务表记录用户参加的任务）




7. 完成任务记录表

| 字段  |  说明  |
|------|--------|
| id | 自增id |
| user_id | 用户id |
| task_id | 任务id |
| credit_uuid | 积分记录id |
| finish_credit | 完成该任务获取的积分 |



### 技术设计
1. 事务的保证

```s
积分服务 事务 {
    a. 扣减积分
    b. 新增积分兑换记录
    c. 调用仓储服务
}
```

2. 消息中间件的引入
3. 重试机制的引入
4. 重试机制下如何保证幂等


## 如何设计一个B站弹幕系统
* ref 1-[Netty 揭秘 B 站弹幕系统 Java 编程](https://www.bilibili.com/video/BV1mp4y1S7d6?p=1&vd_source=940dfe8509f57c2c8551d0a9c2f7f8d8)
* ref 2-[Netty 实现 WebSocket 聊天功能](https://waylau.com/netty-websocket-chat/)
* ref 3-[Netty 的原理](https://zhuanlan.zhihu.com/p/98056056)



弹幕系统的特点
1. 实时性高：你发我发，毫秒之差
2. 并发量大：一人吐槽，万人观看
3. 数据一致性的要求并不高：丢失几条数据并没有太大的关系



技术设计思路
1. 将弹幕消息存放到 Redis 缓存中，服务端去轮询缓存系统，获取对应的弹幕。
2. HTTP 是半双工协议，只能由客户端发起连接。WebSocket 是全双工协议，服务端和客户端均可以发起。
3. HTTP 是基于文本传输，WebSocket 是基于二进制协议。
4. 基于 Netty，实现 WebSocket 弹幕功能
5. Netty 是一个异步的、非阻塞IOD、基于事件驱动的网络应用框架，它可以用来开发高性能服务端和客户端。
6. NIO 是 `Non-blocking I/O`，非阻塞 IO，其中 `Selector` 机制就是 `NIO` 的核心。






## 快速查找一个数字是否出现在40亿个数字中

* [海量数据：快速查找一个数字是否出现在40亿个数字中](https://blog.csdn.net/april2009128/article/details/79124020)


> 给 40 亿个不重复的 unsigned int 的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那 40 亿个数当中


针对上述问题，有两种思路
1. 使用 Bitmap
2. 分治思想


### bitmap

采用 bitmap，1 个字节可以表示 8 个整数是否出现的情况（出现则对应的位置 1，否则为 0），那么表示 40 亿个整数的情况需要 40 亿 / 8 = 5亿，约 500M 的空间，空间复杂度是 `O(n)`。

### 分治思想

在《编程珠玑》里提供了一个思路，使用分治思想求解。

因为 `2^32` 为 40 亿多，所以给定一个数可能在，也可能不在其中；这里我们把 40 亿个数中的每一个用 32 位的二进制来表示。假设这 40 亿个数开始放在一个文件中，然后将这 40 亿个数分成两类
1. 最高位为 0
2. 最高位为 1

并将这两类分别写入到两个文件中，其中一个文件中数的个数 <= 20亿，而另一个 >= 20亿（这相当于折半了）。

与要查找的数的最高位比较并接着进入相应的文件再查找。

再然后把这个文件为又分成两类
1. 次最高位为 0 
2. 次最高位为 1

并将这两类分别写入到两个文件中，其中一个文件中数的个数 <= 10亿，而另一个 >= 10亿（这相当于折半了）。

与要查找的数的次最高位比较并接着进入相应的文件再查找。

.......

以此类推，就可以找到了，而且 时间复杂度为 `O(logn)`。（类似树的查找）

## 从30亿数据中找出出现次数最多的数字
* [从30亿数据中找出出现次数最多的数字](https://mp.weixin.qq.com/s/eVMx0g0afcpLkQxjETC0mA)


1. 首先将30亿数据写入文件中，大约占 10G
2. 使用一个 Map 统计出现频率，key 为数值，value 为出现的频率。
3. 分治处理，多线程处理
4. 多线程中，使用生产-消费设计模式，生产者负责读取数据，消费者负责统计频率


## 双蛋问题
* [去谷歌面试，竟让扔鸡蛋](https://www.teqng.com/2021/12/01/%E5%8E%BB%E8%B0%B7%E6%AD%8C%E9%9D%A2%E8%AF%95%EF%BC%8C%E7%AB%9F%E8%AE%A9%E6%89%94%E9%B8%A1%E8%9B%8B%EF%BC%9F/)
* [双蛋问题 | 维基百科](https://zh.m.wikipedia.org/zh-hans/%E5%8F%8C%E8%9B%8B%E9%97%AE%E9%A2%98)


### 题目描述

你有 2 颗鸡蛋，需要以最少的尝试次数来判断在 100 层的高楼上，哪一层楼是鸡蛋的安全层。

这里有几个假设条件
1. 没有摔碎的鸡蛋可以重复使用
2. 每颗鸡蛋的坚硬程度都是相同的


针对该问题，有如下几种解决思路
1. 逐层尝试，简单粗暴
2. 常规二分
3. 均衡切割
4. 微妙平衡

###  逐层尝试

假设我们只有一颗鸡蛋，显然只有从一楼开始扔，逐层试探，直到鸡蛋摔碎，安全层就是第 (N-1) 层。

该方案在最坏情况需要扔 100 次。


### 常规二分

我们先从 50 楼扔一颗鸡蛋，如果没碎，就往上继续二分，到 75 楼继续扔 ……

这是比较顺利的情况，如果不顺利呢，比如我们从 50 楼扔鸡蛋，直接碎了，那就只有一颗鸡蛋了。

这时候我们就回到解法一了，只能从 1 楼开始遍历，又是拼运气的时候了，要是运气好，1 楼鸡蛋就没了，那测试次数就是 1+1=2 次，但最坏情况就是 1+49=50 次。

### 均衡切割

将 100 层切分成两个维度，由两个鸡蛋分别控制一个维度。
1. 用第 1 个鸡蛋控制区间维度，比如将区间等分为 10 个区间，每 10 层一个区间。第 1个鸡蛋分别在第 0 层、第 10 层、第 20 层、第 30 层 …… 第 90 层、第 100 层扔下，确定区间位置。
2. 如果第 1 个鸡蛋破碎，用第 2 个鸡蛋在每个区间内尝试。比如第 1 个鸡蛋在第 30 层破裂，那么安全层一定在 [20,30] 之间。第 2 个鸡蛋从第 21、22 …… 29 层扔下。


最坏的情况是在第 100 层碎掉，总尝试次数为 10+9=19 次。



### 微妙平衡

「均衡切割」方案中，虽然第 2 颗鸡蛋在区块内部的逐层尝试次数是一样的，但 98 层对应的总尝试次数就多太多了。

**原因就是区块完全均匀划分对大数不利。**

明白了这个缺陷，也就知道了改进的基本思想：要对 100 找出一种二维区块划分，但不是均匀划分。

**对于比较小的区块部分，其包含的楼层范围可以适当增加；越向大数部分走，其包含的楼层范围越来越小。从下往上，每一个区块内所含楼层递减。**

在最高安全楼层比较低的情况下，第一颗鸡蛋尝试的次数少；在最高安全楼层比较高的情况下，则第二颗鸡蛋尝试的次数少。

**就是用第 2 颗鸡蛋尝试次数的减少来弥补第 1 颗鸡蛋需要的尝试次数的递增，使两颗鸡蛋在不同维度上的尝试次数此消彼长，达到一种总体上的平衡。**


**每上一个区块，第 1 颗鸡蛋消耗的次数就 +1，我们索性就假设每个区块包含的楼层数逐级递减 1，以达到平衡。**

那么每个区块包含的层数应该如何划分呢？

我们假设第一个区块有 X 层，那么第二个就是 X-1，以此类推，我们就得到了一个方程式

```s
X+（X-1）+（X-2）+···+ 3 + 2 + 1 ≥100

# 等价于
X(X+1)/2 ≥ 100

# 求解 X的值
X = 14
```



![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2023/design-two-egg-1.png)



可以计算出，X = 14。
* 由此，第一个区块包含 14 层楼，即 1 到 14 层
* 第二个区块包含 13 层楼，即 15 到 27 层
* 第三个区块包含 12 层楼，即 28 到 39 层


第一颗鸡蛋依次试第 14、27、39、50、60、69、77、84、90、95、99、100 层。只要期间任何一次鸡蛋碎了，就拿第二颗鸡蛋从上一次的安全层之后开始逐层尝试，直至第二颗鸡蛋也摔碎为止。

用这个方法，总次数一定不会超过 14 次。




## 红包系统


### 微信抢红包
* [微信高并发抢红包秒杀实战案例](https://zhuanlan.zhihu.com/p/105692236)

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2020/red-bag-design-1.png)



### 10亿红包雨
* ref 1-[京东红包雨的架构设计](https://www.cxymm.net/article/qq_35377525/115195590)


> 题目描述
  
总共有10亿个红包，在某个时间一起来抢红包，如何设计？（只涉及抢红包，不涉及发红包）

> 分析

主要考察的是如何设计高并发系统，但实际上存在一定变通处理方式，不一定全在技术上。

通常在考虑系统 QPS 时，应当按业务上的极限 QPS 作为系统必须承担的 QPS 设计，比如 10 亿个红包，因为用户量巨大，极限 QPS 是可能是 10 亿。

但是一般来说几万 QPS 已经是比较高的并发了，就需要比较大的集群和高并发架构来处理了，所以不可能真正实现 10 亿的并发架构，而是通过一些变通的方法来处理，比如在业务上做一些处理规避掉部分流量。

但尽可能地需要实现高并发架构，思路是将大部分流量拦截在系统承载能力低的模块之前。

> 设计解答

可以从两个方面进行回答，业务层面和技术层面。

一、业务上适当规避

在相应法律法规、规章制度、活动说明、用户体验允许的情况下，可以做以下处理
1. 根据某些规则对部分用户直接返回没抢到。比如有些用户曾经被系统识别为恶意用户、垃圾用户、僵尸用户，直接告诉用户已经抢完。
2. **分散不同客户端打开活动入口的时间。比如将 1 秒内的 10 亿流量分散到 10 秒，那么平均每秒只有 1 亿了。**
3. **增加客户端入口点击门槛。比如需要手机摇一摇，画一个图案才能触发抢红包的接口。这样既可以提高抢红包的门槛，也可以将抢红包的请求打散，分散到不同的时间段内。**

二、技术上硬核抗压

网关是会接触实打实 10 亿流量的地方，也是拦截掉最多无效流量的地方。同理，缓存也是。技术层面上，可以采取如下策略。
1. 限流策略。比如在压力测试中我们测到系统 1 亿 QPS 达到了极限，那么超过的部分直接返回已经抢完，通过 Nginx 的 lua 脚本可以查 Redis 看到 QPS 数据，从而可以动态调节。
2. 作弊拦截。通过对 UA、IP 规则直接将抢红包的作弊流量拦截掉。
3. 异步削峰。对 Redis 中的红包预减数量，立即返回抢红包成功请用户等待，然后把发送消息发给消息队列，进行流量的第二次削峰，让后台服务慢慢处理。（总结而言，就是先判断用户是否抢红包成功，将这个状态先返回给前端，提示“红包领取成功，金额计算中”，红包金额稍后二次计算）
4. 服务逻辑。比如业务逻辑是使用事务控制对数据库的创建红包记录，减红包数量的操作，那么创建操作要放到减数量操作之前，从而避免减数量 update 的行锁持有时间。
5. 机器配置。当然是服务器机器配置约高越好，数据库配置越猛越好，高并发抢红包主要是 CPU 的负载较高，要选择偏向 CPU 性能的机器。



### 发红包和抢红包
* ref 1-[如何设计一个抢红包系统 | 掘金](https://juejin.cn/post/6925947709517987848)
* ref 2-[聊聊红包雨背后的逻辑](https://www.cnblogs.com/gyjx2016/p/12537186.html)



由于查看红包过于简单，所以本文不讨论。那么系统用例就只剩下发、抢两种。
1. 发红包：用户设置红包总金额、总数量
2. 抢红包：用户从总红包中随机获得一定金额


#### 表结构设计

* 红包活动表

```sql
CREATE TABLE `t_redpack_activity`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `total_amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '总金额',
    `surplus_amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '剩余金额',
    `total` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包总数',
    `surplus_total` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包剩余总数',
    `user_id`    bigint(20)     NOT NULL DEFAULT '0' COMMENT '用户编号',
    `version` bigint(20)     NOT NULL DEFAULT '0' COMMENT '版本号',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```

* 红包表

```sql
CREATE TABLE `t_redpack`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `activity_id`         bigint(20)     NOT NULL DEFAULT 0 COMMENT '红包活动ID',
    `amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '金额',
    `status`     TINYINT(4) NOT NULL DEFAULT 0 COMMENT '红包状态 1可用 2不可用',
    `version` bigint(20)     NOT NULL DEFAULT '0' COMMENT '版本号',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```


* 明细表

```sql
CREATE TABLE `t_redpack_detail`
(
    `id`         bigint(20)     NOT NULL COMMENT '主键',
    `amount`     decimal(10, 2) NOT NULL DEFAULT '0.00' COMMENT '金额',
    `user_id`    bigint(20)     NOT NULL DEFAULT '0' COMMENT '用户编号',
    `redpack_id` bigint(20)     NOT NULL DEFAULT '0' COMMENT '红包编号',
    `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8;
```


#### 技术方案
1. 基于分布式锁的实现
   * 基于分布式锁的实现最为简单粗暴，整个抢红包接口以 activityId 作为 key 进行加锁，保证同一批红包抢行为都是串行执行。
   * 锁通过Redis的lua脚本实现，且实现了阻塞式本地可重入。
2. 基于乐观锁的实现
   * 为红包活动表增加乐观锁版本控制，当多个线程同时更新同一活动表时，只有一个 client 会成功。其它失败的 client 进行循环重试，设置一个最大循环次数即可。
   * 此种方案可以实现并发情况下的处理，但是冲突很大。因为每次只有一个人会成功，其他 client 需要进行重试，即使重试也只能保证一次只有一个人成功，因此 TPS 很低。
   * 当设置的失败重试次数小于发放的红包数时，可能导致最后有人没抢到红包，实际上还有剩余红包。
3. 基于悲观锁的实现
   * 由于红包活动表增加乐观锁冲突很大，所以可以考虑使用使用悲观锁 `select * from t_redpack_activity where id = #{id} for update`，注意悲观锁必须在事务中才能使用。
   * 此时，所有的抢红包行为变成了串行。此种情况下，悲观锁的效率远大于乐观锁。
4. 预先分配红包，基于乐观锁的实现
   * 如果我们将乐观锁的维度加在红包明细上，那么冲突又会降低。因为之前红包明细是用户抢到后才创建的，那么**现在需要预先分配红包，即创建红包活动时即生成 N 个红包**，通过状态来控制可用/不可用。
   * **这样，当多个 client 抢红包时，获取该活动下所有可用的红包明细，随机返回其中一条然后再去更新，更新成功则代表用户抢到了该红包，失败则代表出现了冲突，可以循环进行重试。如此，冲突便被降低了。**
5. 基于 Redis 队列的实现
   * 和上一个方案类似，不过，用户发放红包时会创建相应数量的红包，并且加入到 Redis 队列中。抢红包时会将其弹出。Redis 队列很好的契合了我们的需求，每次弹出都不会出现重复的元素，用完即销毁。
   * 缺陷：抢红包时一旦从队列弹出，此时系统崩溃，恢复后此队列中的红包明细信息已丢失，需要人工补偿。
6. 基于 Redis 队列，异步入库
   * 这种方案的是抢到红包后不操作数据库，而是保存持久化信息到 Redis 中，然后返回成功。
   * 通过另外一个线程 UserRedpackPersistConsumer，拉取持久化信息进行入库。

## 智力题
### 如何判断一个点在多边形内
* ref 1-[如何判断一个点在多边形内 - 射线法](https://www.cnblogs.com/muyefeiwu/p/11260366.html)



* 题目描述

现有一个点 P(x,y)，多变形 `Polypon`，判断点 P 是否在多边形内。


* 射线法判断 

可以从该点引出一条水平射线（任意射线都可，但水平便于计算），观察射线与多变形的交点个数，如果交点个数为奇数，则该点在多边形内，如果为偶数 则在多边形外。



### 等概率输出0和1

* ref 1-[概率p输出1，概率1-p输出0，如何等概率输出0和1 | CSDN](https://blog.csdn.net/qq_29108585/article/details/60765640)


* 题目描述

有一个 `RANDOM()` 函数，输出 1 的概率是 p，输出 0 的概率是（1-p），如何才可以等概率输出 1 和 0。


* 解答

| 输出值 | 概率 |
|-------|------|
| 11 | p*p |
| 10 | p*(1-p) |
| 01 | (1-p)*p |
| 00 | (1-p)*(1-p) |


从上表可以看出，如果调用两次 `RANDOM()` 函数，输出 `10` 和 `01` 的概率是一样的。代码实现如下。

```java
//cpp
int random_0_1()  
{  
    int i = RANDOM();  
    int j = RANDOM();  
    int result;  
  
    while (true)  
    {  
        if (i == 0 && j == 1)  //输出 10
        {  
            result = 0;  
            break;  
        }  
        else if (i == 1 && j == 0)    //输出 01
        {  
            result = 1;  
            break;  
        }  
        else  
            continue;  
    }  
  
    return result;  
}  
```