# 分布式-03-分布式一致性算法


[TOC]


## 更新
* 2022/06/08，撰写




## 参考资料
* [分布式共识算法 | 凤凰架构](https://icyfenix.cn/distribution/consensus/)
* [分布式一致性算法-Paxos、Raft、ZAB、Gossip | 知乎](https://zhuanlan.zhihu.com/p/130332285)


## 前言



一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。

一致性又可划分为强一致性和弱一致性（最终一致性）
1. 强一致性：保证系统改变提交以后立即改变集群的状态
   * Paxos
   * Raft（muti-paxos）
   * ZAB（muti-paxos）
2. 弱一致性：也叫最终一致性，系统不保证改变提交以后立即改变集群的状态，但是随着时间的推移最终状态是一致的。
   * DNS 系统
   * Gossip 协议


## Paxos

* ref 1-[Paxos 协议介绍](https://www.cnblogs.com/jmcui/p/14633799.html)




分布式系统中有多个节点，所以就会存在节点间通信的问题。节点通讯模型可分为两种
1. 共享内存（Shared memory）
2. 消息传递（Messages passing）

Paxos 是基于消息传递的通讯模型的，Paxos 的假设前提是在分布式系统中进程之间的通信会出现丢失、延迟、重复等现象，但不会出现传错的现象，即不考虑拜占庭将军问题。



### 什么是Paxos

**Paxos 协议是少数在工程实践中证实的强一致性、高可用的去中心化分布式协议，可以用来解决分布式一致性问题。**

Google 的很多大型分布式系统都采用了 Paxos 算法来解决分布式一致性问题，如 Chubby、Megastore 以及 Spanner 等。开源的 ZooKeeper 以及 MySQL 5.7 推出的用来取代传统的主从复制的 MySQL Group Replication 等纷纷采用 Paxos 算法解决分布式一致性问题。

Paxos 协议的流程较为复杂，但其基本思想却不难理解，类似于人类社会的投票过程。Paxos 协议中，有一组完全对等的参与节点，这组节点各自就某一事件做出决议，如果某个决议获得了超过半数节点的同意则生效。Paxos 协议中只要有超过一半的节点正常，就可以工作，能很好对抗宕机、网络分化等异常情况。

### 协议角色

Paxos 协议中，划分出了 3 个角色
1. Proposer（提案者）
   * 提案者可以有多个
   * 提案者提出议案（value），所谓 `value`，在工程中可以是任何操作，如修改某个变量为某个值、设置当前 `primary` 为某个节点等。Paxos 协议中统一将这些操作抽象为 `value`
   * 同一轮 Paxos 过程，最多只有一个 value 被批准
2. Acceptor（批准者）
   * 批准者可以有 N 个
   * Proposer 提出的 value 必须获得超过半数（N/2+1）的 Acceptor 批准后才能通过
   * Acceptor 之间完全对等独立
3. Learner（学习者）
   * 学习者不参与决策
   * 学习被批准的 value 


上述 3 类角色只是逻辑上的划分，实践中一个节点可以同时充当这 3类角色，即可以“身兼数职”。


### 协议流程

**Paxos 算法解决的核心问题是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值（决议）达成一致。**


Paxos 协议一轮一轮的进行，每轮都有一个编号。每轮 Paxos 协议可能会批准一个 value，也可能无法批准一个 value。 如果某一轮 Paxos 协议批准了某个 value，则以后各轮 Paxos 只能批准这个 value，这是整个协议「正确性」的基础。

一次 Paxos 协议实例只能批准一个 value，这也是 Paxos 协议「强一致性」的重要体现。

每轮 Paxos 协议分为两个阶段，即准备阶段和批准阶段。Paxos 协议流程如下图所示。

![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/paxos-process-1.png)



### Multi-Paxos 算法


Paxos 协议引入了轮数的概念，高轮数的 Paxos 提案可以抢占低轮数的 Paxos 提案，从而避免了「死锁」的发生。然而这种设计却引入了「活锁」的可能，即 Proposer 相互不断以更高的轮数提出议案，使得每轮 Paxos过程都无法最终完成，从而无法批准任何一个value。Multi-Paxos 正是为解决此问题而提出，Multi-Paxos 基于 Basic Paxos 做了两点改进
1. 针对每一个要确定的值，运行一次 Paxos 算法实例（Instance），形成决议。每一个 Paxos 实例使用唯一的 Instance ID 标识。
2. 在所有 Proposers 中选举一个 Leader，由 Leader 唯一的提交 Proposal 给 Acceptors 进行表决。这样没有 Proposer 竞争，解决了活锁问题。在系统中仅有一个 Leader 进行 value 提交的情况下，Prepare 阶段就可以跳过，从而将两阶段变为一阶段，提高效率。


![](https://image-bed-20181207-1257458714.cos.ap-shanghai.myqcloud.com/back-end-2022/multi-paxos-process-1.png)


Multi-Paxos 首先需要选举 Leader，Leader 的确定也是一次决议的形成，所以可执行一次 Basic Paxos 实例来选举出一个 Leader。选出 Leader 之后只能由 Leader 提交 Proposal，在 Leader 宕机之后服务临时不可用，需要重新选举 Leader 继续服务。在系统中仅有一个 Leader 进行 Proposal 提交的情况下，Prepare 阶段可以跳过。

Multi-Paxos 通过改变 Prepare 阶段的作用范围至后面 Leader 提交的所有实例，从而使得 Leader 的连续提交只需要执行一次 Prepare 阶段，后续只需要执行 Accept 阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个 Instance ID 标识，Instance ID 由 Leader 本地递增生成即可。

Multi-Paxos 允许有多个自认为是 Leader 的节点并发提交 Proposal 而不影响其安全性，这样的场景即退化为 Basic Paxos。

Chubby 和 Boxwood 均使用 Multi-Paxos。ZooKeeper 使用的 Zab 也是 Multi-Paxos 的变形。


## Raft
* ref 1-[分布式理论之分布式一致性：Raft 算法原理](https://www.tpvlog.com/article/66)


Paxos 算法不容易实现，Raft 算法是对 Paxos 算法的简化和改进。



Raft 算法中，节点有三种角色（初始状态下所有节点都是 Follower）
1. Leader 总统节点，负责发出提案
2. Follower 追随者节点，负责同意 Leader 发出的提案
3. Candidate 候选人，负责争夺 Leader


Raft 算法将一致性问题分解为两个的子问题
1. Leader 选举
2. 状态复制


### Leader选举
1. 初始状态下所有节点都是 Follower，每个 Follower 都持有一个定时器。
2. 当定时器时间到了而集群中仍然没有 Leader，Follower 将声明自己是Candidate（节点角色从 Follower 变成了 Candidate），并参与 Leader 选举，同时将消息发给其他节点来争取他们的投票，若其他节点长时间没有响应 Candidate，将重新发送选举信息。
3. 集群中其他节点将给 Candidate 投票。
4. 获得多数派支持的 Candidate，将成为第 M 任 Leader（M任是最新的任期）。
5. 在任期内的 Leader 会不断发送心跳给其他节点证明自己还活着，其他节点受到心跳以后就清空自己的计时器并回复 Leader 的心跳。这个机制保证其他节点不会在 Leader 任期内参加 Leader 选举。
6. 当 Leader 节点出现故障而导致 Leader 失联，没有接收到心跳的 Follower 节点将准备成为 Candidate，进入下一轮 Leader 选举。
7. 若出现两个 Candidate 同时选举，并获得了相同的票数，那么这两个 Candidate 将随机推迟一段时间后再向其他节点发出投票请求，这保证了再次发送投票请求以后不冲突。

### 态复制
1. Leader 负责接收来自 Client 的提案请求。
2. 提案内容将包含在 Leader 发出的下一个心跳中。
3. Follower 接收到心跳以后回复 Leader 的心跳。
4. Leader 接收到多数派 Follower 的回复以后，确认提案并写入自己的存储空间中并回复 Client。
5. Leader 通知 Follower 节点确认提案，并写入自己的存储空间，随后所有的节点都拥有相同的数据。


## ZAB算法

ZAB 也是对 Multi Paxos 算法的改进，大部分和 Raft 相同。和 Raft 算法的主要区别
1. 对于 Leader 的任期，Raft 叫做 term，而 ZAB 叫做 epoch
2. 在状态复制的过程中，Raft 的心跳从 Leader 向 Follower 发送，而 ZAB 则相反。

## Gossip

Gossip 算法每个节点都是对等的，即没有角色之分。Gossip 算法中的每个节点都会将数据改动告诉其他节点（类似传八卦）。有话说得好，“最多通过六个人你就能认识全世界任何一个陌生人”，因此数据改动的消息很快就会传遍整个集群。


Redis Cluster 集群中节点通信使用到了 Gossip 协议，详情参考笔记「Redis-07-Redis的3种集群模式」。